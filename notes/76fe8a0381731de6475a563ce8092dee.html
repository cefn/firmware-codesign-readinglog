<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Extracting Usability and User Experience Information from Online User Reviews</title>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    </head>
    <body>
        <h1>
            <a href="../papers/76fe8a0381731de6475a563ce8092dee.pdf">Extracting Usability and User Experience Information from Online User Reviews</a>
        </h1>
        <h2>Authors</h2>
        <p>Steffen Hedegaard, Jakob Grue Simonsen</p>
        <h2>Year</h2>
        <h2>Notes</h2>
        <p>Dimensions (satisfaction measures) of interactive products discussed. Should bottom this out. Need a source of critical design in the context of firmware. This is close - in the context of software/video games, but uses an interesting technique - harvesting from online reviews (similar to source based on bike light review).</p>
        <p>They adopt textual analysis of online reviews as a basis for figuring out how much information content online-reviews might provide for UX and usability feedback. This is linked to sentiment analysis but (they claim) is a much more focused science on UX.</p>
        <p>They cover the nomenclature and categories of 'usability' found in the literature extensively from many authors and further literature surveys, as a basis for introducing their own statistical aggregation measures.</p>
        <p>They reference an ISO standard around usability which should play a part in the literature review.</p>
        <h2>Tags</h2>
        <h2>Relevance</h2>
        <h2>Quotations</h2>
        <p>"We (a) find that 13%–49% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions."<br/>
        </p>
        <p>"The aim of this paper is to quantify the amount of UUX information and dimensions in online reviews from the specific domains of software and video games. We also implement and test a machine-learning-based classifier that tags sentences in reviews according to whether they contain usability or UX-related information and according to the dimensions of usability or UX they pertain to."<br/>
        </p>
        <p>"traditional studies focus on short term product use (median 30 minutes duration [19]) and conducted in lab settings; few studies stretch across longer time periods and then only weeks [19]." [citing Hornbæk, K. 2006]</p>
        <p>"There are important caveats when assessing the potential usefulness of online reviews: It is not clear whether online reviews are written by users typical of the user base; in addition, very few details about reviewers (e.g. gender, age, preferences) are available, in contrast to standard usability studies. Furthermore, some reviews may be fake."</p>
        <p>"A more fine-grained description of usability is obtained by the following five dimensions which, with some variation in the naming of the aspects, are often used for measuring and describing usability in models and literature: (i) Effectiveness/Errors, (ii) Efficiency, (iii) Satisfaction, (iv) Learnability, (v) Memorability." [CH: extensive referencing removed]</p>
        <h2>Boundary Objects</h2>
        <h2>Concepts</h2>
        <h2>Field of Study</h2>
        <p>UX, User Experience, Usability, Text corpus analysis, natural language processing, end user reviews</p>
        <h2>Methodology</h2>
        <h2>References</h2>
        <p>Hornbæk, K. 2006 "Current practice in measuring usability: Challenges to usability studies and research."</p>
        <!-- UNIQUE HASH 76fe8a0381731de6475a563ce8092dee -->
    </body>
</html>

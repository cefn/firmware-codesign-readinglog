<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Framing Embodiment in General-Purpose Computing</title>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    </head>
    <body>
        <h1>
            <a href="../papers/701f35b1caa0d9c0dc2c837b06598f09.pdf">Framing Embodiment in General-Purpose Computing</a>
        </h1>
        <h2>Authors</h2>
        <p>Elisabeth Nesheim</p>
        <h2>Year</h2>
        <h2>Notes</h2>
        <p>She is looking to present a model for 'screenless' [my term] interactions with general purpose computing, and casting around for references and examples which could underpin it, and figuring out what aspects would need to be taken account.</p>
        <p>She discusses Gibson, Norman, but also Dourish, who explores Heidegger present-at-hand and ready-at-hand, and moves towards an analysis of coupling between embodied interaction and meaning, making interaction effective (make things happen) though doesn't seem to turn this into design design principles.</p>
        <h2>Tags</h2>
        <h2>Relevance</h2>
        <h2>Quotations</h2>
        <p>"the importance of affordance needs to be emphasized in interface design, as it points to what we pay attention to when interacting with an object, how we perceive it as possible to use. It therefore plays a key role in deciding what a user most likely will do when operating an interface."</p>
        <p>"The dominant interface for personal computers—the graphical user interface—is highly ocularcentric, where only parts of the body apparatus (eyes and hands) are addressed in the interface directly. As an increasing amount of information, life experience and human contact is channeled through it, the desktop computer system, becomes increasingly inadequate to fully represent these actions. Any prosthesis added to or used in conjunction with the body and any part of the sensory apparatus neglected will define our interaction with information. Information gathered by the somesthetic—the touch and proprioceptic senses—constitute a significant component in the way we form hypotheses about what an object is, and how it can be manipulated. By addressing the somesthetic senses in computer interfaces, we can achieve richer and more intuitive interactive experiences."</p>
        <p>"representation of functionality and possible user actions is key to any computational environment. A user interface sets the stage for interaction between man and machine. It represents an environment, where a user can perform certain tasks and hold cues to how the same user can manipulate this environment according to his/her needs and desires"</p>
        <p>"Coupling is a strong concept for understanding the how we can design meaningful relationships between man and objects. It points to the significance of designing objects with a conceptual identity, that equally encompasses the object as a thing in it itself as well as the actions it can assist the user in performing." [credited to Dourish 2001]</p>
        <p>"Norman looks at interfaces of specialized machines, such as the early video game consoles and household appliances, and attributes their success in the one-to-one relationship between the input device (whether a button, lever, pot or slider) and the action it performs. Norman claims that ideally “both the interface and the computer would be invisible” and that only “the task that would be visible, the task and the tool being used to accomplish the task” (217). User interfaces should be designed, based on an investigation and understanding of the tasks a user wants to accomplish with a computer."<br/>
        </p>
        <h2>Boundary Objects</h2>
        <h2>Concepts</h2>
        <p>Affordance [credited to Gibson 1977], Gulf of Execution, Gulf of Evaluation</p>
        <h2>Field of Study</h2>
        <h2>Methodology</h2>
        <h2>References</h2>
        <!-- UNIQUE HASH 701f35b1caa0d9c0dc2c837b06598f09 -->
    </body>
</html>

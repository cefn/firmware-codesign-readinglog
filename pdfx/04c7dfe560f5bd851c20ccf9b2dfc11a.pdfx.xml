<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>a98203f8e99bf454cfcf82cc4806acf6805a862046a8dbc07ba73ea83d2bde0d</job>
    <base_name>62nl</base_name>
    <doi confidence="possible" alt_doi="http://dx.doi.org/10.1016/b978-0-12-407237-4.00002-5">http://dx.doi.org/10.1007/978-3-662-07811-2_9</doi>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <title-group>
        <article-title class="DoCO:Title" id="1">SKETCHES FOR AND FROM COLLABORATION</article-title>
      </title-group>
      <contrib-group class="DoCO:ListOfAuthors">
        <contrib contrib-type="author">
          <name id="2">JULIE HEISER</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="3">BARBARA TVERSKY</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="4">AND MIA SILVERMAN</name>
        </contrib>
      </contrib-group>
      <region class="unknown" id="5">Department of Psychology, Stanford University Stanford, CA 94305-2130</region>
      <abstract class="DoCO:Abstract" id="6">Pairs of collaborators worked side-by-side using a campus map to design and produce an optimal emergency rescue route. Co- present collaborators shared a map; remote partners were separated by a barrier and used separate maps. In the co-present condition, gestures on the maps, notably pointing and tracing, served to focus attention and to communicate solutions. A shared diagram increased the efficiency of the collaboration, the product of the collaboration, and the enjoyability of the collaboration.</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="7" confidence="possible" page="1" column="1">1. Sketches Promote and Reflect Thought</h1>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="10" page="1" column="1">1.1 TASK: DESIGNING A RESCUE ROUTE COLLABORATIVELY</h2>
        </section>
      </section>
      <region class="DoCO:TextChunk" id="9" page="1" column="1">Sketches, diagrams, graphics, visualizations, external representations--call them what you will—play numerous roles in thought and communication (e. g., <xref ref-type="bibr" rid="R8" id="8" class="deo:Reference">Tversky, 2001</xref>). They record information, to remind one’s self or to convey information and preserve it for others. They externalize internal thought, making it visible to self and others. They convert internal memory and mental manipulations to external memory and physical manipulations, relieving limited cognitive resources. They serve as a platform for inference, reasoning and insight. They capitalize on human spatial experience and reasoning facility by representing abstract concepts spatially. External representations can also serve to facilitate collaborations. This is the role we focus on here, though in facilitating collaboration, sketches can simultaneously facilitate memory, reasoning, and insight. Diagrams do multiple duties.</region>
      <region class="DoCO:TextChunk" id="14" page="1" column="1">Before we illustrate many of the ways that external representations can facilitate collaborations, we describe the collaborative situation in which we have been studying. The task given to pairs of students was to find the most efficient route to rescue a certain number of injured people collected at centers on campus after an earthquake. Students were provided with a standard map of the Stanford campus annotated to show the roads blocked <marker type="page" number="2"/><marker type="block"/> off, the locations where injured are situated, and the number of injured at each location. The students’ task was to draw a route that would enable picking up 60 injured people in the shortest path. In the face-to-face condition, pairs shared a single campus map and produced a single sketch of the route they developed together. In the remote condition, pairs viewed separate but identical campus maps and sketched separate maps of the route they developed together. In the remote condition, the pairs sat next to each other, separated by a curtain, so that they could effortlessly hear each other. Thus, the major difference between the face-to-face and remote condition was whether participants viewed the external representations together or not. This difference had large effects on the nature and the outcome of the collaboration.</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="12" page="2" column="1">2</outsider>
      <outsider class="DoCO:TextBox" type="header" id="13" page="2" column="1">J. HEINER, B. TVERSKY AND M. SILVERMAN</outsider>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="15" confidence="possible" page="2" column="1">2. Process of Collaboration</h1>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="16" page="2" column="1">2.1 SKETCHES CAPTURE JOINT ATTENTION.</h2>
          <region class="DoCO:TextChunk" id="20" page="2" column="1">Despite conventions that speakers make eye contact with listeners in conversations, pairs in the face-to-face condition did not look at each other. The gaze of both participants was on the maps. What’s more, their conversation was directed at the maps, which served as a shared task focus. Pairs in the remote condition also looked at the maps, but they did not look together. In the face-to-face condition, pairs of participants were working in a coordinated fashion on the same subtask <marker type="block"/> whereas in the remote condition, pairs of participants frequently split up the work and concentrated on separate subtasks, with coordination only at a relatively high level. Thus, pairs in the remote condition had separate task foci. Eye-gaze and task focus are evident in Figures 1 and 2 showing pairs of participants in the face-to-face and remote conditions respectively.</region>
          <region class="DoCO:FigureBox" id="F1">
            <image class="DoCO:Figure" src="62nl.page_002.image_01.png" thmb="62nl.page_002.image_01-thumb.png"/>
            <caption class="deo:Caption" id="19" page="2" column="1">Figure 1. A pair of participants in the face-to-face condition considering possible rescue routes.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="header" id="21" page="3" column="1">SKETCHES FOR AND FROM COLLABORATION</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="22" page="3" column="1">3</outsider>
          <region class="DoCO:FigureBox" id="F2">
            <image class="DoCO:Figure" src="62nl.page_003.image_02.png" thmb="62nl.page_003.image_02-thumb.png"/>
            <caption class="deo:Caption" id="24" page="3" column="1">Figure 2. A pair of participants in the remote condition considering possible rescue routes.</caption>
          </region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="25" page="3" column="1">2.2 GESTURES ON SKETCHES</h2>
          <region class="DoCO:TextChunk" id="29" page="3" column="1">The sketch maps did not function alone. What was critical were the gestures participants made on the sketches. Gestures are an inevitable and natural element of speaking; blind children produce them even though they have never seen gestures (Iverson and Goldin-<xref ref-type="bibr" rid="R3" id="26" class="deo:Reference">Meadow, 1997</xref>). Because gestures, like diagrams, serve many roles, there have been a number of classifications for them (e. g., Goldin-<xref ref-type="bibr" rid="R2" id="27" class="deo:Reference">Meadow, 2003</xref>; Mc Neill, 1992). All distinguish several higher order groups, among them, emblems like the OK sign or nodding “yes” or “no.” Emblems are lexicalized, that is, they serve much like spoken words. Another category of gesture is those that promote the discourse, gestures like beats, up and down hand movements timed with items on a list, or alternating hand movements corresponding to “on the one hand” and “on the other hand.” These serve to structure the discourse. Researchers also point to a class of gestures that convey content, sometimes iconically, sometimes metaphorically. A nice example of this comes from children explaining how they solve arithmetic story problems. Discrete solutions are often accompanied by discrete gestures and continuous solutions are typically accompanied by smooth gestures (Alibali, Bassok, Olseth Solomon, Syc, and Goldin-<xref ref-type="bibr" rid="R1" id="28" class="deo:Reference">Meadow, 1999</xref>). The concern here is with gestures that convey meaning. Significantly, the vast majority of them are on the sketches.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="30" page="3" column="1">2.3 WHAT ARE GESTURES FOR?</h2>
          <region class="DoCO:TextChunk" id="38" page="3" column="1">This question arouses controversy (see Goldin- <xref ref-type="bibr" rid="R2" id="31" class="deo:Reference">Meadow, 2003</xref> for a review of this and other topics). On one side are those who claim that gestures promote the gesturer’s cognition but are not communicative. They try to show that on the one hand, preventing speakers from gesturing interferes with their fluency and even with their cognitive agility (e. g., Krauss,<marker type="page" number="4"/><marker type="block"/>  Morrel-<xref ref-type="bibr" rid="R4" id="35" class="deo:Reference">Samuels, and Colasante, 1991</xref>) and on the other hand, listeners learn nothing from the gestures that they did not learn from the words. On the other side are those who show that gestures can and do communicate (e. g., Goldin-<xref ref-type="bibr" rid="R2" id="36" class="deo:Reference">Meadow, 2003</xref>; <xref ref-type="bibr" rid="R6" id="37" class="deo:Reference">Rogers, 1978</xref>), conveying information that is available in the gestures but not in words. There is no reason that gestures, like spoken words and like diagrams, cannot do both; they can promote the thought of the gesturer and they can communicate to listeners. We find numerous examples of both in the collaborations we have studied, as well as other roles that gestures can serve, such as maintaining joint attention.</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="33" page="4" column="1">4</outsider>
          <outsider class="DoCO:TextBox" type="header" id="34" page="4" column="1">J. HEINER, B. TVERSKY AND M. SILVERMAN</outsider>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="39" page="4" column="1">2.4 GESTURES ON SKETCHES FACILITATE COLLABORATION</h2>
          <section class="DoCO:Section">
            <h3 class="DoCO:SectionTitle" id="40" page="4" column="1">2.4.1. Pointing Gestures on Sketches Establish Focus.</h3>
            <region class="DoCO:TextChunk" id="41" page="4" column="1">The dominant gesture is pointing. A sketch is a large window, typically larger than the focus of attention, so a sketch is not sufficient to assure joint attention. To ensure joint focus, collaborators point to the relevant part of sketch, as is evident in the photographs above. Because focus is at a small portion of a larger sketch, it is harder to ensure joint attention in the remote condition than in the face-to-face condition. This may account in part for the interactive nature of face-to-face collaboration in contrast to the fractionated nature of remote collaboration. In face-to-face collaboration, both partners are working jointly on the same subtask most of the time whereas in remote collaboration, partners often work in parallel on different subtasks. Pointing does more than insure joint focus. Pointing also defines the suggested routes, along with a related gesture, tracing. More on this later.</region>
          </section>
          <section class="DoCO:Section">
            <h3 class="DoCO:SectionTitle" id="42" page="4" column="1">2.4.2. Shared Sketches Promote Interactivity.</h3>
            <region class="DoCO:TextChunk" id="43" page="4" column="1">The map, then, served as the focus of attention in both conditions, but in the face-to-face condition, in conjunction with gestures, maps served to insure a joint focus of attention. Pointing assured that face-to-face participants were looking at the same part of the map The remote collaborators could not do that; they had to establish joint reference on the map with circuitous language, not always worth the trouble. Having a shared diagram, hence a shared focus of attention, changed the nature of the collaboration: in the face-to-face condition, collaboration was a continuous, on-going process. In the remote condition, collaboration was disjointed and distributed. This was evidenced in the number of interchanges in the two conditions. There was nearly double the number of interchanges in the face-to-face condition as the remote condition. Furthermore, the contributions of both partners were more balanced in the face-to-face condition. In short, shared external representations promote interactivity.</region>
          </section>
          <section class="DoCO:Section">
            <h3 class="DoCO:SectionTitle" id="44" page="4" column="1">2.4.3. Shared Sketches Promote Efficient Collaboration.</h3>
            <region class="DoCO:TextChunk" id="46" page="4" column="1">The collaborations were divided into stages depending on the ongoing functional activity. The stages and the average amount of time spent at them in seconds appear in <xref ref-type="table" rid="T1" id="45" class="deo:Reference">Table 1</xref>.</region>
            <outsider class="DoCO:TextBox" type="header" id="47" page="5" column="1">SKETCHES FOR AND FROM COLLABORATION</outsider>
            <outsider class="DoCO:TextBox" type="page_nr" id="48" page="5" column="1">5</outsider>
            <region class="DoCO:TextChunk" id="50" confidence="possible" page="5" column="1"> <xref ref-type="table" rid="T1" id="49" class="deo:Reference">TABLE 1</xref>: Time (sec) of Stages of Collaboration</region>
          </section>
        </section>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="51" confidence="possible" page="5" column="1">Stage</h1>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="52" confidence="possible" page="5" column="1">Time</h1>
        <region class="DoCO:TextChunk" id="53" confidence="possible" page="5" column="1">Introduction 0.3 Individual Planning 1.8 Defining Problem 14.1 Proposing Strategy 31.3 Re-Sketching Map 41.3 Evaluating/Eliminating Routes 136.5 Generating Routes 341.7 Sketching Map 464.5 Drawing Final Map 674.5</region>
        <region class="DoCO:TextChunk" id="62" page="5" column="1">Relatively little time was spent introducing participants and task, explicitly dividing the task, defining the problem, proposing strategies for finding solutions, and re-sketching the map, altogether 89 seconds, a little over a minute. Generating, evaluating and eliminating routes took 7.9 minutes altogether; this is the critical part of planning and decision making. Sketching the map took7.5 minutes and drawing the final map took 11.2 minutes; these stages produce the solution that has been discovered. Shared diagrams and the opportunity to gesture on them decreased the time taken to reach a solution. Collaborators in the remote condition took marginally longer (28.5 min, SD =4.0)) overall than collaborators in the co- present condition (25.5 min, SD = 4.2, F(1, 29) = 3.1, p = .09). This was primarily due to the Generating Routes stage of collaboration. Co-present dyads spent 273.20 sec generating routes (SD = 135.48) but remote pairs took 410.20 (SD = 185.37, F (1, 23) = 4.57, p &lt; .05). The extra time taken by remote pairs to generate routes is due to the difficulties of describing the routes verbally rather than pointing to them on the maps. The ease of communication of routes enabled by gestures may also explain why co- present partners revised their solution routes more often (M = 0.73, SD = 0.7) than remote partners (M = 0.2, SD = 0.42; F (1, 23) = 4.6, p &lt; .05). These stages were not necessarily sequential, especially in the remote condition. The remote participants returned to stages more frequently than the co-present participants in the Defining Problem stage (remote M = 1.4, SD = 0.84; co-present M = 0.73, SD = 0.59, F (1, 23) = 5.412, p &lt; 0.03) and in the Proposing Strategy stage (remote M = 1.3, SD = 0.48, co-present M = 0.87, SD = 0.35, F (1, 23) = 6.76, p &lt; 0.002). The increase in overall time and the revisiting of previous stages are evidence that remote collaborations were less efficient than co-present. This conclusion is further supported by the relative frequencies of partners’ working on separate stages during the collaboration. This never happened in the co-present situation, but half the remote partners worked on different stages at some point during the problem-solving process. <marker type="page" number="6"/><marker type="block"/> 2.4.4. Shared Sketches Promote Enjoyable Collaboration. The shared external representation also made the collaboration more enjoyable. Participants in the face-to-face condition enjoyed working on the task more than participants in the remote condition. Participants in the face- to-face condition gave significantly higher ratings to the statement “my partner and I worked well together” than pairs in the remote condition. In addition, participants in the face-to-face condition gave higher agreement to the statement “redrawing the map was important to solving the problem.”<marker type="block"/> 2.4.5. Gesturing While Speaking: Construction of Joint Meaning. Language in the remote condition was complex and clumsy, requiring elaborate and often awkward spatial descriptions. What simplified the language for the face-to-face condition were gestures on the maps. Prominent among them were points and tracings. Locations could be established by pointing, typically along with a verbalized “here” or “there.” Proposing, altering, querying, and clarifying routes could be accomplished by tracing them on the map. Describing a location and especially a route literally required circumlocution in the remote conditions. Some of the major roles of the gestures on the map, then, were to propose or modify or clarify routes, allowing efficient establishment of joint understanding. The most common gestures on the sketches were forms of pointing and forms of tracing. Points were often used with deictic expressions, such as “here” and “there” as well as with referring nouns, such as names of buildings. Points in a single place were sometimes repeated for emphasis. When participants suggested routes, they did so by tracing the route on the map, stopping for each collection point. Subsequent offerings of the same or slightly revised route often indicated the route by a series of points on the collection areas rather than a continuous rendering of the route. Similarly, revisions were often suggested as a series of points rather than as a smooth tracing. On the whole, speakers took turns gesturing just as they took turns speaking. Quite often, though, a listener left a finger on the map as a placeholder. For example, there were several cases where a speaker did not complete a route and the listener picked it up; in many of those cases, the original speaker left a finger pointing to the last location the speaker described. Gestures sometimes overlapped, for example, when one participant suggested an alteration of another’s route. Gesturing on the sketches, then, played a critical role in proposing, comprehending, and altering routes and thereby, in establishing the common ground necessary for effective decision making and planning.<marker type="block"/> 2.4.6. Gestures While Listening: Comprehension and Memory. Gestures in the remote condition served entirely different functions. Instead of serving as communications to partners, gestures served as communications to self. Interestingly, they often accompanied listening rather than speaking, a phenomenon rarely if ever noted in the earlier<marker type="page" number="7"/><marker type="block"/> literature. In face-to-face conversation, gestures are normally accompanied by speech, often tightly timed to speech (e. g., Clark, 2004); listeners rarely gesture. The gestures listeners in the collaborative situation used seemed to function to understand a route proposed by a partner, and to rehearse it. Frequently, when a speaker in the remote condition proposed a route, a listener traced the route on the map with discrete pointing or continuous tracing, the pointing and tracing closely timed to the speaker’s speech. The pointing or tracing seemed to serve two functions: to comprehend the proposed route and to remember it. Whether such gestures actually function to improve comprehension and memory is a topic under current investigation.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="55" page="6" column="1">6</outsider>
        <outsider class="DoCO:TextBox" type="header" id="56" page="6" column="1">J. HEINER, B. TVERSKY AND M. SILVERMAN</outsider>
        <outsider class="DoCO:TextBox" type="header" id="60" page="7" column="1">SKETCHES FOR AND FROM COLLABORATION</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="61" page="7" column="1">7</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="63" confidence="possible" page="7" column="1">3. Product of Collaboration</h1>
        <region class="DoCO:TextChunk" id="81" page="7" column="1">Better Maps in Less Time. All pairs in both conditions found efficient routes to rescue the injured. The face-to-face pairs and remote pairs were equally good in finding a route that rescued the most injured in the shortest time. However, the face-to-face group accomplished that in 25.5 minutes, compared to the remote groups’ average of 28.5 minutes. Importantly, the face-to-face groups also produced far superior maps. Producing a clear, complete, well-labeled map was part of the assignment. In a separate study, we had 16 new participants rate the effectiveness of each map produced in the collaboration experiment. They rated effectiveness on a 1-7 scale, 1 being poor and7 being excellent. Four of the five top-rated maps were produced by partners in the co-present condition. The top two campus maps, both by face-to-face collaborators, are depicted in Figure 3below. <marker type="block"/> The ratings are supported by qualitative advantages to the maps produced by co-present collaborators. The maps produced by the face-to-face groups included more landmarks that indicated where turns should be taken, more<marker type="page" number="8"/><marker type="block"/> landmarks on the paths to assure users that they are on the correct path, and more streets that were labeled. Figures 4 and 5 show examples of route maps produced by remote pairs.<marker type="block"/> The higher quality of the maps produced by face-to-face pairs of participants is evident from the examples shown here. The differences in quality of the maps produced by collaborators in the two conditions are also evident. The maps in <xref ref-type="fig" rid="F4" id="75" class="deo:Reference">Figure 4</xref> are typical. Although the remote pairs depicted the same route, the style of depiction differed dramatically, compare to <xref ref-type="fig" rid="F5" id="76" class="deo:Reference">Figure 5</xref>. The informative elegance of the maps produced by the face-to-face pairs is consistent with previous work of <xref ref-type="bibr" rid="R7" id="77" class="deo:Reference">Schwartz (1995)</xref>, who<marker type="page" number="9"/><marker type="block"/> found that students working in pairs produced superior scientific diagrams than those working alone. Working in pairs eliminated idiosyncratic and unimportant material and assured the inclusion of the essential information.</region>
        <region class="DoCO:FigureBox" id="Fx65">
          <image class="DoCO:Figure" src="62nl.page_007.image_03.png" thmb="62nl.page_007.image_03-thumb.png"/>
          <image class="DoCO:Figure" src="62nl.page_007.image_04.png" thmb="62nl.page_007.image_04-thumb.png"/>
        </region>
        <region class="unknown" id="66" page="7" column="1">Figures 3: Highest Rated Maps, Produced by Co-present Collaborators.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="68" page="8" column="1">8</outsider>
        <outsider class="DoCO:TextBox" type="header" id="69" page="8" column="1">J. HEINER, B. TVERSKY AND M. SILVERMAN</outsider>
        <region class="DoCO:FigureBox" id="F4">
          <image class="DoCO:Figure" src="62nl.page_008.image_05.png" thmb="62nl.page_008.image_05-thumb.png"/>
          <caption class="deo:Caption" id="72" page="8" column="1">Figure 4. Rescue Map Produced by Face-to-Face Pair of Participants.</caption>
        </region>
        <region class="DoCO:FigureBox" id="F5">
          <image class="DoCO:Figure" src="62nl.page_008.image_06.png" thmb="62nl.page_008.image_06-thumb.png"/>
          <caption class="deo:Caption" id="74" page="8" column="1">Figure 5. Rescue Maps Produced by a Remote Pair</caption>
        </region>
        <outsider class="DoCO:TextBox" type="header" id="79" page="9" column="1">SKETCHES FOR AND FROM COLLABORATION</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="80" page="9" column="1">9</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="82" confidence="possible" page="9" column="1">4. Sketches for and from Collaboration</h1>
        <region class="DoCO:TextChunk" id="84" page="9" column="1">How do sketches promote collaboration? We are studying this in a task in which pairs of students construct a route that will allow rescuing the largest number of injured people in the shortest distance after an earthquake on the Stanford campus. They are given a standard campus map annotated with the roads blocked off and the numbers of injured at collection spots. Collaborators either worked face-to-face or they worked remotely, side-by- side so that they could hear each other easily but could not see each other. The shared sketch promoted the collaboration in multiple ways. It served as a shared focus of attention, insuring that both partners were considering the same thing. It simplified communication by allowing efficient gestures on the sketch to convey spatial temporal information instead of cumbersome language. Thus, it allowed for rapid establishment and maintenance of common ground. The success and efficiency of communication with a shared sketch depended on interacting with the sketch using gestures. Gestures such as pointing and tracing conveyed spatial information clearly and immediately, facilitating proposing, comprehending, and revising routes. The presence of a shared sketch encouraged interactivity between the participants, enhancing their evaluation and enjoyment of the collaboration. Partners in the face-to-face condition not only looked at a shared sketch, they also produced one that depicted their assessment of the most efficient rescue route. The map they drew was a joint product, not the product of either participant. Collaborators in both conditions produced efficient rescue routes, but those in the face-to-face condition produced far better maps in far less time than those in the remote condition. The maps produced by the face-to-face condition contained more of the essential information and less of the irrelevant information. The task given collaborators was a spatial design task. Would a shared sketch facilitate collaborations on other tasks? There is good reason to think that it would. Many abstract design problems can be depicted by mapping the elements and relations of the abstract task onto visual elements and spatial relations in a sketch (e. g., <xref ref-type="bibr" rid="R8" id="83" class="deo:Reference">Tversky, 2001</xref>). Such visualizations are common to represent both structures and procedures, for example, systems design, corporate structures or procedures to pass legislation. Sketches of these turn an abstract problem into a spatial one, allowing designers to apply their experience in spatial reasoning to reasoning in an abstract domain. Thus, the virtues of a shared sketch in creating and maintaining common ground and in serving as a joint product should be effective in enhancing collaboration on abstract problems as well as concrete ones.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="85" page="10" column="1">10</outsider>
        <outsider class="DoCO:TextBox" type="header" id="86" page="10" column="1">J. HEINER, B. TVERSKY AND M. SILVERMAN</outsider>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="87" confidence="possible" page="10" column="1">Acknowledgements</h1>
        <region class="DoCO:TextChunk" id="88" page="10" column="1">This project has been supported by Office of Naval Research, Grants Number NOOO14-PP-1-O649, N000140110717 and N000140210534 to Stanford University. We are grateful to Helen Harris, Heesoo Kim, and Vince Pham for assistance in all aspects of the investigation.</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="89" confidence="possible" page="10" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="90" page="10" column="1">Alibali, M. W., Bassok, M., Olseth Solomon, K., Syc, S. E., and Goldin-Meadow, S.: 1999, Illuminating mental representation through speech and gesture, Psychological Science, 10, 327-333.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="91" confidence="possible" page="10" column="1">Goldin-Meadow, S.: 2003, Hearing gesture: How our hands help us think. Cambridge: Belknap Press.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="92" page="10" column="1">Iverson, J. and Goldin-Meadow, S.: 1997, What's communication got to do with it? Gesture in children blind from birth, Developmental Psychology, 33, 453-467.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="93" page="10" column="1">Krauss, R. M., Morrel-Samuels, P., and Colasante, C.: 1991, Do conversational hand gestures communicate? Journal of Personality and Social Psychology, 61, 743-754.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="94" confidence="possible" page="10" column="1">McNeill, D.: 1992, Hand and mind: What gestures reveal about thought. Chicago: University of Chicago Press.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="95" page="10" column="1">Rogers, W. T.: 1978, The contribution of kinesic illustrators toward the comprehension of verbal behavior within utterances. Human Communication Research, 5, 54–62.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="96" page="10" column="1">Schwartz, D. L.: 1995, The emergence of abstract representations in dyad problem solving. The Journal of the Learning Sciences, 4, 321-354.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="97" page="10" column="1">Tversky, B.: 2001, Spatial schemas in depictions, in M. Gattis (Ed), Spatial schemas and abstract thought. pp. 79-111 Cambridge: MIT Press.</ref>
        </ref-list>
      </section>
    </body>
  </article>
</pdfx>

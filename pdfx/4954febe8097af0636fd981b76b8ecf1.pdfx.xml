<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>be1df9d33b1907a611b9e15d30aecc57252d5e99e30eb39d72f3830c4e1dbd14</job>
    <base_name>62ky</base_name>
    <doi>http://dx.doi.org/10.1080/17493460601117272</doi>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <outsider class="DoCO:TextBox" type="header" id="2">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="1">http://www.tandf.no/artifact</ext-link></outsider>
      <outsider class="DoCO:TextBox" type="header" id="4">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="3">http://www.tandf.no/artifact</ext-link></outsider>
      <region class="unknown" id="5">Abstract:</region>
      <title-group>
        <article-title class="DoCO:Title" id="6">Enactments in Interaction Design: How Designers</article-title>
      </title-group>
      <region class="unknown" id="7">Make Sketches Behave</region>
      <region class="DoCO:TextChunk" id="8" confidence="possible">How do designers of interactive media work on the dynamic aspects of their designs? Previous research has emphasised the role of gestures to express what users and</region>
      <contrib-group class="DoCO:ListOfAuthors">
        <contrib contrib-type="author">
          <name id="9">Mattias Arvola</name>
        </contrib>
      </contrib-group>
      <region class="unknown" id="10">1</region>
      <contrib-group class="DoCO:ListOfAuthors">
        <contrib contrib-type="author">
          <name id="13">Henrik Artman</name>
        </contrib>
      </contrib-group>
      <footnote class="DoCO:Footnote" id="30" page="1" column="1">2 The Royal Institute of Technology (KTH)</footnote>
    </front>
    <body class="DoCO:BodyMatter">
      <region class="DoCO:TextChunk" id="12" page="1" column="1">computers do. This paper contributes with a detailed analysis of interaction designers’ <marker type="block"/> enactments in terms of what they express using a model of interaction design based on</region>
      <region class="DoCO:TextChunk" id="14" confidence="possible" page="1" column="1">five domains: design concept, functions &amp; content, structure, interaction and</region>
      <region class="unknown" id="15" page="1" column="1">1 Corresponding author</region>
      <region class="DoCO:TextChunk" id="16" page="1" column="1">presentation. Two enactive means for expression are identified: Interaction walkthrough</region>
      <region class="unknown" id="17" page="1" column="1">1 Linköpings universitet</region>
      <region class="DoCO:TextChunk" id="18" confidence="possible" page="1" column="1">and improvised role play. Gestures drive the interaction walkthrough and scenarios</region>
      <region class="unknown" id="19" page="1" column="1">Department of Information and Computer Science</region>
      <region class="DoCO:TextChunk" id="20" confidence="possible" page="1" column="1">created on the spot drive the improvised role play. In terms of the suggested model of</region>
      <region class="unknown" id="21" page="1" column="1">SE-581 83 Linköping, Sweden</region>
      <region class="DoCO:TextChunk" id="24" page="1" column="1">interaction design, interaction walkthroughs start out in the domain of interaction, and <marker type="block"/> improvised role play start out in the domain of design concept. From these domains the</region>
      <region class="unknown" id="23" page="1" column="1">Telephone: +46 13 285626</region>
      <region class="unknown" id="25" page="1" column="1">Fax: +46 13 142231</region>
      <region class="DoCO:TextChunk" id="26" confidence="possible" page="1" column="1">designer can then see consequences for the other domains of interaction design. The</region>
      <region class="unknown" id="28" page="1" column="1">E-mail: <email id="27">matar@ida.liu.se</email></region>
      <region class="DoCO:TextChunk" id="29" confidence="possible" page="1" column="1">five domains of interaction design can be used as analytical tool for thoughtful</region>
      <region class="DoCO:TextChunk" id="31" page="1" column="1">reflection, and interaction walkthroughs and improvised role play can be articulated as</region>
      <region class="DoCO:TextChunk" id="32" confidence="possible" page="1" column="1">conscious means for expression.</region>
      <region class="unknown" id="33" page="1" column="1">Computer Science and Communication SE-100 44 Stockholm, Sweden</region>
      <region class="unknown" id="34" page="1" column="1">Keywords:</region>
      <region class="unknown" id="36" page="1" column="1">E-mail: <email id="35">artman@kth.se</email></region>
      <region class="DoCO:TextChunk" id="37" confidence="possible" page="1" column="1">Design representations, Gestures, Performance, Interaction design, Means for expression, Models, Sketching</region>
      <region class="unknown" id="38" page="1" column="1">Running headline: Enactments in Interaction Design</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="39" page="1" column="2">1</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="40" page="1" column="2">2</outsider>
      <outsider class="DoCO:TextBox" type="header" id="42" page="2" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="41">http://www.tandf.no/artifact</ext-link></outsider>
      <outsider class="DoCO:TextBox" type="header" id="44" page="2" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="43">http://www.tandf.no/artifact</ext-link></outsider>
      <section class="deo:Introduction">
        <h1 class="DoCO:SectionTitle" id="45" page="2" column="1">1. Introduction</h1>
        <region class="DoCO:TextChunk" id="46" confidence="possible" page="2" column="1">The object for design in interaction design is dynamic and experiential: ways of</region>
        <region class="DoCO:TextChunk" id="49" page="2" column="1">interacting and using a system ( <xref ref-type="bibr" rid="R4" id="47" class="deo:Reference">Arvola, 2005</xref>, 2006). Designers who work in the area of<marker type="block"/> interaction design need to represent ways for people to interact, they need to represent</region>
        <region class="DoCO:TextChunk" id="50" confidence="possible" page="2" column="1">usage, and they need to represent user experiences. Sketching in interaction design accordingly differs from sketching in other domains due to the explicit focus on expressing kinaesthetic experience, interactivity, temporal aspects, tangibility,</region>
        <region class="DoCO:TextChunk" id="55" page="2" column="1">immersion, sound, and haptics ( <xref ref-type="bibr" rid="R18" id="51" class="deo:Reference">Fällman, 2003</xref>; <xref ref-type="bibr" rid="R51" id="52" class="deo:Reference">Svanæs, 2000</xref>). Sketching in interaction<marker type="block"/> design needs to be both static and temporal (<xref ref-type="bibr" rid="R35" id="54" class="deo:Reference">Löwgren, 2004</xref>). The overarching problem</region>
        <region class="DoCO:TextChunk" id="56" confidence="possible" page="2" column="1">that this paper addresses is how interaction designers express the dynamics of interaction: from user interface elements to the design concept and the business</region>
        <region class="DoCO:TextChunk" id="59" page="2" column="1">relations that surround it. A short and less analytical version of this paper was presented <marker type="block"/> at the workshop Design and semantics of form and movement—<xref ref-type="bibr" rid="R8" id="58" class="deo:Reference">DeSForM 2006</xref> (Arvola</region>
        <region class="DoCO:TextChunk" id="61" confidence="possible" page="2" column="1">&amp; <xref ref-type="bibr" rid="R7" id="60" class="deo:Reference">Artman, 2006</xref>).</region>
        <region class="DoCO:TextChunk" id="63" page="2" column="1">We will present an analysis of how collaborating designers portray interaction by taking <marker type="block"/> on the role of another person or a system component. The designers in our study create</region>
        <region class="DoCO:TextChunk" id="64" confidence="possible" page="2" column="1">a composition in combinations of motivation, actions, linguistic expressions, argumentation and graphical representations. In the following background we will cover the role of models and sketches in design,</region>
        <region class="DoCO:TextChunk" id="66" page="2" column="1">how interaction designers typically sketch interaction flows, and some research on both <marker type="block"/> planned and situated enactments to express interaction. Finally, we present a model of</region>
        <region class="DoCO:TextChunk" id="67" confidence="possible" page="2" column="1">interaction design, describing different levels of detail of the design object, which we</region>
        <region class="DoCO:TextChunk" id="68" confidence="possible" page="2" column="2">will use to analyse what collaborating interaction designers express in their situated enactments of interaction.</region>
        <region class="DoCO:TextChunk" id="69" confidence="possible" page="2" column="2">1.1 The Role of Making Models in Design</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="70" page="2" column="2">1.1 The Role of Making Models in Design</h2>
          <region class="DoCO:TextChunk" id="71" page="2" column="2">Designers always use ketches and models. When designers perform acts on their models</region>
          <region class="DoCO:TextChunk" id="76" confidence="possible" page="2" column="2">we say that they act in the action context; that is, here and now in the workplace activity (<xref ref-type="bibr" rid="R2" id="72" class="deo:Reference">Artman et al., 2005</xref>; <xref ref-type="bibr" rid="R55" id="73" class="deo:Reference">Tang, 1989</xref>). The models, however, are also representations of what will happen in the target context, in the virtual world of hypothetical user activity where a future design solution will be used (<xref ref-type="bibr" rid="R46" id="74" class="deo:Reference">Schön, 1983</xref>; <xref ref-type="bibr" rid="R56" id="75" class="deo:Reference">Tuikka, 2002</xref>).</region>
          <region class="DoCO:TextChunk" id="77" page="2" column="2">Models are also used to communicate ideas and understand the design situation (Nelson</region>
          <region class="DoCO:TextChunk" id="82" confidence="possible" page="2" column="2">and <xref ref-type="bibr" rid="R37" id="78" class="deo:Reference">Stolterman, 2003</xref>; <xref ref-type="bibr" rid="R29" id="79" class="deo:Reference">Lantz et al., 2005</xref>; <xref ref-type="bibr" rid="R52" id="80" class="deo:Reference">Sundholm et al., 2004</xref>). The understanding emerges in quick loops of making explorative design moves in the model, seeing the effects, and assessing the holistic consequences (<xref ref-type="bibr" rid="R4" id="81" class="deo:Reference">Arvola, 2005</xref>). Models and representations also satisfy the need to collaboratively propose, discuss and evaluate design. Sketching is a particularly quick way to create and assess design alternatives. As the</region>
          <region class="DoCO:TextChunk" id="83" page="2" column="2">designer sketches, the representation of a design idea creates further ideas, and helps the</region>
          <region class="DoCO:TextChunk" id="84" confidence="possible" page="2" column="2">designers to reframe their design problem. In fact, the sketch can precede the thought</region>
          <region class="DoCO:TextChunk" id="87" page="2" column="2">and hence drive the cognitive process (<xref ref-type="bibr" rid="R47" id="85" class="deo:Reference">Schön, 1987</xref>; <xref ref-type="bibr" rid="R17" id="86" class="deo:Reference">Fleming, 1998</xref>). Designers reflect</region>
          <region class="DoCO:TextChunk" id="88" confidence="possible" page="2" column="2">on their sketches in both acts of “seeing as” and acts of “seeing that” (Goldschmidt, 1991). Seeing-as stimulates new ideas, while seeing-that prompts assessment of consequences.</region>
          <outsider class="DoCO:TextBox" type="footer" id="89" page="2" column="2">3</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="90" page="2" column="2">4</outsider>
          <outsider class="DoCO:TextBox" type="header" id="92" page="3" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="91">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="94" page="3" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="93">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="95" confidence="possible" page="3" column="1">Designers tend to talk and draw simultaneously, a phenomenon called spatial-action</region>
          <region class="DoCO:TextChunk" id="98" page="3" column="1">language ( <xref ref-type="bibr" rid="R47" id="96" class="deo:Reference">Schön, 1987</xref>). The sketch as such can be seen as a material anchor (Hutchins,<marker type="block"/> 2005) for complex design concepts and their implications: it holds the design in place</region>
          <region class="DoCO:TextChunk" id="99" confidence="possible" page="3" column="1">and makes it stable enough to reason about.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="100" page="3" column="1">1.2 Sketching interaction flows In interaction design, computer prototypes are usually built to represent and</h2>
          <region class="DoCO:TextChunk" id="101" confidence="possible" page="3" column="1">In interaction design, computer prototypes are usually built to represent and</region>
          <region class="DoCO:TextChunk" id="103" page="3" column="1">communicate the dynamics of a working interactive system. Before such prototypes can <marker type="block"/> be built, however, the dynamics must be represented in other ways and state transition</region>
          <region class="DoCO:TextChunk" id="104" confidence="possible" page="3" column="1">charts are one such way.</region>
          <region class="DoCO:TextChunk" id="108" page="3" column="1">As seen in studies performed by <xref ref-type="bibr" rid="R32" id="105" class="deo:Reference">Newman and Landay (2000)</xref>, and by <xref ref-type="bibr" rid="R29" id="106" class="deo:Reference">Lantz et al. (2005)</xref><marker type="block"/> designers often use storyboards as well as navigation structures (site maps) to describe</region>
          <region class="DoCO:TextChunk" id="109" confidence="possible" page="3" column="1">the flows of users’ interactions.</region>
          <region class="DoCO:TextChunk" id="110" page="3" column="1">Site maps are one type of state-transition chart. They describe the states that are possible</region>
          <region class="DoCO:TextChunk" id="111" confidence="possible" page="3" column="1">for a given system. If we were to place users’ actions on the arrows between the web pages in the site map we would have a state transition chart. A common way to represent users’ input is to use state transition charts. In such charts, every node represents a state in the input sequence at which the user can pause or make a choice.</region>
          <region class="DoCO:TextChunk" id="116" page="3" column="1">The nodes are linked together in a directed graph by placing arrows between the nodes. <marker type="block"/> Labels placed on each arrow (or arc) represent the action performed by the user and the<marker type="block"/> result of that action. A major drawback of these charts is that they become very difficult<marker type="block"/> to read and draw as the system becomes more complex (<xref ref-type="bibr" rid="R38" id="115" class="deo:Reference">Newman &amp; Lamming, 1995</xref>).</region>
          <region class="DoCO:TextChunk" id="117" confidence="possible" page="3" column="2">State transitions, however, are not only used to describe input. They are also used to</region>
          <region class="DoCO:TextChunk" id="118" page="3" column="2">describe system output. One form such charts can take is Object State Transition Charts,</region>
          <region class="DoCO:TextChunk" id="120" confidence="possible" page="3" column="2">also known as OSTCs or ‘ostrich charts’ (<xref ref-type="bibr" rid="R38" id="119" class="deo:Reference">Newman &amp; Lamming, 1995</xref>). These charts</region>
          <region class="DoCO:TextChunk" id="121" page="3" column="2">depict the state of the user interface objects in nodes, while users’ actions are depicted</region>
          <region class="DoCO:TextChunk" id="122" confidence="possible" page="3" column="2">using labelled arrows between the states.</region>
          <region class="DoCO:TextChunk" id="123" page="3" column="2">Storyboards are visual scenarios telling a story. First developed by moviemakers trying</region>
          <region class="DoCO:TextChunk" id="124" confidence="possible" page="3" column="2">to illustrate their manuscripts, they are closely related to, and often make use of, the visual language of comics. Here the states of the story are expressed in frames and</region>
          <region class="DoCO:TextChunk" id="126" page="3" column="2">readers have to infer what happens between the frames. Sketching in interaction design <marker type="block"/> tends to take the form of storyboards, where arrows are used to express movements and</region>
          <region class="DoCO:TextChunk" id="127" confidence="possible" page="3" column="2">transitions. This fact has led several research teams to develop computer tools for</region>
          <region class="DoCO:TextChunk" id="129" page="3" column="2">storyboarding. Examples include Silk (<xref ref-type="bibr" rid="R28" id="128" class="deo:Reference">Landay &amp; Myers, 1995</xref>) CrossWeaver (Sinha &amp;</region>
          <region class="DoCO:TextChunk" id="135" confidence="possible" page="3" column="2"> <xref ref-type="bibr" rid="R49" id="130" class="deo:Reference">Landay, 2001</xref>), Anecdote (<xref ref-type="bibr" rid="R20" id="131" class="deo:Reference">Harada et al., 1996</xref>), Denim (<xref ref-type="bibr" rid="R32" id="132" class="deo:Reference">Lin et al., 2000</xref>), and Demais (<xref ref-type="bibr" rid="R10" id="133" class="deo:Reference">Bailey &amp; Konstan, 2003</xref>; <xref ref-type="bibr" rid="R11" id="134" class="deo:Reference">Bailey et al. 2001</xref>).</region>
          <region class="DoCO:TextChunk" id="136" confidence="possible" page="3" column="2">By enacting the role of users and system components, a designer can better figure out</region>
          <region class="DoCO:TextChunk" id="137" confidence="possible" page="3" column="2">how an interactive system should behave and appear to the user. One of the key</region>
          <region class="DoCO:TextChunk" id="138" confidence="possible" page="3" column="2">techniques, in the creativity technique called synectics, is personal analogies:</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="139" page="3" column="2">1.3 Planned Enactments By enacting the role of users and system components, a designer can better figure out how an interactive system should behave and appear to the user. One of the key techniques, in the creativity technique called synectics, is personal analogies: participants are encouraged to imagine what it would be like to be the system or a</h2>
          <region class="DoCO:TextChunk" id="140" confidence="possible" page="3" column="2">participants are encouraged to imagine what it would be like to be the system or a</region>
          <region class="DoCO:TextChunk" id="142" page="3" column="2">component of the system (<xref ref-type="bibr" rid="R15" id="141" class="deo:Reference">Cross, 2000</xref>). For example, what would it feel like to be the</region>
          <region class="DoCO:TextChunk" id="143" confidence="possible" page="3" column="2">garbage collector in the programming environment of LISP ? In fact, enactment, where a</region>
          <region class="DoCO:TextChunk" id="144" page="3" column="2">person acts out the performance of someone else or animates the behaviour of an object</region>
          <region class="DoCO:TextChunk" id="147" confidence="possible" page="3" column="2">has been argued to be vital in design (<xref ref-type="bibr" rid="R43" id="145" class="deo:Reference">Robertson, 1996</xref>, 1997; <xref ref-type="bibr" rid="R55" id="146" class="deo:Reference">Tang, 1989</xref>). The</region>
          <outsider class="DoCO:TextBox" type="footer" id="148" page="3" column="2">5</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="149" page="3" column="2">6</outsider>
          <outsider class="DoCO:TextBox" type="header" id="151" page="4" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="150">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="153" page="4" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="152">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="154" page="4" column="1">enactment allows a designer to create and take part in a time-based representation of an</region>
          <region class="DoCO:TextChunk" id="155" confidence="possible" page="4" column="1">activity, and others can join in this enactment.</region>
          <region class="DoCO:TextChunk" id="157" page="4" column="1">Similar enactments, but for a different purpose, are used in low-fidelity paper prototype <marker type="block"/> sessions. In such sessions the aim is to do user testing of a system that is represented on</region>
          <region class="DoCO:TextChunk" id="159" confidence="possible" page="4" column="1">paper. One person takes on the role of the computer during the session; this person displays the feedback from the computer to the user by moving pieces of paper and providing sound feedback (<xref ref-type="bibr" rid="R50" id="158" class="deo:Reference">Snyder, 2003</xref>). The purpose is to test the design by simulating to the user how the computer would behave. Enactments can also be used to test how the user would behave. Jeff Hawkins, the inventor of PalmPilot, has been said to walk around with small pieces of wood in his</region>
          <region class="DoCO:TextChunk" id="160" page="4" column="1">pocket to prototype a PDA (personal digital assistant) and discover where and when he</region>
          <region class="DoCO:TextChunk" id="163" confidence="possible" page="4" column="1">could make use of their product (<xref ref-type="bibr" rid="R45" id="161" class="deo:Reference">Sato &amp; Salvador, 1999</xref>). <xref ref-type="bibr" rid="R13" id="162" class="deo:Reference">Buchenau and Suri (2000)</xref> describe this kind of prototyping as “experience prototyping”; they highlight “the experiential aspect of whatever representations are needed to successfully (re)live or convey an experience with a product, space or system” (p. 424). The idea is for the</region>
          <region class="DoCO:TextChunk" id="164" page="4" column="1">individual to experience it personally rather than watching a demonstration or someone</region>
          <region class="DoCO:TextChunk" id="165" confidence="possible" page="4" column="1">else’s experience. If they are to experience the technology personally, designers must</region>
          <region class="DoCO:TextChunk" id="168" page="4" column="1">actively experience the subtle differences between design alternatives, and explore by <marker type="block"/> doing. Buchenau and Sari say that doing so will make it easier to grasp issues and feel<marker type="block"/> empathy with stakeholders and their experiences. Thus, designers can explore by asking</region>
          <region class="DoCO:TextChunk" id="169" confidence="possible" page="4" column="1">questions like “what would it feel like if...?” In participatory design, developers sometimes engage users, employing staged and</region>
          <region class="DoCO:TextChunk" id="170" page="4" column="1">planned performances and role play in order to try out prototypes and mock-ups. Their</region>
          <region class="DoCO:TextChunk" id="175" confidence="possible" page="4" column="2">aim is to explore usage situations in a highly engaged way and to develop empathy. These performances can take the form of improvisational theatre or staged scenarios (<xref ref-type="bibr" rid="R25" id="171" class="deo:Reference">Iacucci, Kuutti &amp; Ranta, 2000</xref>; <xref ref-type="bibr" rid="R24" id="172" class="deo:Reference">Iacucci, Iacucci &amp; Kuutti, 2002</xref>; Eden, Scharff &amp; <xref ref-type="bibr" rid="R16" id="173" class="deo:Reference">Hornecker, 2002</xref>; <xref ref-type="bibr" rid="R21" id="174" class="deo:Reference">Howard, Carroll, Murphy &amp; Peck, 2002</xref>).</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="176" page="4" column="2">1.4 Situated Enactments The above techniques for acting out interaction are all planned and structured. Other</h2>
          <region class="DoCO:TextChunk" id="177" confidence="possible" page="4" column="2">The above techniques for acting out interaction are all planned and structured. Other</region>
          <region class="DoCO:TextChunk" id="178" page="4" column="2">enactments, however, are unplanned, situated, and taken for granted. These expressions</region>
          <region class="DoCO:TextChunk" id="180" confidence="possible" page="4" column="2">of the dynamics of interaction and usage often take the form of gesture. Designers frequently use hand gestures to make references (<xref ref-type="bibr" rid="R17" id="179" class="deo:Reference">Fleming, 1998</xref>). This includes pointing to make references and gesturing to clarify or emphasize concepts</region>
          <region class="DoCO:TextChunk" id="191" page="4" column="2">(e.g. shrinking a square with the hands while asking “or can we scale the size down?”). <marker type="block"/> Gestures form an important part of the spatial-action language of designers and making<marker type="block"/> gestures is a convenient way to express the behaviour of both users and objects (Tang,<marker type="block"/> 1989; <xref ref-type="bibr" rid="R43" id="184" class="deo:Reference">Robertson, 1996</xref>; <xref ref-type="bibr" rid="R9" id="185" class="deo:Reference">Athavankar, 1999</xref>; <xref ref-type="bibr" rid="R22" id="186" class="deo:Reference">Hummels, 2000</xref>). These gestural enactments<marker type="block"/> are sometimes made in reference in relation to a text or a sketch. In themselves, gestures<marker type="block"/> and hypothetical user actions are ephemeral, and do not leave stable representations for<marker type="block"/> future scrutiny (<xref ref-type="bibr" rid="R56" id="190" class="deo:Reference">Tuikka, 2002</xref>). Performing sequences of collaborative enactments is one</region>
          <region class="DoCO:TextChunk" id="194" confidence="possible" page="4" column="2">way to explore ideas and share knowledge (<xref ref-type="bibr" rid="R12" id="192" class="deo:Reference">Bekker et al., 1995</xref>; <xref ref-type="bibr" rid="R62" id="193" class="deo:Reference">Wulff et al., 1990</xref>).</region>
          <region class="DoCO:TextChunk" id="195" page="4" column="2">They create a lived experience for the actor that also can be seen and assessed by others.</region>
          <region class="DoCO:TextChunk" id="197" confidence="possible" page="4" column="2">This helps the design team focus on what the user is doing at all stages in the design (<xref ref-type="bibr" rid="R43" id="196" class="deo:Reference">Robertson, 1996</xref>).</region>
          <region class="DoCO:TextChunk" id="199" page="4" column="2">For example, <xref ref-type="bibr" rid="R12" id="198" class="deo:Reference">Bekker et al. (1995)</xref> describe how designers illustrate how customers at an</region>
          <region class="DoCO:TextChunk" id="200" confidence="possible" page="4" column="2">automatic post office placed packages on a scale, punching in numbers and sticking</region>
          <outsider class="DoCO:TextBox" type="footer" id="201" page="4" column="2">7</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="202" page="4" column="2">8</outsider>
          <outsider class="DoCO:TextBox" type="header" id="204" page="5" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="203">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="206" page="5" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="205">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="207" confidence="possible" page="5" column="1">postage stickers onto the box, before putting the box in the bin. Using gestures, they illustrated opening and closing of doors and other actions, and often moved around while gesturing. The gestures occurred in relation to the spatial arrangements of the</region>
          <region class="DoCO:TextChunk" id="208" page="5" column="1">participants and work objects, and some gestures persisted throughout the meeting, even</region>
          <region class="DoCO:TextChunk" id="209" confidence="possible" page="5" column="1">though they referred to imaginary objects. In analyses of cognitive practices, it has been shown that gestures can be means for mapping the invisible and untouchable to concrete experiences. A sketch makes an</region>
          <region class="DoCO:TextChunk" id="214" page="5" column="1">abstract idea, of for example user behaviour or product operations, more concrete, and a <marker type="block"/> gesture is made in reference to this static representation. Then the once-abstract object<marker type="block"/> becomes dynamic as it is construed as being in motion. People use gesture to enhance<marker type="block"/> the embodied experience of a representation. Bodily engagement can be used to reason<marker type="block"/> about how two static representations are related to each other. In such a process, gesture</region>
          <region class="DoCO:TextChunk" id="217" confidence="possible" page="5" column="1">often ties together different representations into larger schematic units, marking out potential dependencies between representations. (Ala! and <xref ref-type="bibr" rid="R1" id="215" class="deo:Reference">Hutchins, 2004</xref>) When people try to understand a dynamic process, they frequently make referential displacements, where they personalize inanimate objects (<xref ref-type="bibr" rid="R41" id="216" class="deo:Reference">Ochs et al., 1996</xref>). Graphic</region>
          <region class="DoCO:TextChunk" id="219" page="5" column="1">representations then provide a cognitive and spatial domain to inhabit and move around <marker type="block"/> in. By using gestures in a graphic space people can symbolically re-enact events in front</region>
          <region class="DoCO:TextChunk" id="220" confidence="possible" page="5" column="1">of each other in a collaborative thinking-through process.</region>
          <region class="DoCO:TextChunk" id="221" page="5" column="1">Graphical representations play a key role in such a process, in that they can be treated</region>
          <region class="DoCO:TextChunk" id="223" confidence="possible" page="5" column="1">them as stages on which people can collaboratively dramatize their understanding. In these dramatizations one team member may in fact act as choreographer for another team member’s enactment (<xref ref-type="bibr" rid="R40" id="222" class="deo:Reference">Ochs et al. 1994</xref>).</region>
          <region class="DoCO:TextChunk" id="224" page="5" column="2">Based on previous research that has indicated that kinetic gestures and enactment play</region>
          <region class="DoCO:TextChunk" id="230" confidence="possible" page="5" column="2">an important role in exploring how a product is used (<xref ref-type="bibr" rid="R55" id="225" class="deo:Reference">Tang, 1989</xref>; <xref ref-type="bibr" rid="R62" id="226" class="deo:Reference">Wulff et al., 1990</xref>; <xref ref-type="bibr" rid="R43" id="227" class="deo:Reference">Robertson, 1996</xref>, 1997; <xref ref-type="bibr" rid="R12" id="228" class="deo:Reference">Bekker et al., 1995</xref>; Athawankar, 1999; <xref ref-type="bibr" rid="R56" id="229" class="deo:Reference">Tuikka, 2002</xref>;</region>
          <region class="DoCO:TextChunk" id="232" page="5" column="2"> <xref ref-type="bibr" rid="R22" id="231" class="deo:Reference">Hummels, 2000</xref>), we decided to analyse what it is that interaction designers are enacting</region>
          <region class="DoCO:TextChunk" id="235" confidence="possible" page="5" column="2">with their kinetic gestures. In this analysis we also draw on discussions from practice studies of cognitive activity (Ala! and <xref ref-type="bibr" rid="R1" id="233" class="deo:Reference">Hutchins, 2004</xref>; <xref ref-type="bibr" rid="R41" id="234" class="deo:Reference">Ochs, 1996</xref>; 1994).</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="236" page="5" column="2">1.5 Domains in Interaction Design To analyse what it is that interaction designers express with kinetic gestures, we</h2>
          <region class="DoCO:TextChunk" id="237" confidence="possible" page="5" column="2">To analyse what it is that interaction designers express with kinetic gestures, we</region>
          <region class="DoCO:TextChunk" id="241" page="5" column="2">developed a model built on the idea of interaction design as being performed in several <marker type="block"/> domains at different levels of detail. Several models of interaction design conceptualize<marker type="block"/> different levels of detail. One can, for example, think of the object for interaction design<marker type="block"/> in terms of the three levels from activity theory: activity, action, and operations (Arvola,</region>
          <region class="DoCO:TextChunk" id="243" confidence="possible" page="5" column="2">2005). <xref ref-type="bibr" rid="R58" id="242" class="deo:Reference">Van Welie and van der Veer (2003)</xref> suggest interaction design patterns at the</region>
          <region class="DoCO:TextChunk" id="245" page="5" column="2">levels of business goals, posture, user experience, task, and action. Design patterns have <marker type="block"/> also been thought of at the levels of environments for interaction, means for interaction,</region>
          <region class="DoCO:TextChunk" id="248" confidence="possible" page="5" column="2">and interfaces for interaction (<xref ref-type="bibr" rid="R6" id="246" class="deo:Reference">Arvola, 2006</xref>). The domains we use in this article divide up the design space slightly differently compared to the models presented above. We draw on information design as well as architecture (<xref ref-type="bibr" rid="R61" id="247" class="deo:Reference">Woolman, 2002</xref>) and expand on the process of interactive design as</region>
          <region class="DoCO:TextChunk" id="250" page="5" column="2">described by <xref ref-type="bibr" rid="R27" id="249" class="deo:Reference">Kristof and Satran (1995)</xref>. Our model includes the five elements of design</region>
          <region class="DoCO:TextChunk" id="251" confidence="possible" page="5" column="2">concept, function and content, structure, interaction, and presentation. • Design concept can be thought of as the design idea in terms of its purpose and intended use. This is what the product should do and be; it includes the</region>
          <outsider class="DoCO:TextBox" type="footer" id="252" page="5" column="2">9</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="253" page="5" column="2">10</outsider>
          <outsider class="DoCO:TextBox" type="header" id="255" page="6" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="254">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="257" page="6" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="256">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="263" confidence="possible" page="6" column="1">definition of its audience and users. The character of the system (<xref ref-type="bibr" rid="R3" id="258" class="deo:Reference">Arvola, 2003</xref>, 2005), the dynamic gestalt (<xref ref-type="bibr" rid="R35" id="259" class="deo:Reference">Löwgren &amp; Stolterman, 2004</xref>), the genre (Lundberg, 2004), and the posture (<xref ref-type="bibr" rid="R14" id="260" class="deo:Reference">Cooper et al., 2003</xref>; van <xref ref-type="bibr" rid="R58" id="261" class="deo:Reference">Welie &amp; van der Veer, 2003</xref>) are all elements of the design concept. • Function and content are the functions and the information content needed to fulfil the purpose and intended use of the design concept. This is equivalent to the object-action model of the system (e.g. <xref ref-type="bibr" rid="R48" id="262" class="deo:Reference">Shneiderman &amp; Plaisant, 2004</xref>). • Structure is the arrangement and organisation of functions and content. The structure can be flat or deep. It can be hierarchical, networked, linear, or circular. Things like task structures, flow charts, and site maps belong to this domain. • Interaction is how the user interacts with the functions and contents and how he or she navigates in the structure to make use of functions, access or manipulate content, and fulfil the intended use. Interaction styles such as forms, menus, and direct manipulation, and interaction techniques such as zooming, panning, and point-and-click, as well as controls and interaction devices, are all parameters of this domain. • Presentation is the look and feel of the product. This is what meets the senses of the user and this is what needs to be interpreted in the situation of use. This is the graphical part of a graphical user interface. Issues of style and layout become important here.</region>
          <region class="DoCO:TextChunk" id="264" confidence="possible" page="6" column="2">The five domains described above can be thought of as being at different levels of detail in the interactive system that is being designed. In this paper, we use them to analyse what the interaction designers are expressing and enacting in their kinetic gestures.</region>
        </section>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="265" confidence="possible" page="6" column="2">2 Method</h1>
        <region class="DoCO:TextChunk" id="285" page="6" column="2">This study reports a detailed analysis of a four-hour design workshop with four master’s <marker type="block"/> students in interaction design. This particular workshop is part of a series of workshops<marker type="block"/> with students performing and learning interaction design. In total, the empirical material<marker type="block"/> supporting co-located collaborative work. It is used both as a learning facility and as an<marker type="block"/> screen, also touch-sensitive. This interactive table is large enough for up to eight people<marker type="block"/> to sit around it. In one corner of the room a smaller table and three chairs are placed in<marker type="block"/> front of a wall-mounted plasma display, enabling a part of the group to work separately.<marker type="page" number="7"/><marker type="column" number="1"/><marker type="block"/> Because there are many computers in the room and users can also bring their personal</region>
        <region class="unknown" id="269" page="6" column="2">is encompassed by approximately 20 hours of video recordings made using multiple cameras. Our studies took place at the Royal Institute of Technology in Kista where an interactive space called the iLounge was designed and built with the purpose of</region>
        <region class="unknown" id="271" page="6" column="2">experimental research facility. Two large touch-sensitive displays (smartboards) are built into a wall. In front of this wall is a table with a horizontally embedded plasma</region>
        <region class="unknown" id="276" page="6" column="2"> <xref ref-type="fig" rid="F1" id="275" class="deo:Reference">Figure 1</xref> shows a plan of the room. The room has a wireless network and contains laptop computers with a wireless LAN card. The keyboards and mice in the room are also wireless, using Bluetooth. Finally, the iLounge contains high-quality audio and video equipment that can be used for videoconferences, or during user studies.</region>
        <outsider class="DoCO:TextBox" type="footer" id="277" page="6" column="2">11</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="278" page="6" column="2">12</outsider>
        <outsider class="DoCO:TextBox" type="header" id="280" page="7" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="279">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="header" id="282" page="7" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="281">http://www.tandf.no/artifact</ext-link></outsider>
        <region class="DoCO:FigureBox" id="F1">
          <image class="DoCO:Figure" src="62ky.page_007.image_01.png" thmb="62ky.page_007.image_01-thumb.png"/>
          <caption class="deo:Caption" id="284" page="7" column="1">Figure 1. Blueprint of the room.</caption>
        </region>
        <region class="DoCO:TextChunk" id="286" confidence="possible" page="7" column="1">artefacts into the room, it is not at all obvious how information is shared between the</region>
        <region class="DoCO:TextChunk" id="289" page="7" column="1">different work surfaces. To facilitate and support work in the iLounge most research so <marker type="block"/> far has focused on developing services that support the user in moving data between the<marker type="block"/> devices present in the room. Tipple 1 is a service that can be used to open any file on any</region>
        <region class="DoCO:TextChunk" id="290" confidence="possible" page="7" column="1">other computer that runs the Tipple service. Its interface shows icons representing all the other computers running the service. A user who wants to open a file on another computer can drag the file icon to the icon representing the other computer; an early</region>
        <region class="DoCO:TextChunk" id="293" page="7" column="1">prototype is described in <xref ref-type="bibr" rid="R59" id="291" class="deo:Reference">Werle et al. (2001)</xref>. The service Multibrowse allows the user<marker type="block"/> to move web content between displays in the room. By right-clicking a page or a link, a</region>
        <region class="DoCO:TextChunk" id="295" confidence="possible" page="7" column="1">user can “multibrowse” it either to or from its present location; see Johanson et al. (2001) for a more thorough description. PointRight makes it possible to use the same 1 Tipple is being developed by the FUSE group, Stockholm University/ Royal Institute of Technology, and can be downloaded at <ext-link ext-link-type="uri" href="http://www.dsv.su.se/fuse/downloads.htm" id="294">http://www.dsv.su.se/fuse/downloads.htm</ext-link></region>
        <region class="DoCO:TextChunk" id="298" page="7" column="2">pointing device or keyboard on more than one computer in the room. When the pointer <marker type="block"/> between computers in the space. The text is placed on a clipboard that is shared by the</region>
        <region class="unknown" id="297" page="7" column="2">reaches the border of the screen it continues on the screen next to it that also has the service. By using PointRight together with iClipboard, a user can cut or copy text</region>
        <region class="unknown" id="299" page="7" column="2">computers running the service. 2 In the study reported on in this paper we also introduced some Smart Technologies services to the participants, specifically the virtual keyboard and Smart Notebook. Smart Notebook is an electronic whiteboard application that allows the user to create documents containing typed text, hand-written text, and pictures. The document is visualized as a book with pages.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="300" page="7" column="2">2.1 Procedure Four master’s students in interaction design, two male and two female, were invited to iLounge. They all knew each other well, having taken the same courses for four years. The two female students were given a design brief asking them to design an interactive space to be used for studio classes. The two male students were given a brief asking them to design a drawing tool for an interactive digital whiteboard. The briefs thus pointed towards design solutions in the direction of the iLounge they were to visit and experience. Our idea was that they were to seriously consider how they would like such an environment to be structured, and thus come up with ideas about how iLounge could be improved.</h2>
          <region class="unknown" id="302" page="7" column="2">2 Multibrowse, Pointright and iClipboard are part of the iWork package being developed by the Interactive Workspaces at Stanford University. The iWork services can be downloaded at <ext-link ext-link-type="uri" href="http://iwork.stanford.edu/download.shtml." id="301">http://iwork.stanford.edu/download.shtml.</ext-link></region>
          <outsider class="DoCO:TextBox" type="footer" id="303" page="7" column="2">13</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="304" page="7" column="2">14</outsider>
          <outsider class="DoCO:TextBox" type="header" id="306" page="8" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="305">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="308" page="8" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="307">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="309" confidence="possible" page="8" column="1">The participants had worked individually on their designs before coming to iLounge.</region>
          <region class="DoCO:TextChunk" id="310" page="8" column="1">During the visit to iLounge they synthesized their individual design work with the work</region>
          <region class="DoCO:TextChunk" id="311" confidence="possible" page="8" column="1">of the other design student who had been given the same brief. Then presented their</region>
          <region class="DoCO:TextChunk" id="314" page="8" column="1">collective ideas to the two other students and ran a critique session. After these sessions <marker type="block"/> we conducted an evaluation of the iLounge studio and what they thought about working<marker type="block"/> there. During the first hour, an introduction to iLounge was given. Each group then used</region>
          <region class="DoCO:TextChunk" id="315" confidence="possible" page="8" column="1">about thirty minutes each to synthesize their designs and about ten minutes to present their ideas; the critique session took about ten to fifteen minutes for each pair. The evaluation was performed during the following hour. We recorded all sessions using both audio and video from multiple cameras. No</region>
          <region class="DoCO:TextChunk" id="316" page="8" column="1">interventions were made during the sessions, except during the evaluation, which was</region>
          <region class="DoCO:TextChunk" id="317" confidence="possible" page="8" column="1">facilitated.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="318" page="8" column="1">2.2 Analysis After we gathered the data, we analyzed it together. The focus of our analysis was on</h2>
          <region class="DoCO:TextChunk" id="319" confidence="possible" page="8" column="1">After we gathered the data, we analyzed it together. The focus of our analysis was on</region>
          <region class="DoCO:TextChunk" id="320" page="8" column="1">the gestures and dramatizations (i.e. enactments) of their design proposals. During the</region>
          <region class="DoCO:TextChunk" id="321" confidence="possible" page="8" column="1">analysis we interpreted the enactments and their performatives. We also traced our</region>
          <region class="DoCO:TextChunk" id="322" page="8" column="1">interpretations of events in the synthesis sessions to events in the presentation sessions.</region>
          <region class="DoCO:TextChunk" id="323" confidence="possible" page="8" column="1">All verbal utterances and gestures were transcribed in our native language (Swedish).</region>
          <region class="DoCO:TextChunk" id="326" page="8" column="1">We then analyzed the transcriptions further as we engaged with them theoretically using <marker type="block"/> previous research and the five domains of interaction design (design concept, functions<marker type="block"/> &amp; content, structure, interaction and presentation), and only then did we translate them</region>
          <region class="DoCO:TextChunk" id="327" confidence="possible" page="8" column="1">into English.</region>
        </section>
      </section>
      <section class="deo:Results">
        <h1 class="DoCO:SectionTitle" id="328" page="8" column="2">3. Results</h1>
        <region class="DoCO:TextChunk" id="329" confidence="possible" page="8" column="2">In this section we describe how the designers enacted their design sketches using</region>
        <region class="DoCO:TextChunk" id="331" page="8" column="2">gestures to make them behave. Often they incorporated these enactments within acts of <marker type="block"/> speech, but, as we will see, the enactments had no signifying word or verbal counterpart</region>
        <region class="DoCO:TextChunk" id="332" confidence="possible" page="8" column="2">during the sessions. The enactments enhanced what the designers wanted to</region>
        <region class="DoCO:TextChunk" id="335" page="8" column="2">communicate, much in the same way that sketches provide simplified visualizations of a <marker type="block"/> complex and dynamic design proposal. In this section we present examples of how such<marker type="block"/> communicative enactments are performed and what domains of interaction design they</region>
        <region class="DoCO:TextChunk" id="336" confidence="possible" page="8" column="2">represent.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="337" page="8" column="2">3.1 Gestures Expressing Interaction and Design Concept</h2>
          <region class="DoCO:TextChunk" id="338" page="8" column="2">The two women, whom we will call Anna and Barbara, had the assignment of designing</region>
          <region class="DoCO:TextChunk" id="339" confidence="possible" page="8" column="2">an interactive space using different digital resources. They started their synthesis</region>
          <region class="DoCO:TextChunk" id="340" page="8" column="2">session by quickly examining their sketches and summarizing their basic ideas about an</region>
          <region class="DoCO:TextChunk" id="341" confidence="possible" page="8" column="2">interactive space. They had two basic ideas: that users needed plenty of space for</region>
          <region class="DoCO:TextChunk" id="343" page="8" column="2">sketches and that they needed space for both individual and collective activities. They <marker type="block"/> were quite surprised that their sketches coincided. One of them, Anna, quickly took on</region>
          <region class="DoCO:TextChunk" id="344" confidence="possible" page="8" column="2">the role of sketching on the smartboard and Barbara took on being the discussant:</region>
          <region class="DoCO:TextChunk" id="345" page="8" column="2">structuring the process of synthesizing the design by suggesting themes and discussing</region>
          <region class="DoCO:TextChunk" id="346" confidence="possible" page="8" column="2">individual design proposals as well as documenting ideas. Anna generally expressed herself using many gestures, while Barbara was more modest with her gestures.</region>
          <region class="DoCO:TextChunk" id="348" page="8" column="2">Barbara suggested that to structure the process they should start off by sketching things <marker type="block"/> that would not need to be mobile, “like whiteboards etc.” In Excerpt 1 we see how she</region>
          <outsider class="DoCO:TextBox" type="footer" id="349" page="8" column="2">15</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="350" page="8" column="2">16</outsider>
          <outsider class="DoCO:TextBox" type="header" id="352" page="9" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="351">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="354" page="9" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="353">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="358" confidence="possible" page="9" column="1">was abruptly interrupted by Anna who vividly presented an idea about a mobile whiteboard. Excerpt 1. Group 1, Synthesis session. The tilting <xref ref-type="table" rid="T3" id="355" class="deo:Reference">table 3</xref> Time Person Transcript of interaction Characteristic of action Domain 0.10.27 1 Anna Some of these come on small Stands up and vividly Interaction, stands with wheels. [Barbara: enacts a “tilting table” Structure, OK] It depends on, I don’t with her arms: Holds Design know, it depends on how the arms straight out with concept transmission works, but if there one hand vertically are many sockets then you can positioned under the put it in different places... or at other. Moves hands in a least slant it so it depends on if curve downwards so they are permanent like these or that they are not. horizontally positioned in respect to each other. (See <xref ref-type="fig" rid="F2" id="356" class="deo:Reference">Figure 2</xref>-7 below for a similar enactment later in the conversation.) 2 Barbara For the whiteboard then.. Sits down and documents some of the ideas they have suggested. 3 Anna Yes, like those old stands like While saying, “curtain Interaction those old rolling blackboards at the theatre,” she [Barbara: uh huh, OK] that you walks like she is pulling could move like a curtain at the the curtain. theatre. 4 Barbara Could you make them work that She makes a gesture Interaction way too? indicating a table that can be tilted. 5 Anna I don’t know, but it would be cool. 6 Barbara It would be cool [writes] I’ll Documenting some of write work area the discussion. 7 Anna Write: for different purposes. Design concept 3 The transcriptions are divided following the work of <xref ref-type="bibr" rid="R42" id="357" class="deo:Reference">Pomerantz and Fehr (1997)</xref>. In our study, however, “characteristic of action” describes the actor’s action, not the abstraction of the utterances.</region>
          <region class="DoCO:TextChunk" id="359" page="9" column="2">Although Barbara suggested starting off with non-mobile furniture the discussion then</region>
          <region class="DoCO:TextChunk" id="360" confidence="possible" page="9" column="2">focused on Anna’s idea of a mobile smartboard that can be tilted. By demonstrating</region>
          <region class="DoCO:TextChunk" id="361" page="9" column="2">how a smartboard can be slanted from a vertical to a horizontal position Anna enacted</region>
          <region class="DoCO:TextChunk" id="362" confidence="possible" page="9" column="2">the interaction, which was closely connected to the purpose of their design concept. First, in turn 1, Anna waved her arms to act out how it should be possible to slant the</region>
          <region class="DoCO:TextChunk" id="363" page="9" column="2">smartboard, and in turn 3, she makes an act of seeing-as where the smartboards can be</region>
          <region class="DoCO:TextChunk" id="364" confidence="possible" page="9" column="2">pulled along like a curtain. In turn 4, Barbara made a mirroring tilting gesture. In this</region>
          <region class="DoCO:TextChunk" id="366" page="9" column="2">gesture she both experienced the interaction of tilting the board, and affirmed that she <marker type="block"/> understood the concept. They both found this idea very appealing. Anna, however, also</region>
          <region class="DoCO:TextChunk" id="367" confidence="possible" page="9" column="2">considered the structure and construction of such an artefact.</region>
          <region class="DoCO:TextChunk" id="368" page="9" column="2">In terms of the five domains of interaction design (design concept, functions &amp; content,</region>
          <region class="DoCO:TextChunk" id="369" confidence="possible" page="9" column="2">structure, interaction, and presentation) the designers start out from expressing interaction in the gestural enactment (the tilting). They immediately see that there are consequences for the structural domain (how transmissions work), and the design concept (with the purpose of providing flexibility). In the next gestural enactment the see the smartboard as a curtain, and combine that with the tilting to make complex</region>
          <region class="DoCO:TextChunk" id="370" page="9" column="2">hypothetical user actions and object behaviour. Finally, they make the connection back</region>
          <region class="DoCO:TextChunk" id="371" confidence="possible" page="9" column="2">again to the design concept domain by seeing that there are positive consequences (when Anna says, “Write: for different purposes”).</region>
          <region class="DoCO:TextChunk" id="372" page="9" column="2">About 15 minutes later, while they were discussing and summarizing their synthesized</region>
          <region class="DoCO:TextChunk" id="373" confidence="possible" page="9" column="2">design proposal they returned to the enactment of the tilting table. During the process said had said that they should denote different aspects of the properties in the room</region>
          <outsider class="DoCO:TextBox" type="footer" id="374" page="9" column="2">17</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="375" page="9" column="2">18</outsider>
          <outsider class="DoCO:TextBox" type="header" id="377" page="10" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="376">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="379" page="10" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="378">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="382" confidence="possible" page="10" column="1">using different colours: blue was to denote technology. Excerpt 2 presents what they said and Figures 2 through 7 depicts the enactments in a picture sequence. Excerpt 2. Group 1, Synthesis session. The tilting table, continued Time 0.18.36 Person Transcript of interaction Characteristic of action 1 Anna Okay, but then I’ll draw them in blue as Reaches for the smartboard they are technology. pen and moves towards the smartboard. 2 Barbara The tables? Are they technology? 3 Anna Well...the... Physically represents a tilting table (<xref ref-type="fig" rid="F2" id="380" class="deo:Reference">Figure 2</xref>-5) 4 Barbara Uhuh, those ..yes Mirrors the enactment (<xref ref-type="fig" rid="F5" id="381" class="deo:Reference">Figure 5</xref>-7)</region>
          <region class="DoCO:FigureBox" id="Fx383">
            <image class="DoCO:Figure" src="62ky.page_010.image_02.png" thmb="62ky.page_010.image_02-thumb.png"/>
          </region>
          <region class="DoCO:TextChunk" id="386" confidence="possible" page="10" column="2"> <xref ref-type="fig" rid="F2" id="384" class="deo:Reference">Figure 2</xref>-7. Sequence showing the enactment of “the tilting table.” In <xref ref-type="fig" rid="F2" id="385" class="deo:Reference">Figure 2</xref>-5, Anna waves her arms to enact “the tilting table” and in Figure 6-7, Barbara mirrors the enactment. When Anna suggested that she draw the tables into their design sketch using the blue pen to denote technology, Barbara did not understand why the tables should be denoted with blue. This misunderstanding is reasonable as they had been discussing both tables in the sense of ordinary designed tables and an enacted “tilting” smartboard. When Barbara asked whether the tables counted as technology, Anna answered by again enacting the tilting table; this helped Barbara understand, and she then mirrored the</region>
          <outsider class="DoCO:TextBox" type="footer" id="387" page="10" column="2">19</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="388" page="10" column="2">20</outsider>
          <outsider class="DoCO:TextBox" type="header" id="390" page="11" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="389">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="392" page="11" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="391">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="393" confidence="possible" page="11" column="1">tilting with her arms. Still they had not given this table/board a name or label. The tilting table existed only in the enactment that the two designers shared.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="394" page="11" column="1">3.2 Gestures Expressing Interaction and Presentation</h2>
          <region class="DoCO:TextChunk" id="395" page="11" column="1">The two men, whom we will call Christian and Daniel, had the assignment of designing</region>
          <region class="DoCO:TextChunk" id="396" confidence="possible" page="11" column="1">a drawing tool for a smartboard. Their synthesis session started directly, as they</region>
          <region class="DoCO:TextChunk" id="399" page="11" column="1">discussed differences between traditional whiteboards and a digital counterpart in terms <marker type="block"/> of affordances. Christian went to the smartboard and started up the installed sketchpad,<marker type="block"/> and then sat down to listen to Daniel. Daniel first explained his view of the differences</region>
          <region class="DoCO:TextChunk" id="400" confidence="possible" page="11" column="1">in what it is possible to do with a traditional whiteboard. They both pointed to the object-centred character of the digital whiteboard (that the user works with drawn</region>
          <region class="DoCO:TextChunk" id="401" page="11" column="1">objects rather than with pen strokes). In excerpt 3, we see how Daniel went goes to the</region>
          <region class="DoCO:TextChunk" id="402" confidence="possible" page="11" column="1">smartboard and presented his idea about the differences. Figure 8 is embedded in the excerpt in order to put it in context. Excerpt 3. Group 2, Synthesis session. Naturally not natural Time Person Transcript of Characteristic of action Domain 0.02.51 interaction</region>
          <region class="unknown" id="403" page="11" column="1">1 Daniel</region>
          <region class="unknown" id="404" page="11" column="1">Interaction, Presentation</region>
          <region class="DoCO:FigureBox" id="F8">
            <image class="DoCO:Figure" src="62ky.page_011.image_03.png" thmb="62ky.page_011.image_03-thumb.png"/>
            <caption class="deo:Caption" id="406" page="11" column="1">Figure 8. Presents his argument by making a sketch of how one does not do it</caption>
          </region>
          <region class="unknown" id="407" page="11" column="1">Because when you.... When you draw then...you know, this is not natura...it’s not natural. I must put this pen away then take my finger and drag this. You know, I do this only because I know I can put away the pen and use my finger as a mouse naturally so to speak [#1:yes]</region>
          <region class="unknown" id="408" page="11" column="2">2 Christian But at the same time I think that it is like.. 3 Daniel But it’s good that Continues to demonstrate how users would Interaction you can do that as behave if it is an object. 4 Christian Did you have any alternative, or 5 Daniel No, not really, I Interaction just thought that you might have a tool to use? as a mouse...</region>
          <region class="DoCO:TextChunk" id="411" page="11" column="2">Their preliminary and quite spontaneous analysis of the differences between traditional <marker type="block"/> and digital whiteboards was clearly connected to their enactment of interaction. In fact,<marker type="block"/> the enactments drove the analysis, moving it from an abstract and analytical perspective</region>
          <region class="DoCO:TextChunk" id="412" confidence="possible" page="11" column="2">on the differences in affordances, to the concrete and physical behavior of this actual digital whiteboard. By exploring this analysis of affordances at the same time that he explored the actual smartboard Daniel dramatized a type of user behaviour: a</region>
          <region class="DoCO:TextChunk" id="414" page="11" column="2">designer’s think-aloud exploration. This enactment also took place on the presentation <marker type="block"/> level, since the designers explored the feel of the smartboard. In this case it did not feel</region>
          <region class="DoCO:TextChunk" id="415" confidence="possible" page="11" column="2">natural. Christian, who was sitting down, was more distant in his attempts to take the floor, but Daniel was so engaged in his explorative dramatization that he seemed to more or less ignore Christian’s initiatives. When Christian prompted Daniel to think</region>
          <region class="DoCO:TextChunk" id="417" page="11" column="2">about whether he had an alternative idea about interacting, the discussion ended with a <marker type="block"/> blunt no, with Daniel’s extension that maybe it all could have been done with a mouse.</region>
          <region class="DoCO:TextChunk" id="418" confidence="possible" page="11" column="2">The explorative dramatization might have made Daniel a bit disillusioned about how one can interact with the smartboard as he reverted to an almost mundane form of interaction.</region>
          <outsider class="DoCO:TextBox" type="footer" id="419" page="11" column="2">21</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="420" page="11" column="2">22</outsider>
          <outsider class="DoCO:TextBox" type="header" id="422" page="12" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="421">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="424" page="12" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="423">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="425" confidence="possible" page="12" column="1">Turning to the five domains of interaction design, we see that the gestural enactment here also started in the domain of interaction, and this time the designers were seeing that it had consequences for the presentation (it did not feel natural).</region>
          <region class="DoCO:TextChunk" id="426" confidence="possible" page="12" column="1">In the following excerpt we exemplify how the two male designers explored the</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="427" page="12" column="1">3.3 Improvised Role Play Expressing Design Concept In the following excerpt we exemplify how the two male designers explored the different uses of the actual smartboards in order to design them to be used for</h2>
          <region class="DoCO:TextChunk" id="428" confidence="possible" page="12" column="1">different uses of the actual smartboards in order to design them to be used for</region>
          <region class="DoCO:TextChunk" id="429" page="12" column="1">collaborative purposes. It is striking that the pair started to dramatize their work using</region>
          <region class="DoCO:TextChunk" id="430" confidence="possible" page="12" column="1">other voices, as if to explicitly express that someone else (the user) would say and act</region>
          <region class="DoCO:TextChunk" id="431" page="12" column="1">out what they think. These forms of voice dramatization quickly turned into examples</region>
          <region class="DoCO:TextChunk" id="432" confidence="possible" page="12" column="1">of what each speaker wanted to do. In turn, the two amplified and enhanced these examples as they engaged in enactments, trying to do what they anticipated the users doing; see Excerpt 4. Here Daniel concluded by describing the concept of the traditional whiteboard. Figure 9 depicts the two designers taking on the role of the users. Excerpt 4. Group 2, Synthesis session. You sketch there and I sketch here Time Person Transcript of Characteristic of action Domain 0.05.40 interaction</region>
          <region class="unknown" id="433" page="12" column="1">1 Daniel</region>
          <region class="unknown" id="434" page="12" column="1">Design concept</region>
          <region class="unknown" id="435" page="12" column="1">But I think it’s, what I think is a bit difficult about this is that we absolutely cannot work at the same time. Think of if I were to like ”But check this out, then we cannot have that there...”</region>
          <region class="DoCO:FigureBox" id="F9">
            <image class="DoCO:Figure" src="62ky.page_012.image_04.png" thmb="62ky.page_012.image_04-thumb.png"/>
            <caption class="deo:Caption" id="437" page="12" column="1">Figure 9: Both designers are working together in vividly dramatizing the users’</caption>
          </region>
          <region class="DoCO:TextChunk" id="438" confidence="possible" page="12" column="2">behaviours. 2 Christian Exactly. If we do that then I would come and say, ”but this should be here”, but you will say “no it should be here.” 3 Daniel “But, we do like this”.. hang on... wait a moment.. 4 Christian Then I want to at Functions &amp; the same time, and content want to move these... 5 Daniel Exactly...or you Structure want to draw... Say you want to draw down in the corner... 6 Christian There you have Starts enacting several scenarios of this Design the advantage collective sketching situation. concept with the whiteboard. Okay, then you sketch there and I sketch here... This episode of dramatization is interesting in that both designers cooperated in the drama; Christian followed Daniel, playing along with his initiatives. In the earlier excerpts, we also saw that the female designers were playing along, but they mirrored each other’s enactments rather than one taking a distinct lead. In this session the two designers cooperate and play along, using both gestures and voice in taking on the roles of users. These short role playing sessions evolve into a discussion of what target context the user would be in. They explore the concept of cooperative sketching by role playing. Again, this can be analysed using the five domains of interaction design. This time, the enactment does not start in the domain of interaction. Instead it starts in the domain of the design concept: the need to be able to work at the same time. In their enactment they</region>
          <outsider class="DoCO:TextBox" type="footer" id="439" page="12" column="2">23</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="440" page="12" column="2">24</outsider>
          <outsider class="DoCO:TextBox" type="header" id="442" page="13" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="441">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="444" page="13" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="443">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="445" page="13" column="1">continue by moving from the domain of design concept to the domain of functions and</region>
          <region class="DoCO:TextChunk" id="446" confidence="possible" page="13" column="1">content (when they identify functions like move and draw). In the next moment they have seen consequences in the domain of structure (one person works in one corner while the other works in the other corner). At this stage they see the benefit of the whiteboard, at which they are back in the domain of the design concept. After this episode, Christian started a long enactment of a scenarios involving several users using the same smart-sketching whiteboard. A while later, the pair turned to a</region>
          <region class="DoCO:TextChunk" id="447" page="13" column="1">discussion of how the technology could cope with several users, the functions it would</region>
          <region class="DoCO:TextChunk" id="448" confidence="possible" page="13" column="1">require, and how it should be structured and constructed.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="449" page="13" column="1">3.4 Improvised Role Play to Discover Consequences While they were playing around with the actual smartboard, the two male designers</h2>
          <region class="DoCO:TextChunk" id="450" confidence="possible" page="13" column="1">While they were playing around with the actual smartboard, the two male designers</region>
          <region class="DoCO:TextChunk" id="452" page="13" column="1">discovered that it handled objects and sketches differently. These are two different kinds <marker type="block"/> of content, created using different functions. Sketches made with the pencil can easily</region>
          <region class="DoCO:TextChunk" id="453" confidence="possible" page="13" column="1">be deleted with an eraser, while geometric objects (rectangles, circles etc.) cannot be</region>
          <region class="DoCO:TextChunk" id="455" page="13" column="1">erased with the eraser but have to be deleted using the menus. The designers saw this as <marker type="block"/> a serious problem, one they discussed thoroughly in their final design presentation. In</region>
          <region class="DoCO:TextChunk" id="456" confidence="possible" page="13" column="1">Figure 10, we see Daniel enacts how he would erase an object using a smartboard eraser—but he fails, because it is an object rather than a free-hand sketch. Here, the</region>
          <region class="DoCO:TextChunk" id="457" page="13" column="1">enactment starts out in the domain of functions (easing vs. deleting) and content (free-</region>
          <region class="DoCO:TextChunk" id="458" confidence="possible" page="13" column="1">hand sketches vs. objects).</region>
          <region class="DoCO:FigureBox" id="F10">
            <image class="DoCO:Figure" src="62ky.page_013.image_05.png" thmb="62ky.page_013.image_05-thumb.png"/>
            <caption class="deo:Caption" id="460" confidence="possible" page="13" column="2">Figure 10. Daniel is trying to demonstratively erase an object saying, “This is all wrong.” This discovery reminded them that they were not to evaluate the current system but rather to design a system to support collaborative design tasks. They started to summarize this process in Excerpt 5, which provides further examples of their collaborative thinking-through process. Excerpt 5. Group 2; Synthesis session 3:2: Shall we sum up? Time Person Transcript of interaction Characteristic of Domain 0.55 action 1 Christian Should we sum up a bit...what have we arrived at? 2 Daniel Nothing [laughs] 3 Christian Yes, but I see a couple things. I see we want to have a large white surface on the whiteboard. We do not want a program mode; instead we want a large white surface, which works like a whiteboard but has interactivity in that you can make circles around menus, put in pictures, interface sketches, and interface elements and such . 4 Daniel Yes Writes down some ideas on the smartboard. Christian Then we want several client Acts out the scenario Structure, possibilities. We want it to run on a using the whiteboard Design concept, computer, and run network Functions &amp;</caption>
          </region>
          <outsider class="DoCO:TextBox" type="footer" id="461" page="13" column="2">25</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="462" page="13" column="2">26</outsider>
          <outsider class="DoCO:TextBox" type="header" id="464" page="14" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="463">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="466" page="14" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="465">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="unknown" id="467" page="14" column="1">functionalities over a net, so you can content get the same picture and the same surface in several different programs. Then you want, I think, in this situation you want me to be able to work on the computer with this while you work here on the whiteboard and someone else with this. You want to work on the same document even if document is a ridiculous word, but in the same workbook so to speak. Daniel Exactly, right Christian But then should several persons work [Daniel writes and Design concept, in parallel on the whiteboard like we sketches] Functions &amp; said? Also it should know which content, person does what, so the pencils must Interaction be able to identify the users, so that when I sketch here with my pen and you have your pen then you don’t have to switch pens. I can choose tools with my pen and write “this there and that there” and at the same time you will work here and you can show each other...</region>
          <region class="DoCO:FigureBox" id="F11">
            <image class="DoCO:Figure" src="62ky.page_014.image_06.png" thmb="62ky.page_014.image_06-thumb.png"/>
            <caption class="deo:Caption" id="469" page="14" column="1">Figure 11. Christian sums up the discussion and Daniel documents it through sketches and words.</caption>
          </region>
          <region class="DoCO:TextChunk" id="473" page="14" column="1">During this excerpt they continued to try out the design proposals. In contrast to earlier <marker type="block"/> excerpts we see that earlier enactments of hypothetical user activity have consequences<marker type="block"/> in the domain of structure (how functions and content should be organised technically,<marker type="block"/> temporally and spatially). Christian enacts the parallel work, which is part of the design</region>
          <region class="DoCO:TextChunk" id="474" confidence="possible" page="14" column="2">concept, in order to demonstrate the benefit of the proposed structure. During this enactment he also discovers the need for new functionality (identification of users).</region>
          <region class="DoCO:TextChunk" id="477" page="14" column="2">Christian was active, talking and exemplifying using enactments, while Daniel did a lot <marker type="block"/> of backchanneling [which has not been transcribed fully] as well as trying to document<marker type="block"/> and play around with some sketches (Figure 11). The progression of their design ideas</region>
          <region class="DoCO:TextChunk" id="478" confidence="possible" page="14" column="2">correlated well with their own experiences and uses of the technology. Thus their experiences of using the smartboard, as well as their experiences of playing at being</region>
          <region class="DoCO:TextChunk" id="479" page="14" column="2">users with the existing smartboard, drove the discussion forward. After this session they</region>
          <region class="DoCO:TextChunk" id="480" confidence="possible" page="14" column="2">refined the sketch (Figure 12).</region>
          <region class="DoCO:FigureBox" id="Fx481">
            <image class="DoCO:Figure" src="62ky.page_014.image_07.png" thmb="62ky.page_014.image_07-thumb.png"/>
          </region>
          <region class="unknown" id="482" page="14" column="2">F igure 12. Final sketch for presentation. A translation of the text in the sketch: Parallelism—Several users work at the same time. Multimodal—Different views depending on modality (computer,</region>
          <outsider class="DoCO:TextBox" type="footer" id="483" page="14" column="2">27</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="484" page="14" column="2">28</outsider>
          <outsider class="DoCO:TextBox" type="header" id="486" page="15" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="485">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="488" page="15" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="487">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="489" confidence="possible" page="15" column="1">whiteboard, handheld computer). The “icke o.o.” means that whiteboard is not object oriented, while the application on the laptop is.</region>
        </section>
      </section>
      <section class="deo:Discussion">
        <h1 class="DoCO:SectionTitle" id="490" page="15" column="1">4 Discussion</h1>
        <region class="DoCO:TextChunk" id="491" confidence="possible" page="15" column="1">We began this paper with an overarching problem: how interaction designers express the dynamics of interaction. Looking at previous research as well as our results, we</region>
        <region class="DoCO:TextChunk" id="492" page="15" column="1">have seen that they create the dynamic aspects within a tight coupling of talk, graphical</region>
        <region class="DoCO:TextChunk" id="493" confidence="possible" page="15" column="1">representations, and gestural enactments. The sketches are important as tools for thought, but it is the enactments and</region>
        <region class="DoCO:TextChunk" id="494" page="15" column="1">dramatizations that make the sketches behave. Playing the role of a user, and exploring</region>
        <region class="DoCO:TextChunk" id="495" confidence="possible" page="15" column="1">the potential technology with the intent of using it, helps designers explore the design and their design ideas, and also come up with new ideas. The enactments help designers to focus and move themselves imaginatively into the target context where their design solution might be used. As such, gestures serve as a powerful means to collaboratively assess the use of their design and engage in the</region>
        <region class="DoCO:TextChunk" id="499" page="15" column="1">situation of its use (see also <xref ref-type="bibr" rid="R43" id="496" class="deo:Reference">Robertson, 1996</xref>, 1997 and <xref ref-type="bibr" rid="R56" id="497" class="deo:Reference">Tuikka, 2002</xref>). But not only do<marker type="block"/> gestures help designers assume the role of the user. They also help them take on the role</region>
        <region class="DoCO:TextChunk" id="500" confidence="possible" page="15" column="1">of the artefact-in-use. In the empirical material, we saw how Christian and Daniel</region>
        <region class="DoCO:TextChunk" id="501" page="15" column="1">constantly imagined and enacted what the computer should be doing, for example, how</region>
        <region class="DoCO:TextChunk" id="502" confidence="possible" page="15" column="1">it should behave when the eraser was applied to an object.</region>
        <region class="DoCO:TextChunk" id="503" page="15" column="1">In the action context of the here and now, designers speak, gesture, and modify graphic</region>
        <region class="DoCO:TextChunk" id="504" confidence="possible" page="15" column="1">representations. The graphic representations create a space, representing the target</region>
        <region class="DoCO:TextChunk" id="506" page="15" column="1">context, in which designers can perform design moves (<xref ref-type="bibr" rid="R2" id="505" class="deo:Reference">Artman et al., 2005</xref>). They do so</region>
        <region class="DoCO:TextChunk" id="507" confidence="possible" page="15" column="1">by continuously modifying the graphic representations and by performing gestural</region>
        <region class="DoCO:TextChunk" id="509" confidence="possible" page="15" column="2">enactments to communicate and explore the dynamics of interaction. This process supports the interaction designers in imagining themselves as part of the interaction processes of people and artefacts. Our observations support the work by Robertson (1996, 1997) who describe how designers use enactments to create and take part in a time-based representation of process or activity that others can take part in (see also <xref ref-type="bibr" rid="R40" id="508" class="deo:Reference">Ochs et al., 1994</xref>; 1996).</region>
        <region class="DoCO:TextChunk" id="515" page="15" column="2">Sketches can be thought of as states in a state diagram; what the diagram lacks are the <marker type="block"/> transitions. In order to represent the transitions between states, the designers make use<marker type="block"/> of gestures. In fact, the tilting table has two states: horizontal and vertical. In between<marker type="block"/> those states there is a transition, which the women designers represented by using arm<marker type="block"/> movements. Similarly, as the Christian and Daniel dramatized the users’ utterances and<marker type="block"/> actions, they were representing transitions within and between functions, thus creating</region>
        <region class="DoCO:TextChunk" id="517" confidence="possible" page="15" column="2">and experiencing structure and interaction. This can be seen as a form of experience prototyping (<xref ref-type="bibr" rid="R13" id="516" class="deo:Reference">Buchenau &amp; Suri, 2000</xref>). The drama becomes a process of collaborative</region>
        <region class="DoCO:TextChunk" id="518" page="15" column="2">reasoning, firmly anchored in a situation of imagined use. Once again, this echoes the</region>
        <region class="DoCO:TextChunk" id="522" confidence="possible" page="15" column="2">research by <xref ref-type="bibr" rid="R55" id="519" class="deo:Reference">Tang (1989)</xref>, <xref ref-type="bibr" rid="R44" id="520" class="deo:Reference">Robertson (1996, 1997)</xref>, <xref ref-type="bibr" rid="R56" id="521" class="deo:Reference">Tuikka (2002)</xref>, Ala! and Hutchins</region>
        <region class="DoCO:TextChunk" id="525" page="15" column="2">(2004) and <xref ref-type="bibr" rid="R41" id="523" class="deo:Reference">Ochs et al. (1994, 1996)</xref>. We think that early in their training designers must<marker type="block"/> learn to acknowledge and even articulate these enactments as important ways to express</region>
        <region class="DoCO:TextChunk" id="527" confidence="possible" page="15" column="2">themselves as they develop designs. This is especially important since much of the design in industrial settings is accomplished in joint collaboration in front of whiteboards (<xref ref-type="bibr" rid="R29" id="526" class="deo:Reference">Lantz et al., 2005</xref>).</region>
        <outsider class="DoCO:TextBox" type="footer" id="528" page="15" column="2">29</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="529" page="15" column="2">30</outsider>
        <outsider class="DoCO:TextBox" type="header" id="531" page="16" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="530">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="header" id="533" page="16" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="532">http://www.tandf.no/artifact</ext-link></outsider>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="534" page="16" column="1">4.1 Enactments and Domains of Interaction Design</h2>
          <region class="DoCO:TextChunk" id="537" page="16" column="1">Let us now turn to our model with five domains of interaction design (design concept, <marker type="block"/> functions &amp; content, structure, interaction and presentation). We set out to analyse what<marker type="block"/> it is that is expressed in kinetic gestures and enactments in more detail using this model.</region>
          <region class="DoCO:TextChunk" id="538" confidence="possible" page="16" column="1">In Excerpt 1, 2 and 3 the participants perform their enactments using gestures that mimic the actions of users in an interaction walkthrough. The interaction walkthrough</region>
          <region class="DoCO:TextChunk" id="539" page="16" column="1">is a gesture-driven enactment. In excerpt 4 and 5 Christian and Daniel takes on the role</region>
          <region class="DoCO:TextChunk" id="540" confidence="possible" page="16" column="1">of two users and imagine themselves in a certain situation of use. This improvised role play is a scenario-driven enactment, and is used as a designer’s think aloud exploration. Turning to the five domains of interaction design we see that the gesture-driven interaction walkthroughs started out from the domain of interaction and drove the</region>
          <region class="DoCO:TextChunk" id="542" page="16" column="1">designers to see that there were consequences for primarily the domain of presentation <marker type="block"/> and the domain of design concept. There are also secondary consequences for the other</region>
          <region class="DoCO:TextChunk" id="543" confidence="possible" page="16" column="1">domains. The enactments in the form of improvised role play started out from the</region>
          <region class="DoCO:TextChunk" id="544" page="16" column="1">domain of design concept (in terms of need and purpose) and propagated consequences</region>
          <region class="DoCO:TextChunk" id="545" confidence="possible" page="16" column="1">primarily for the domain of functions and content, and the domain of structure. Secondarily, there are also consequences for the other domains. Using interaction walkthroughs, driven by gestures, means of expression gives the</region>
          <region class="DoCO:TextChunk" id="549" page="16" column="1">interaction designer expressive ability in the domains of interaction and presentation. It <marker type="block"/> also facilitates seeing that there are consequences in the other domains. An example of<marker type="block"/> that is when Anna and Barbara gets the ideas of the functions tilt and pull based on their<marker type="block"/> interaction walkthrough. These functions are also a specification of the concept of their</region>
          <region class="DoCO:TextChunk" id="550" confidence="possible" page="16" column="1">mobile and flexible smartboards.</region>
          <region class="DoCO:TextChunk" id="551" confidence="possible" page="16" column="2">Embodied enactments in interaction design are important for all domains of interaction design. Without these forms of expression, it would be difficult to express interaction</region>
          <region class="DoCO:TextChunk" id="552" page="16" column="2">and also the fundamental design concept. This would have consequences for the other</region>
          <region class="DoCO:TextChunk" id="553" confidence="possible" page="16" column="2">domains: functions &amp; content, structure, and presentation.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="555" page="16" column="2">4.2 Future research As <xref ref-type="bibr" rid="R56" id="554" class="deo:Reference">Tuikka (2002)</xref> has noted, enactments are of an ephemeral nature. This means that</h2>
          <region class="DoCO:TextChunk" id="557" confidence="possible" page="16" column="2">As <xref ref-type="bibr" rid="R56" id="556" class="deo:Reference">Tuikka (2002)</xref> has noted, enactments are of an ephemeral nature. This means that</region>
          <region class="DoCO:TextChunk" id="558" page="16" column="2">there are no stable traces of them. In order to make specifications for construction and to</region>
          <region class="DoCO:TextChunk" id="560" confidence="possible" page="16" column="2">support asynchronous communication it is however necessary to document the dynamics in some other way than gestures and role play. <xref ref-type="bibr" rid="R22" id="559" class="deo:Reference">Hummels (2000)</xref> provides</region>
          <region class="DoCO:TextChunk" id="561" page="16" column="2">examples of how arrows in sketches are used for that purpose. Improvised role play can</region>
          <region class="DoCO:TextChunk" id="562" confidence="possible" page="16" column="2">be documented in high-level storyboards and written scenarios. Interaction walkthroughs can be documented in storyboards and state transition charts. Building running prototypes is probably an even better specification. None of stable representations are however as swiftly used and convenient in collaborative design as</region>
          <region class="DoCO:TextChunk" id="563" page="16" column="2">enactments are, in the form of improvised role play and interaction walkthroughs. The</region>
          <region class="DoCO:TextChunk" id="564" confidence="possible" page="16" column="2">communication between designers and systems developers is an area that largely has been neglected in research to this date.</region>
          <region class="DoCO:TextChunk" id="566" page="16" column="2">The use of gestural enactments points towards prototyping tools for interaction design <marker type="block"/> that are built on principles of programming by example. Perhaps they could be used in</region>
          <region class="DoCO:TextChunk" id="568" confidence="possible" page="16" column="2">combination with a gesture-based user interface (<xref ref-type="bibr" rid="R28" id="567" class="deo:Reference">Landay &amp; Myers, 1995</xref>; Hummels, 2000). How to implement this kind of prototyping tool remain an issue for future research.</region>
          <outsider class="DoCO:TextBox" type="footer" id="569" page="16" column="2">31</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="570" page="16" column="2">32</outsider>
          <outsider class="DoCO:TextBox" type="header" id="572" page="17" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="571">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="574" page="17" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="573">http://www.tandf.no/artifact</ext-link></outsider>
          <region class="DoCO:TextChunk" id="575" confidence="possible" page="17" column="1">This study was carried out focusing on four master’s students. To form a solid basis</region>
          <region class="DoCO:TextChunk" id="576" page="17" column="1">further research needs to be conducted. At the time of writing we have begun to expand</region>
          <region class="DoCO:TextChunk" id="577" confidence="possible" page="17" column="1">the analysis to professional interaction designers in real world design work. The interplay betweens means for expression will particularly be studied, as well as processes of learning how to use different means of expression.</region>
          <region class="DoCO:TextChunk" id="578" confidence="possible" page="17" column="1">In this paper, we have analysed what gestures in interaction design express. We have</region>
          <region class="DoCO:TextChunk" id="579" confidence="possible" page="17" column="1">identified two means for expression of the dynamic aspects of interaction design:</region>
          <region class="DoCO:TextChunk" id="580" confidence="possible" page="17" column="1">Interaction walkthrough and improvised role play. Gestures drive the interaction</region>
          <region class="DoCO:TextChunk" id="581" confidence="possible" page="17" column="1">walkthrough and scenarios created on the spot drives the improvised role play. These</region>
          <region class="DoCO:TextChunk" id="582" confidence="possible" page="17" column="1">means for expression are two kinds of enactments that previous research has not</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="583" page="17" column="1">4.3 Conclusions In this paper, we have analysed what gestures in interaction design express. We have identified two means for expression of the dynamic aspects of interaction design: Interaction walkthrough and improvised role play. Gestures drive the interaction walkthrough and scenarios created on the spot drives the improvised role play. These means for expression are two kinds of enactments that previous research has not distinguished between. In our analysis, based on our model of interaction design</h2>
          <region class="DoCO:TextChunk" id="584" confidence="possible" page="17" column="1">distinguished between. In our analysis, based on our model of interaction design</region>
          <region class="DoCO:TextChunk" id="586" page="17" column="1">consisting of five domains (design concept, functions &amp; content, structure, interaction <marker type="block"/> and presentation), we have seen that interaction walkthroughs start out in the domain of</region>
          <region class="DoCO:TextChunk" id="587" confidence="possible" page="17" column="1">interaction, and improvised role play start out in the domain of design concept. From</region>
          <region class="DoCO:TextChunk" id="590" page="17" column="1">these domains the designer can then see consequences for the other domains. Given the <marker type="block"/> ephemeral nature of enactments, the improvised role play and interaction walkthroughs<marker type="block"/> still need to be documented in stable representations. Storyboards, scenarios, and state</region>
          <region class="DoCO:TextChunk" id="591" confidence="possible" page="17" column="1">transition charts are examples of stable representations that can be used. We wish to conclude by emphasising the implications for interaction design education. In this article we have seen the importance of two forms of enactment (improvised role play</region>
          <region class="DoCO:TextChunk" id="592" page="17" column="1">and interaction walkthroughs). These are means for expressions that can be deliberately</region>
          <region class="DoCO:TextChunk" id="593" confidence="possible" page="17" column="1">and reflectively used by interaction designers. We think that education in interaction</region>
          <region class="DoCO:TextChunk" id="594" page="17" column="2">design must not only focus on the practice and skill of sketching, but also acknowledge</region>
          <region class="DoCO:TextChunk" id="595" confidence="possible" page="17" column="2">the natural and spontaneous enactment that represents dynamics. Our results imply that improvised role play and interaction walkthrough can be articulated as conscious means for expression to be taught and refined in learning of</region>
          <region class="DoCO:TextChunk" id="597" page="17" column="2">interaction design. The model of design domains in interaction design (design concept, <marker type="block"/> functions &amp; content, structure, interaction and presentation) can be used to analyse and</region>
          <region class="DoCO:TextChunk" id="598" confidence="possible" page="17" column="2">thoughtfully reflect on complex consequences of a design solution. This is useful for creating both a reflective learning practice and a reflective professional practice in interaction design.</region>
          <outsider class="DoCO:TextBox" type="footer" id="599" page="17" column="2">33</outsider>
          <outsider class="DoCO:TextBox" type="footer" id="600" page="17" column="2">34</outsider>
          <outsider class="DoCO:TextBox" type="header" id="602" page="18" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="601">http://www.tandf.no/artifact</ext-link></outsider>
          <outsider class="DoCO:TextBox" type="header" id="604" page="18" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="603">http://www.tandf.no/artifact</ext-link></outsider>
        </section>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="605" page="18" column="1">Acknowledgements</h1>
        <region class="DoCO:TextChunk" id="606" page="18" column="1">We thank Ann Lantz and Jonas Lundberg for comments on an earlier draft. This study</region>
        <region class="DoCO:TextChunk" id="607" confidence="possible" page="18" column="1">was financed by the Swedish Research Council and VINNOVA.</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="608" page="18" column="2">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="609" page="18" column="2">Ala!, M. &amp; Hutchins, E. (2004). I see what you are saying: Action as cognition in fMRI</ref>
          <ref class="deo:BibliographicReference" id="610" confidence="possible" page="18" column="2">brain mapping practice. Journal of Cognition and Culture 4 (3-4), 629 - 661.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="611" page="18" column="2">Artman, H., Ramberg, R., Sundholm, H. &amp; Cerratto Pargman, T. (2005). Action context and target context representations: A case study on collaborative design learning. In T.</ref>
          <ref class="deo:BibliographicReference" id="612" page="18" column="2">Koschman, D. Suthers, &amp; T.W. Chan (Eds.), Computer supported collaborative learning</ref>
          <ref class="deo:BibliographicReference" id="613" page="18" column="2">2005: The next 10 years! Mahwah, NJ: Lawrence Erlbaum Associates.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="614" page="18" column="2">Arvola, M. (2003). The interaction character of computers in co-located collaboration. In E. O’Neill, P. Palangue &amp; P. Johnson (Eds.), People and computers XVII –</ref>
          <ref class="deo:BibliographicReference" id="615" confidence="possible" page="18" column="2">Designing for society (pp. 37-51). London, UK: Springer-Verlag.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="616" page="18" column="2">Arvola, M. (2005). Shades of use: The dynamics of interaction design for sociable use.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="617" confidence="possible" page="18" column="2">Linköping Studies in Science and Technology, Dissertation No. 900. Linköping, Sweden: Linköpings universitet. Retrieved May 1, 2006 from</ref>
          <ref class="deo:BibliographicReference" id="619" confidence="possible" page="18" column="2"> <ext-link ext-link-type="uri" href="http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-5019" id="618">http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-5019</ext-link></ref>
          <ref rid="R6" class="deo:BibliographicReference" id="620" page="18" column="2">Arvola, M. (2006). Interaction design patterns for computers in sociable use,</ref>
          <ref class="deo:BibliographicReference" id="621" confidence="possible" page="18" column="2">International journal of computer applications in technology, 25 (2/3), 128-139.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="622" page="18" column="2">Arvola, M., &amp; Artman, H. (2006). Interaction Walkthroughs and Improvised Role Play.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="623" page="18" column="2">In L. Feijs, S. Kyffin &amp; B. Young (Eds.), Design and Semantics of Form and Movement: DeSForM 2006 (pp. 42-51). Eindhoven, The Netherlands: Koninklijke</ref>
          <ref class="deo:BibliographicReference" id="624" page="18" column="2">Philips Electronics N.V.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="631" page="19" column="1">Athavankar, U. (1999). Gestures, mental imagery and spatial reasoning. In J. S. Gero &amp;</ref>
          <ref class="deo:BibliographicReference" id="632" page="19" column="1">B. Tversky (Eds.), Visual and Spatial Reasoning in Design. University of Sydney, Austrailia: Key Centre of Design Computing and Cognition.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="633" page="19" column="1">Bailey, B.P. &amp; Konstan, J.A. (2003). Are informal tools better? Comparing DEMAIS, pencil and paper, and Authorware for early multimedia design. In Proceedings of the</ref>
          <ref class="deo:BibliographicReference" id="634" confidence="possible" page="19" column="1">SIGCHI conference on Human factors in computing systems (pp. 313-320). New York, NY: ACM Press.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="635" page="19" column="1">Bailey, B.P., J.A., Konstan, &amp; Carlis, J.V. (2001). DEMAIS: Designing multimedia applications with interactive storyboards. In Proceedings of the ninth ACM international</ref>
          <ref class="deo:BibliographicReference" id="636" confidence="possible" page="19" column="1">conference on Multimedia (pp. 241-250). New York, NY: ACM Press.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="637" page="19" column="1">Bekker, M., Olson, J.S. &amp; Olson, G.M. (1995). Analysis of gestures in face-to-face</ref>
          <ref class="deo:BibliographicReference" id="638" confidence="possible" page="19" column="1">design teams provides guidance for how to use groupware in design. In Proceedings of the conference on Designing interactive systems: processes, practices, methods, and techniques (pp. 157-166). New York, NY: ACM Press.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="639" page="19" column="1">Buchenau, M. &amp; Suri, J.F. (2000). Experience prototyping. In Proceedings of the</ref>
          <ref class="deo:BibliographicReference" id="640" confidence="possible" page="19" column="1">conference on Designing interactive systems: processes, practices, methods, and techniques (pp. 424-433). New York, NY: ACM Press.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="641" page="19" column="1">Cooper, A., Reimann, R., Reimann, R.M. &amp; Dubberly, H. (2003). About face 2.0: The</ref>
          <ref class="deo:BibliographicReference" id="643" page="19" column="1">essentials of interaction design. Chichester: John Wiley. <marker type="column" number="2"/><marker type="block"/> Cross, N. (2000). Engineering design methods: Strategies for product design, 3rd</ref>
          <ref class="deo:BibliographicReference" id="644" page="19" column="2">edition. Chichester: John Wiley.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="645" page="19" column="2">Eden, H., Scharff, E. &amp; Hornecker, E. (2002). Multilevel design and role play:</ref>
          <ref class="deo:BibliographicReference" id="646" confidence="possible" page="19" column="2">Experiences in assessing support for neighborhood participation in design. Proceedings of the conference on Designing interactive systems: processes, practices, methods, and techniques (pp. 387-392). New York, NY: ACM Press.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="647" page="19" column="2">Fleming, D. (1998). Design talk: Constructing the object in studio conversations,</ref>
          <ref class="deo:BibliographicReference" id="648" confidence="possible" page="19" column="2">Design issues, 14 (2), 41-62.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="649" page="19" column="2">Fällman, D. (2003). In romance with the materials of mobile interaction: A</ref>
          <ref class="deo:BibliographicReference" id="650" confidence="possible" page="19" column="2">phenomenological approach to the design of mobile information technology. Dissertation. Umeå, Sweden: Umeå University.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="651" page="19" column="2">Goldschmidt, G. (1991). The dialectics of sketching. Creativity research journal, 4 (2),</ref>
          <ref class="deo:BibliographicReference" id="652" confidence="possible" page="19" column="2">123-143.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="653" page="19" column="2">Harada, K., Tanaka, E., Ogawa, R. &amp; Hara, Y. (1996). Anecdote: A multimedia storyboarding system with seamless authoring support. In Proceedings of the Forth</ref>
          <ref class="deo:BibliographicReference" id="654" confidence="possible" page="19" column="2">ACM International Conference on Multimedia (pp. 341-351). New York, NY: ACM Press.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="655" page="19" column="2">Howard, S., Carroll, J., Murphy, J. &amp; Peck, J. (2002). Using ‘endowed props’ in</ref>
          <ref class="deo:BibliographicReference" id="656" confidence="possible" page="19" column="2">scenario-based design. In Proceedings of the second Nordic conference on Human- computer interaction (pp. 1-10). New York, NY: ACM Press.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="663" page="20" column="1">Hummels. C. (2000). Gestural design tools: Prototypes, experiments and scenarios.</ref>
          <ref class="deo:BibliographicReference" id="664" confidence="possible" page="20" column="1">Dissertation. Delft, The Netherlands: Technische Universiteit Delft.</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="665" page="20" column="1">Hutchins, E. (2005). Material anchors for conceptual blends, Journal of pragmatics 37</ref>
          <ref class="deo:BibliographicReference" id="666" confidence="possible" page="20" column="1">(10), 1555-1577.</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="667" page="20" column="1">Iacucci, G., Iacucci, C. &amp; Kuutti, K. (2002). Imagining and experiencing in design: The</ref>
          <ref class="deo:BibliographicReference" id="668" confidence="possible" page="20" column="1">role of performances. . In Proceedings of the second Nordic conference on Human- computer interaction (pp. 167-176). New York, NY: ACM Press.</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="669" page="20" column="1">Iacucci, G., Kuutti, K. &amp; Ranta, M. (2000). On the move with a magic thing: Role playing in concept design of mobile services and products In Proceedings of the</ref>
          <ref class="deo:BibliographicReference" id="670" confidence="possible" page="20" column="1">conference on Designing interactive systems: processes, practices, methods, and techniques (pp. 193-202). New York, NY: ACM Press.</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="671" page="20" column="1">Johanson, B., Ponnekanti, S., Sengupta, C. &amp; Fox, A. (2001) Multibrowsing: Moving web content across multiple displays. In Proceedings of the 3rd international conference</ref>
          <ref class="deo:BibliographicReference" id="672" confidence="possible" page="20" column="1">on Ubiquitous Computing (pp. 346-353). London, UK: Springer-Verlag.</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="673" page="20" column="1">Kristof, R. &amp; Satran A. (1995). Interactivity by design: Creating and communicating</ref>
          <ref class="deo:BibliographicReference" id="674" confidence="possible" page="20" column="1">with new media. Mountainview, CA: Adobe.</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="675" page="20" column="1">Landay, J.A. &amp; Myers, B.A. (1995). Interactive sketching for early stages of user</ref>
          <ref class="deo:BibliographicReference" id="676" confidence="possible" page="20" column="1">interface design. In Proceedings of the SIGCHI conference on Human factors in computing systems (pp. 43-50). New York, NY: ACM Press.</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="677" page="20" column="2">Lantz, A., Artman, H. &amp; Ramberg, R. (2005). Interaction design as experienced by</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="678" confidence="possible" page="20" column="2">practitioners. In Proceedings of the Nordic design research conference 2005. Retrieved</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="680" confidence="possible" page="20" column="2">May 1, 2006 from <ext-link ext-link-type="uri" href="http://www.tii.se/reform/inthemaking/proceedings.htm" id="679">http://www.tii.se/reform/inthemaking/proceedings.htm</ext-link></ref>
          <ref rid="R32" class="deo:BibliographicReference" id="681" page="20" column="2">Lin, J., Newman, M.W., Hong, J.I. &amp; Landay, J.A. (2000). DENIM: Finding a tighter fit between tools and practice for web site design. In Proceedings of the SIGCHI</ref>
          <ref class="deo:BibliographicReference" id="682" confidence="possible" page="20" column="2">conference on Human factors in computing systems (pp. 510-517). New York, NY: ACM Press.</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="683" page="20" column="2">Lundberg, J. (2005). Shaping online news: Genre perspectives on interaction design. Linköping Studies in Science and Technology, Dissertation No. 918. Linköping,</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="684" confidence="possible" page="20" column="2">Sweden: Linköpings universitet. Retrieved May 1, 2006 from</ref>
          <ref class="deo:BibliographicReference" id="686" confidence="possible" page="20" column="2"> <ext-link ext-link-type="uri" href="http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-5020" id="685">http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-5020</ext-link></ref>
          <ref rid="R35" class="deo:BibliographicReference" id="687" page="20" column="2">Löwgren, J. (2004). Animated use sketches as design representations. Interactions,</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="688" confidence="possible" page="20" column="2">November + December 2004, 22-27.</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="689" page="20" column="2">Nelson, H. &amp; Stolterman, E. (2003). The design way: Intentional change in an</ref>
          <ref class="deo:BibliographicReference" id="690" confidence="possible" page="20" column="2">unpredictable world. Englewood Cliffs, NJ: Educational Technology Publications.</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="691" page="20" column="2">Newman, W.M. &amp; Lamming, M.G. (1995). Interactive system design. Harlow, UK:</ref>
          <ref class="deo:BibliographicReference" id="692" page="20" column="2">Addison-Wesley.</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="693" page="20" column="2">Newman, W. &amp; Landay, J.A. (2000). Sitemaps, storyboards, and specifications: A</ref>
          <ref class="deo:BibliographicReference" id="694" confidence="possible" page="20" column="2">sketch of web site design practice. In Proceedings of the conference on Designing</ref>
          <ref class="deo:BibliographicReference" id="701" page="21" column="1">interactive systems: processes, practices, methods, and techniques (pp. 263-274). New York, NY: ACM Press.</ref>
          <ref rid="R40" class="deo:BibliographicReference" id="702" page="21" column="1">Ochs, E., Jacoby, S. &amp; Gonzales, P. (1994). Interpretative journeys: How physicists talk</ref>
          <ref class="deo:BibliographicReference" id="703" confidence="possible" page="21" column="1">and travel through graphic space, Configurations, 2 (1), 151-172.</ref>
          <ref rid="R41" class="deo:BibliographicReference" id="704" page="21" column="1">Ochs, E., Gonzales, P. &amp; Jacoby, S. (1996). “When I come down I’m in the domain</ref>
          <ref class="deo:BibliographicReference" id="705" confidence="possible" page="21" column="1">state”: Grammar and graphic representation in the interpretative activity of physicists. In E. Ochs, E. Schegloff, &amp; S. Thompson (Eds.), Interaction Grammar (pp. 328-369). Cambridge, UK: Cambridge University Press.</ref>
          <ref rid="R42" class="deo:BibliographicReference" id="706" page="21" column="1">Pomerantz, A., &amp; Fehr, B.J. (1997). Conversation analysis: An approach to the study of</ref>
          <ref class="deo:BibliographicReference" id="707" page="21" column="1">social action as sense making practices. In T.A. van Dijk (Ed.), Discourse as Social Interaction (pp. 64-91). London, UK: Sage Publications.</ref>
          <ref rid="R43" class="deo:BibliographicReference" id="708" page="21" column="1">Robertson, T. (1996). Embodied actions in time and place: The design of a multimedia, educational computer game. Computer supported cooperative work: The journal of</ref>
          <ref class="deo:BibliographicReference" id="709" confidence="possible" page="21" column="1">collaborative computing, 5 (4), 1-27.</ref>
          <ref rid="R44" class="deo:BibliographicReference" id="710" page="21" column="1">Robertson, T. (1997). Cooperative work and lived cognition: A taxonomy of embodied</ref>
          <ref class="deo:BibliographicReference" id="711" confidence="possible" page="21" column="1">actions. In Proceedings of the Fifth European Conference on Computer-Supported Cooperative Work (pp. 205-220). Dordrecht, The Netherlands: Kluwer Academic Publishers.</ref>
          <ref rid="R45" class="deo:BibliographicReference" id="712" page="21" column="2">Sato, S. &amp; Salvador, T. Playacting and focus troupes: Theater techniques for creating quick, intense, immersive, and engaging focus group sessions. Interactions, September + October 1999, 35-41.</ref>
          <ref rid="R46" class="deo:BibliographicReference" id="713" page="21" column="2">Schön, D. (1983). The Reflective Practitioner: How Professionals Think in Action. New</ref>
          <ref class="deo:BibliographicReference" id="714" confidence="possible" page="21" column="2">York, NY: Basic Books.</ref>
          <ref rid="R47" class="deo:BibliographicReference" id="715" page="21" column="2">Schön, D. (1987). Educating the Reflective Practitioner. San Francisco, CA: Jossey-</ref>
          <ref class="deo:BibliographicReference" id="716" confidence="possible" page="21" column="2">Bass.</ref>
          <ref rid="R48" class="deo:BibliographicReference" id="717" page="21" column="2">Shneiderman, B. &amp; Plaisant, C. (2004). Designing the user Interface: Strategies for</ref>
          <ref class="deo:BibliographicReference" id="718" page="21" column="2">effective human-computer interaction, 4th edition. Harlow, UK: Addison-Wesley,</ref>
          <ref rid="R49" class="deo:BibliographicReference" id="719" page="21" column="2">Sinha, K. &amp; Landay, J.A. (2001). Visually prototyping perceptual user interfaces through multimodal storyboarding. In Proceedings of the 2001 workshop on Perceptive</ref>
          <ref class="deo:BibliographicReference" id="720" confidence="possible" page="21" column="2">user interfaces (pp. 1-4). New York, NY: ACM Press.</ref>
          <ref rid="R50" class="deo:BibliographicReference" id="721" page="21" column="2">Snyder, C. (2003). Paper prototyping: The fast and easy way to design and refine user</ref>
          <ref class="deo:BibliographicReference" id="722" page="21" column="2">interfaces. San Francisco, CA: Morgan Kaufmann Publishers.</ref>
          <ref rid="R51" class="deo:BibliographicReference" id="723" page="21" column="2">Svanæs, D. (2000). Understanding interactivity: Steps to a phenomenology of human-</ref>
          <ref class="deo:BibliographicReference" id="724" confidence="possible" page="21" column="2">computer interaction, Dissertation. Trondheim, Norway: Norges teknisk- naturvitenskaplige universitet.</ref>
          <ref rid="R52" class="deo:BibliographicReference" id="725" page="21" column="2">Sundholm, H., Ramberg, R. &amp; Artman, H. (2004). Learning conceptual design: Activities with electronic whiteboards. In M. Agger Eriksen, L. Malmborg, J. Nilsen</ref>
          <ref rid="R53" class="deo:BibliographicReference" id="732" page="21" column="2">(Eds.), CADE2004 web proceedings of computers in art and design education <marker type="page" number="22"/><marker type="column" number="1"/><marker type="block"/> conference. Copenhagen, Denmark and Malmö, Sweden: Copenhagen Business School and Malmö University. Retrieved May 1, 2006 from asp.cbs.dk/cade2004/proceedings/<marker type="block"/> Tang, J.C. (1989). Toward an understanding of the use of shared workspaces by design</ref>
          <ref class="deo:BibliographicReference" id="733" confidence="possible" page="22" column="1">teams, Dissertation. Stanford, CA: Stanford University.</ref>
          <ref rid="R56" class="deo:BibliographicReference" id="734" page="22" column="1">Tuikka, T. (2002). Remote concept design from an activity theory perspective. In</ref>
          <ref rid="R57" class="deo:BibliographicReference" id="735" confidence="possible" page="22" column="1">Proceedings of the 2002 ACM conference on Computer supported cooperative work</ref>
          <ref class="deo:BibliographicReference" id="736" confidence="possible" page="22" column="1">(pp. 186-195). New York , NY: ACM Press.</ref>
          <ref rid="R58" class="deo:BibliographicReference" id="737" page="22" column="1">Van Welie, M. &amp; van der Veer, G.C. (2003). Pattern languages in interaction design: Structure and organization. In Proceedings of Interact ’03 (pp. 527-534). Amsterdam,</ref>
          <ref class="deo:BibliographicReference" id="738" confidence="possible" page="22" column="1">The Netherlands: IOS Press.</ref>
          <ref rid="R59" class="deo:BibliographicReference" id="739" page="22" column="1">Werle, P., Kilander, F., Jonsson, M., Lönnqvist, P. &amp; Jansson, C.G. (2001). A</ref>
          <ref rid="R60" class="deo:BibliographicReference" id="740" confidence="possible" page="22" column="1">ubiquitous service environment with active documents for teamwork support. In Ubicomp 2001: Ubiquitous Computing, Third International Conference (pp. 139-155).</ref>
          <ref class="deo:BibliographicReference" id="741" confidence="possible" page="22" column="1">London, UK: Springer-Verlag.</ref>
          <ref rid="R61" class="deo:BibliographicReference" id="742" page="22" column="1">Woolman, M. (2002). Digital information graphics. London, UK: Thames &amp; Hudson.</ref>
          <ref rid="R62" class="deo:BibliographicReference" id="743" page="22" column="1">Wulff, W., Evans, S. &amp; Rheinfrank, J. (1990). Animating interfaces. In Proceedings of the 1990 ACM conference on Computer-supported cooperative work (pp. 241-254).</ref>
          <ref class="deo:BibliographicReference" id="744" confidence="possible" page="22" column="1">New York, NY: ACM Press.</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="footer" id="625" page="18" column="2">35</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="626" page="18" column="2">36</outsider>
        <outsider class="DoCO:TextBox" type="header" id="628" page="19" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="627">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="header" id="630" page="19" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="629">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="footer" id="657" page="19" column="2">37</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="658" page="19" column="2">38</outsider>
        <outsider class="DoCO:TextBox" type="header" id="660" page="20" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="659">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="header" id="662" page="20" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="661">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="footer" id="695" page="20" column="2">39</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="696" page="20" column="2">40</outsider>
        <outsider class="DoCO:TextBox" type="header" id="698" page="21" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="697">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="header" id="700" page="21" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="699">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="footer" id="727" page="21" column="2">41</outsider>
        <outsider class="DoCO:TextBox" type="footer" id="728" page="21" column="2">42</outsider>
        <outsider class="DoCO:TextBox" type="header" id="730" page="22" column="1">This is a preprint of an article whose final and definitive form has been published in the journal Artifact ©2006 Taylor &amp; Francis; Artifact is available online at: <ext-link ext-link-type="uri" href="http://www.tandf.no/artifact" id="729">http://www.tandf.no/artifact</ext-link></outsider>
        <outsider class="DoCO:TextBox" type="footer" id="745" page="22" column="2">43</outsider>
      </section>
    </body>
  </article>
</pdfx>

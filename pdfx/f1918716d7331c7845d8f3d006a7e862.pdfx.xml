<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>0900dbfdeed083cccbc7558dcd6edba8c90906467ba772acfe19721d93359358</job>
    <base_name>62ig</base_name>
    <doi>10.1016/j.intcom.2006.05.004</doi>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <region class="DoCO:FigureBox" id="Fx1">
        <image class="DoCO:Figure" src="62ig.page_001.image_01.png" thmb="62ig.page_001.image_01-thumb.png"/>
      </region>
      <region class="unknown" id="2">Interacting with Computers 18 (2006) 1012–1031 www.elsevier.com/locate/intcom</region>
      <title-group>
        <article-title class="DoCO:Title" id="3">Designing for programming as joint performances among groups of children</article-title>
      </title-group>
      <contrib-group class="DoCO:ListOfAuthors">
        <contrib contrib-type="author">
          <name id="4">Ylva Fernaeus</name>
          <aff id="5">*</aff>
        </contrib>
        <contrib contrib-type="author">
          <name id="6">Jakob Tholander</name>
        </contrib>
      </contrib-group>
      <footnote class="DoCO:Footnote" id="12">* Corresponding author. Tel.: +46 08 674 74 68; fax: +46 08 703 90 25. E-mail addresses: <email id="10">ylva@dsv.su.se</email> (Y. Fernaeus), <email id="11">jakobth@dsv.su.se</email> (J. Tholander).</footnote>
      <region class="unknown" id="7">Department of Computer and Systems Sciences, Stockholm University Forum 100, 164 40 Kista, Sweden Available online 17 July 2006</region>
      <abstract class="DoCO:Abstract" id="8">Research on computer programming usually views the interactions as mostly cognitively based, with focus on concepts such as memory, perception and conceptual understanding. However, the current trend towards embodied and social perspectives on interaction provides an alternative way of looking at interactive processes, instead emphasising aspects such as social and physical performance with and around technology. We have explored a range of activities and tools that explicitly address these aspects in programming, with a specific focus on children’s making of own computer games and simulations. We exemplify this work through three different situations where tools and activities are used by children as recourses for building of interactive systems, while at the same time allowing for bodily action in negotiation of design ideas. We discuss how situations like these may provide directions for new technologies for programming as well as methodological developments in the area of interaction design. Ó 2006 Elsevier B.V. All rights reserved.</abstract>
      <region class="DoCO:TextChunk" id="9" confidence="possible">Keywords: Interaction design; Tangible programming; Performance in interaction design; Children’s programming</region>
      <region class="unknown" id="13">0953-5438/$ - see front matter Ó 2006 Elsevier B.V. All rights reserved. doi:10.1016/j.intcom.2006.05.004</region>
      <outsider class="DoCO:TextBox" type="header" id="14">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="15">1013</outsider>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="deo:Introduction">
        <h1 class="DoCO:SectionTitle" id="16" page="2" column="1">1. Introduction</h1>
        <region class="DoCO:TextChunk" id="26" page="2" column="1">Performance in interaction design can be investigated through a range of different perspectives. One is the classic view of Brenda Laurel’s Computers and Theatre ( <xref ref-type="bibr" rid="R21" id="17" class="deo:Reference">Laurel, 1993</xref>), where the computer program itself is looked upon as a ‘live perfor- mance’, experienced in use by its users. The role of the developer is then somewhat as a theatre director orchestrating the acts to be performed by the computer program. A second view is through the performance of users, who together and with the system act in a social setting, towards a real or imagined ‘audience’. A third perspective, and which will be primarily considered here, concerns the communicative acts of designers and programmers ‘in the making’. When building an interactive system, collaborating participants often need to physically perform towards one another in order to communicate ideas and properties of the system to be realised. External resources such as sketches as well as bodily action all play important parts in such processes. Examples of methods that explicitly address these matters include test-running of low-fidelity prototypes through collaborative role-plays (<xref ref-type="bibr" rid="R33" id="18" class="deo:Reference">Rettig, 1994</xref>) and methods of bodystorming (<xref ref-type="bibr" rid="R29" id="19" class="deo:Reference">Oulasvirta et al., 2003</xref>), where designers explore a given context of use through acting out everyday activities in the environment of their target users. Recently, such bodily aspects of performances have been increasingly brought into the conceptual discussions of interaction design at large, and especially in the design of physical and mixed media interactive environments (<xref ref-type="bibr" rid="R16" id="20" class="deo:Reference">Jacucci, 2004</xref>). To further understand how the concept of performance can be used to support the more technical parts of making computational systems, we have explored a range of activities and tools that explicitly address the activity of programming, and especially in programming performed by children. This research has been conducted through setting up ‘staged activities’, in which groups of children get to use existing programming tools and research prototypes. In these activities we attempt to engage children in productive use of the technology and thereby provide them with realistic experiences of how the resources could be used. Based on recorded material from such settings, detailed analyses of the interactions with and around the tools have been made. The purpose of the analyses is to provide insights into children’s perception of the technologies, and thereby work as input for design of new tools and activities. The design process does in this sense have many similarities to the use of ‘‘technology probes’’ (<xref ref-type="bibr" rid="R14" id="21" class="deo:Reference">Hutchinson et al., 2003</xref>) as resources for design. In this paper, we present three examples from such activities, emphasising different aspects of performance in children’s programming practices. The last example that we provide involves a tangible programming system that has come out of this work, and which allows for groups of children to build their own dynamic play worlds (<xref ref-type="bibr" rid="R8" id="22" class="deo:Reference">Fernaeus and Tholander, 2005</xref>, 2006). It should be noted how performance here not only served as a means for our own design, but in the end, we also made physical performance part of the actual programming environment. Each of the analyses presented are intended to illustrate programming activities in which children make use of the interactive resources to physically display and act out ideas for each other, as an integrated part of their development process. We end the<marker type="page" number="3"/><marker type="block"/> paper by pointing towards directions for designs that may bring the concepts of bodily performance in programming further, allowing for full-body interactions, increased use of spatial properties of the room and a larger focus on the social aspects of interaction.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="24" page="3" column="1">1014</outsider>
        <outsider class="DoCO:TextBox" type="header" id="25" page="3" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="27" page="3" column="1">2. Background: Programming as performed action</h1>
        <region class="DoCO:TextChunk" id="52" page="3" column="1">A main concern in research on programming for children has been to develop representations that children may easily understand, and with which they may express themselves and their ideas through. Examples of research in this area include efforts in finding program representations that more directly map to the runtime representations, such as graphical rewrite rules ( <xref ref-type="bibr" rid="R35" id="28" class="deo:Reference">Smith and Cypher, 1999</xref>) and comic strips (<xref ref-type="bibr" rid="R19" id="29" class="deo:Reference">Kindborg, 2003</xref>). Other approaches are to use concrete virtual objects (<xref ref-type="bibr" rid="R38" id="30" class="deo:Reference">Tholander, 2003</xref>) and real world physical artefacts (<xref ref-type="bibr" rid="R7" id="31" class="deo:Reference">Eisenberg et al., 2002</xref>; <xref ref-type="bibr" rid="R25" id="32" class="deo:Reference">McNerny, 2004</xref>; <xref ref-type="bibr" rid="R41" id="33" class="deo:Reference">Zuckerman and Resnick, 2003</xref>) as resources when building a computational system. An argument often put forth for such approaches is that they make otherwise abstract concepts more concrete and easier to manipulate, and in a way provide bridges for young students to grasp important concepts in areas such as mathematics, physics and computer science. A growing area in interactive technologies for children is concerned with technologies such as physical storytelling spaces (<xref ref-type="bibr" rid="R26" id="34" class="deo:Reference">Montemayor et al., 2002</xref>), room-based (<xref ref-type="bibr" rid="R36" id="35" class="deo:Reference">Stanton et al., 2001</xref>) and out-door interactive environments (<xref ref-type="bibr" rid="R3" id="36" class="deo:Reference">Benford et al., 2005</xref>; <xref ref-type="bibr" rid="R31" id="37" class="deo:Reference">Rogers et al., 2004</xref>). These technologies more extensively consider how to design for and make use of the physical space, and how this can support collaborative activities. Our work aims to extend this research by designing technologies for children that let them create dynamic systems through activities in which bodily engagement and social performance plays a more significant role. Through such a perspective, a central quality of new programming representations is that they provide the possibility for participants to engage in what we call embodied programming. We use this term – in the same vein as in Paul Dourish’s (<xref ref-type="bibr" rid="R6" id="38" class="deo:Reference">Dourish, 2001</xref>) notion embodied interaction – to emphasise that programming with visual and tangible forms of representations allows people to involve bodily actions such as pointing and gesture in a more direct sense than is possible with traditional text-based or symbolic programming representations. This includes bodily actions performed in order to interact with and through the programming environment, and also physical aspects of the discussions, negotiations and perception taking place when elaborating the content of the program being discussed. Our analytical starting point is that different forms of representation afford different forms of interaction, and consequently also influence the meaning that people ascribe to those representations (<xref ref-type="bibr" rid="R39" id="39" class="deo:Reference">Wertsch, 1998</xref>). In HCI it is well known that looking at, and interacting with, a graphical interface is essentially different from interacting with a text-based or command driven interface, not only in how to ‘‘read’’ the system, but also in how to interact with and through it (<xref ref-type="bibr" rid="R28" id="40" class="deo:Reference">Norman, 1993</xref>). Hence, different ways of representing tools and information imply different kinds of action<marker type="page" number="4"/><marker type="block"/> and interaction, as well as emphasising different aspects of what is being represented. Interaction with textual and graphical interfaces often has a character of looking and manipulating, with limited bodily engagement; while interaction with tangible interfaces generally require more of physical engagement from the users. Hence, such representations afford a set of actions and activities that are quite different from those afforded by more text- or symbol-based representations. We use this perspective to analyse the character of children’s interaction in three different hands-on activities with visual and tangible programming representations. This is done in an ethnomethodological tradition (<xref ref-type="bibr" rid="R12" id="44" class="deo:Reference">Heath and Luff, 2000</xref>; <xref ref-type="bibr" rid="R37" id="45" class="deo:Reference">Suchman, 1987</xref>), through detailed description of practices of interaction with technological artefacts. An important element of such work is to understand the indexical aspects of language and interaction, i.e., how people make sense of indexical terms like ‘‘this’’ and ‘‘there’’ and how they are able to understand what one is referring to through pointing and gesture (<xref ref-type="bibr" rid="R11" id="46" class="deo:Reference">Hanks, 1992</xref>; <xref ref-type="bibr" rid="R20" id="47" class="deo:Reference">Koschmann and LeBaron, 2002</xref>). Study- ing the interactions on such a fine-grained level of analysis allows us to describe the actual character of the activity that the children engage in. Central to our interpretation of actions and utterances of people is to understand them as an interactive achievement between the participants, involving the use of external resources as well as talk and gesture. Hence, the meaning of the term ‘‘that’’ in the phrase ‘‘pick up that one’’ is not to be found solely in the intentions of the person uttering the phrase, nor in the addressee’s capability of decoding its meaning, but rather in the interactions between the participants and their relation to the context. Moreover, a number of studies have shown the importance of the body in these practices, for instance how posture and gaze in concert with talk contribute to making particular features of the environment salient to another person (<xref ref-type="bibr" rid="R10" id="48" class="deo:Reference">Goodwin, 2000</xref>; <xref ref-type="bibr" rid="R27" id="49" class="deo:Reference">Nishizaka, 2000</xref>). <xref ref-type="bibr" rid="R12" id="50" class="deo:Reference">Heath and Hindmarsh (2000)</xref> provide examples from technology- rich settings showing how subtle actions such as moving one’s gaze away from the screen may indicate to others that an alternative course of action is suggested. Another vivid example is provided in Goodwin’s (2000) study of girls’ social interaction when playing hopscotch. The hopscotch grid drawn on the ground provides a structure to the activity, which allows the girls to use phrases like ‘‘this’’ and ‘‘that’’ and also gesture to refer to different squares in the grid. In the excerpts presented here, we will see how the character of the representations work as ‘‘structuring resources’’ (<xref ref-type="bibr" rid="R22" id="51" class="deo:Reference">Lave, 1988</xref>) for the activity so that bodily action becomes central to children’s activity of ‘‘doing’’ programming. We discuss how this may point towards new directions in the development of new technological resources for developing dynamic and interactive systems.</region>
        <outsider class="DoCO:TextBox" type="header" id="42" page="4" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="43" page="4" column="1">1015</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="53" page="4" column="1">3. Case studies</h1>
        <region class="DoCO:TextChunk" id="57" page="4" column="1">Attempting to illustrate the diversity in how performance is and can be brought into children’s practical programming activities, we will present three separate fragments that we find typical for what we call ‘‘embodied programming’’: a domination of social and embodied aspects of interaction, structured by the physical manifesta- <marker type="page" number="5"/><marker type="block"/> tions of the tools. The excerpts are taken from three workshops in which different groups of children were engaged in activities of making own animated games and simulations using different programming tools and resources.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="55" page="5" column="1">1016</outsider>
        <outsider class="DoCO:TextBox" type="header" id="56" page="5" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
        <region class="DoCO:TextChunk" id="58" confidence="possible" page="5" column="1">• The first fragment is an ethnographic account of a setting where two boys are building a game in a visual programming environment installed on a laptop PC. The fragment illustrates how gestures and body language in interplay with external artefacts are important resources when the children negotiate and decide what to program. • The second fragment is taken from an exploratory activity where a group of children collaboratively debug a program through an offline role-play. The fragment points to the usefulness of activities that explicitly use embodied performances as a part of programming activities for children. • The third fragment could be thought of as a design and technology intervention, showing a group of children who program together in a tangible programming space. The system that the children use was designed based on insights from our previous work.</region>
        <region class="DoCO:TextChunk" id="59" page="5" column="1">Our analyses are based on detailed description of the actions and interactions of the children participating in the activities. The children’s talk was originally in Swedish, and has been translated to English by the authors. Snapshot pictures are used to illustrate particular physical actions, which are sometimes highlighted using arrows and other graphical markings. By studying the interactions on such fine-grained level of analysis, we hope to be able to describe the actual character of the activity that the children engage in. We have excluded the children’s origi- nal utterances in Swedish, partly because of the very crude character of these utterances, but also to emphasise the importance of the non-verbal actions that the children take. In the transcripts talk is in italics and other actions within brackets.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="60" page="5" column="1">3.1. Bodily action in shifting focus between different media</h2>
          <region class="DoCO:TextChunk" id="75" page="5" column="1">In this excerpt two boys, Adam and Fabian, are working on the task of building a game in the animated programming language ToonTalk ( <xref ref-type="bibr" rid="R17" id="61" class="deo:Reference">Kahn, 1996</xref>). The programming environment is designed particularly for children, and is based upon concrete metaphors represented in a visual and partially animated interface. The game that the children are working on is described on a paper illustration (<xref ref-type="fig" rid="F1" id="62" class="deo:Reference">Fig. 1</xref>) that they have to the left side of the computer. The conversation in this except primarily concerns how to interpret the static representation on the paper illustration, so that they can go on to specify how the objects in the game should be moving and acting. In order to express their ideas of how to program the dynamics in the game, they largely use gesture as a means of articulation. The excerpt starts when Adam and Fabian have just finished programming one of the characters (‘‘the girl’’) in the game and are moving on to discuss how the next character should be programmed.<marker type="page" number="6"/><marker type="block"/> See Excerpt 1, displayed on next page. The excerpt starts out by Adam suggesting how one of the characters in the game, a water-skier, should move (line 57). The suggestion is achieved by combining talk (‘‘should go like this’’) and gesture (waving the left hand) where the waving of the hand provides a means of proposing and describing a motion for the water-skier from right to left. This description would supposedly have required more effort to describe in words and yet been less precise. The suggestion is refined by Fabian (58) in the following turn where he says that the water-skier should move ‘‘behind’’. Exactly at the moment after saying ‘‘behind’’ he also makes a cir- cular gesture to specify what ‘‘behind’’ should mean in this particular situation, since the meaning of ‘‘behind’’ is ambiguous in this context. From what can be interpreted from the following turns, Fabian uses ‘‘behind’’ as a description for how an object is invisibly being moved across the scene from one side to the other. In line 59, Adam repeats Fabian’s ‘‘behind’’ in a low pitch tone of voice that suggests to Fabian that he is still not really sure what ‘‘behind’’ should mean in this particular situation. In the following turn (61) Adam moves his gaze towards Fabian immediately after saying ‘‘what’’, and provides a description that he leaves open (line 62: ‘‘then like [do -]’’). Fabian responds to this by attempting to refine his explanation. This is achieved by picking up the piece of paper, and thereby moving the attention away from the computer screen. In lines 63– 66 Fabian uses the paper in combination with talk and gesture to elaborate on his description. Previously he tried to do this by using the screen as the primary reference point, now the piece of paper works as an alternative and less compli- cated representation of what they are building. The screen is filled with a large number of objects, pictures, and programming resources which requires substantial work<marker type="page" number="8"/><marker type="block"/> to talk about. By using a gesture indexed towards the paper illustration they are able to ‘‘leave’’ the screen and instead create an alternative space in which it is easier to focus and discuss the behaviour of an object. In summary, what the children repeatedly have to do throughout this passage is to establish a way of referencing ‘‘things’’ that are not available, neither on the screen nor in the piece of paper. They have to make substantial efforts in estab- lishing a way of ‘‘talking’’ what they are about to program before they can go on to actually build it. In doing that, explicitly conducted performance of bodily action such as gesture and programming interface actions play a significant role. By combining talk and gesture in relation to the paper representation and to the programming system, the children are able to mutually construct a space for talk- ing about and acting upon the properties of the common object that they are working on. In this case the children worked with a visual programming environment, consisting of concrete visual objects that naturally affords pointing and use of deictic state- ments such as ‘‘that’’ and ‘‘there’’. However, the programming resources in this example do not appear to support the physical performances that the children need to express and share their ideas with one another. To perform and negotiate in the programming activity, the children ‘‘leave’’ the space on the screen and instead act out ideas in the social space and with tangible resources (the paper in this case). This implies a demand for programming objects that more freely can be used both for immediate programming purposes as well as for social purposes involved in the activity. Naturally, activity of similar character as we have shown here also occurs in the use of text-based representations for programming, i.e., bodily actions become a part in meaning-making and understanding of programming actions, especially when developing systems that are rich in terms of animation and interaction. However. when the actual resources are based on visual or tangible representations, such bodily means for articulation get even more interweaved into the activity, since also the interface manipulations become concrete rather than symbolic in kind. This will be further illustrated in our final excerpt.</region>
          <outsider class="DoCO:TextBox" type="header" id="64" page="6" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="65" page="6" column="1">1017</outsider>
          <region class="DoCO:FigureBox" id="F1">
            <image class="DoCO:Figure" src="62ig.page_006.image_02.png" thmb="62ig.page_006.image_02-thumb.png"/>
            <caption class="deo:Caption" id="67" page="6" column="1">Fig. 1. Paper illustration of the game.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="page_nr" id="69" page="7" column="1">1018</outsider>
          <outsider class="DoCO:TextBox" type="header" id="70" page="7" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <region class="DoCO:FigureBox" id="Fx71">
            <image class="DoCO:Figure" src="62ig.page_007.image_03.png" thmb="62ig.page_007.image_03-thumb.png"/>
            <image class="DoCO:Figure" src="62ig.page_007.image_04.png" thmb="62ig.page_007.image_04-thumb.png"/>
            <image class="DoCO:Figure" src="62ig.page_007.image_05.png" thmb="62ig.page_007.image_05-thumb.png"/>
            <image class="DoCO:Figure" src="62ig.page_007.image_06.png" thmb="62ig.page_007.image_06-thumb.png"/>
            <image class="DoCO:Figure" src="62ig.page_007.image_07.png" thmb="62ig.page_007.image_07-thumb.png"/>
          </region>
          <region class="unknown" id="72" page="7" column="1">Excerpt 1.</region>
          <outsider class="DoCO:TextBox" type="header" id="73" page="8" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="74" page="8" column="1">1019</outsider>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="76" page="8" column="1">3.2. Enactment of programming elements</h2>
          <region class="DoCO:TextChunk" id="99" page="8" column="1">In the next fragment, we discuss an activity where a group of children is involved in controlling, running and representing parts of a game using low-fidelity resources away from the computer setting. The primary purpose of these kinds of activities is to collaboratively act out the workings of the different parts of a system as a way of discussing its functionality. Like research on ‘participatory simulations’ ( <xref ref-type="bibr" rid="R4" id="77" class="deo:Reference">Colella, 2000</xref>; <xref ref-type="bibr" rid="R32" id="78" class="deo:Reference">Resnick and Wilensky, 1998</xref>), the idea is that through collaborative and enacted performance of a system, the participants may find it easier to relate to the mechanisms involved in the system and how they relate to one another. In conventional participatory simulations, individuals use their bodies to enact the workings of different objects, for instance ants in an ant colony or the visual elements in a computer simulation. However, rather than<marker type="page" number="9"/><marker type="block"/> focusing on emergent phenomena arising from a large number of objects, the activity performed here more specifically focused on computational complexities involved in systems made up of a smaller set of objects, which could be controlled and shared by a small group of children. This is similar to standard tech- niques of low-fidelity prototyping (<xref ref-type="bibr" rid="R33" id="82" class="deo:Reference">Rettig, 1994</xref>), only that the focus is here explicitly on programming and implementation, rather than on general issues related to interface design. The activities normally start out from games and systems running on the computer, and during the activities, the systems often get ‘reprogrammed’ in several variations. The activity discussed here was introduced by the researchers by first showing and discussing a computer-version of a simple game displayed on a large screen. Eight children participated in the activity, and during the discussion each child got to identify a rule in the game, that they would later get to enact in the role-playing activity. Large paper elements representing the visual objects in the computer system were arranged on an area on the floor serving as the background (see <xref ref-type="fig" rid="F2" id="83" class="deo:Reference">Fig. 2</xref>). The two researchers were assigned the role of users, and the children took on the roles of ‘ro- bots’ responsible for the execution of one or a small set of rules. The game was then played by iteratively evaluating all the rules/behaviours in the system. In each itera- tion the children performed their actions if the conditions for their behaviour are fulfilled. In the following excerpt, the group has been playing for some time, and all the children have started to get used to their respective task and what they should be doing in the activity. To further open up for discussion, one of the researchers comes up with a provoking suggestion, to remove one of the robots in the game.<marker type="page" number="10"/><marker type="block"/> There are two issues that we would like to highlight in this excerpt. The first is that the children take on a first person perspective of the computational process. The children extensively identify themselves with the behaviours that they are responsible for, referring to them as ‘‘me’’, ‘‘we’’ and ‘‘her’’. This personal iden- tification with the programming rules seems to play an important part when they discuss the researcher’s suggestion in line 1, that they should try something else. Sandra saying that she has not performed her action yet became a trigger for the rest of the group to discuss why this was the case and if removing any other ‘‘ro- bot’’ would have the effect that Sandra still would not get a chance to perform her actions. For instance, in turn 5 where Per makes a suggestion for why Sandra did not get a chance to execute her action as she had complained about in turn 3, he pairs his program action together with Lisa since both their actions concerned the same object. Lisa kept moving the object down, Per was responsible for moving it to the top again when it reached the bottom, and Sandra was responsible for removing the player object if it collided with the object controlled by Lisa and Per. Note also that even in this very short passage five of the eight children were actively engaged in analysing the consequences of removing a robot. The suggestion initiated by the researcher in turn 1 appear to work as a catalyst for the whole group to get involved in a negotiation of the role played by the different objects and behaviours that build up the system. The actions of each child were grounded in the previous turns and almost in every case explicitly considered different aspects of the relations between themselves and the objects in the system. Tom’s proposal<marker type="page" number="11"/><marker type="block"/> in turn 10 is an excellent example of how the suggestion by Klas in turn 6 is picked up by another participant in the group. Tom tries to make Klas’s suggestion under- standable to the others by drawing an analogy to the objects and the rules, and the children handling these on the left part of the game. Since these have similar behaviours as those on the right side, the same argument should be valid for Anna and Ida on their side of the game. The second issue that we would like to bring up concerns how the relation between one’s own and other’s physical position around the game becomes an essential part in the activity. In turn 6, Klas brought up a consequence of removing the rule that he was responsible for. If that rule was removed then Sandra’s would also have to be removed since her rule would then never trigger. When explaining this relationship, he begins by referring to his own physical position: ‘‘because I stand to the right’’ (turn 8). The children have arranged themselves around the game so that their program actions in the game correspond to the way they are physically located. By referring to his own physical location, it is hence possible for the others to see that he is the one who would move the bug in the direction of Sandra and that if he would be removed then Sandra would still not get a chance to trigger. Several of the turns that followed were of similar character, taking dependencies and relations between objects into consideration, with reference to ones own and others’ physical positions and actions in the game. Staged activities such as these have been performed in a range of different settings and with different resources, all aiming to allow children to discuss and share ideas about the inner workings of a computational system. <xref ref-type="fig" rid="F3" id="93" class="deo:Reference">Fig. 3</xref> shows an activity where a group collaboratively control a Lego robot through a manual random number gen- erator, created by resources that the children brought from another play-setting, ‘‘spin the bottle’’. As was the case in the fragment above, the children quickly took on different roles in the activity, such as for message passing and execution, and did in this sense also display a first person engagement in the activity. The social setting<marker type="page" number="12"/><marker type="block"/> here also seemed to work as a trigger for discussing the technical structure of the system that they explored, as well as providing a stage for physically acting out and displaying those ideas to one another. Bringing an activity out to the physical space, and making it explicitly collaborative, adds new dimensions to what the activity is about. Clearly for the children, these activities were not only about building and discussing program functionality, but just as much about being part in a group and performing in the social setting. Our first example showed how the PC-setting restricted the possible ways that the children could perform towards one another, and how the children had to create an alternative space away from the computer to discuss important aspects of what they were building. In this example, physical performances were not only used to discuss and express aspects of a computational system, but also contributed to structure the activity to become highly social and collaborative in character. This suggests how tools and resources play a central role for actions that build up the social space of an activity, in this case as a collaborative performance away from the direct programming context.</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="80" page="9" column="1">1020</outsider>
          <outsider class="DoCO:TextBox" type="header" id="81" page="9" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <region class="DoCO:FigureBox" id="F2">
            <image class="DoCO:Figure" src="62ig.page_009.image_08.png" thmb="62ig.page_009.image_08-thumb.png"/>
            <caption class="deo:Caption" id="86" page="9" column="1">Fig. 2. The group engaged in the activity.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="header" id="87" page="10" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="88" page="10" column="1">1021</outsider>
          <region class="unknown" id="89" page="10" column="1">Excerpt 2.</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="91" page="11" column="1">1022</outsider>
          <outsider class="DoCO:TextBox" type="header" id="92" page="11" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <region class="DoCO:FigureBox" id="F3">
            <image class="DoCO:Figure" src="62ig.page_011.image_09.png" thmb="62ig.page_011.image_09-thumb.png"/>
            <caption class="deo:Caption" id="96" page="11" column="1">Fig. 3. A role-play activity around a tangible lego robot.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="header" id="97" page="12" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="98" page="12" column="1">1023</outsider>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="100" page="12" column="1">3.3. Bodily action with tangible programming resources</h2>
          <region class="DoCO:TextChunk" id="122" page="12" column="1">The following fragment is taken from a workshop in which children used a tangible programming system for building a game displayed on a wall ( <xref ref-type="bibr" rid="R9" id="101" class="deo:Reference">Fernaeus and Tholander, 2006</xref>). The design of the system is based on experiences such as the ones described above, with the goal to allow children to more extensively use bodily action in programming. The system takes the shape of a physical space, (see <xref ref-type="fig" rid="F4" id="102" class="deo:Reference">Fig. 4</xref>) equipped with a number of tangible resources laid out on a surface on the<marker type="page" number="13"/><marker type="block"/> floor. The tangible resources are used to manipulate the looks and the behaviour of visual objects displayed on the screen. <xref ref-type="fig" rid="F1" id="108" class="deo:Reference">Fig. 1</xref> shows the physical setup of the system, consisting of a large mat with a grid of wirelessly identifiable position tags under- neath, a set of plastic programming cards, several tangible creator blocks that are wirelessly connected to the software on the computer, and a visual display showing the system that is being built. The creator blocks are used to connect the physical actions with the system that is being programmed on the screen. When users interact with the system, they add pictures to the screen display and program those by placing cards on top of the creator blocks (see <xref ref-type="fig" rid="F2" id="109" class="deo:Reference">Fig. 2</xref>). Rectangles displayed on the screen indicate where each creator block is located on the mat. Picture cards are used to place new objects at specific locations on the screen, while other cards are used to specify the functionality and change programming properties of objects that have already been added, or for controlling the system as a whole, such as running, stopping and saving a game or simulation. Throughout the analysis we attempt to illustrate how the tangibility of the system allows the performance of bodily action to become a central element in the use of the system, as well as for interaction with each other. In this specific excerpt, the children are in a process of programming the first object to populate their game world. The children have already added a picture (a baby Bedouin) to the screen, and programmed it so that it will be able to move when the game is playing. The children are now discussing what other properties and behaviours that should be assigned to the picture that they have just added to the screen. The system allows for adding the logical property of ‘‘colour’’ to any picture, which can be used as a way of specifying interaction between specific objects. Though there are three different readers available on the mat, all children are here focusing on the one currently controlled by Sebbe (see <xref ref-type="fig" rid="F5" id="110" class="deo:Reference">Fig. 5</xref>).<marker type="page" number="14"/><marker type="block"/> The excerpt consists of a short negotiation regarding what colour-property that the children should assign to the baby Bedouin, resulting in the agreement of giving it the colour ‘‘green’’. What we would like to emphasise here is how this negotiation to a large extent is based upon physical performance in the social setting. One could expect that deciding upon a conceptual content of assigning properties and defining relations within a group of five children would require substantial verbal elabora- tions in order to be settled. This was partly the case also for this group, but just as importantly, physical actions like glancing at the wall projection, holding up a card, handing over a card to someone all significantly shaped the interaction and coordinated the programming actions. Note first how the group as a whole has arranged themselves to make the activity a joint endeavour in which everyone can contribute. The physical resources being spread on the floor surface allow the children to physically position themselves to face one another and at the same time keep their focus directed towards the set of physical resources collected on the surface between them. Consider for instance how Sebbe, who in this sequence is most active in manipulating the tools, is facing away from the screen display. To check what is happening on the screen requires that he turns away from the rest of the group (see <xref ref-type="fig" rid="F5" id="118" class="deo:Reference">Fig. 5</xref>). Such physical action becomes a natural and embodied way of signalling a temporary shift of attention: away from the group and towards the screen display. Thereby the physical distribution of the tools and the actual positioning of the children in the group provide additional options for indicating to others what one is doing at a particular moment, through<marker type="page" number="15"/><marker type="block"/> bodily as well as verbal action. In a more conventional setting with only mouse and keyboard as interactive resources, such shifts of attention is naturally much more subtle, requiring more interactive work, e.g., through pointing and verbal explanations, in order to create a shared focus throughout the activity. Note also how physical action with the cards became a significant part of the negotiation, carrying as much meaning as the actual talk. This may be especially evident for instance in Niki’s utterance in turn 5, (‘‘it can be blue’’), while she simultaneously puts her hand on a card. In other instances throughout the activity the names of colours were a cause of confusion in the group, since having a colour can refer to an object’s natural colour as well as a programmed property of an object. However, through Niki’s pointing towards a programming card she provides a contextual framing that indicates that it is the programming property ‘‘blue’’ that she is referring to here, which also appears to be how this is interpreted by the other children. The physical action thereby serves to demarcate the range of potential meanings that the spoken utterance could otherwise have. It should also be noted that the cards are not just any physical objects – they are also the resource that the children use to complete the result of the negotiation. This means that the cards may function as external ‘memories’ of the current sta- tus of the discussion, while also being the means used for actually completing what gets agreed upon. Acting with the cards therefore became closely interweaved with children’s talk, negotiation and decision-making throughout the programming process. We would also like to bring up how Sebbe, who during this sequence seems to hold the responsibility of placing cards on the interactive reader block, repeatedly acts to make the rest of the group involved in this aspect of the activity. Just as Sebbe is about to place the ‘‘green’’ card on the reader (line 14), he moves back, rises slight- ly and points with his index finger saying ‘‘and the red are the evil’’. In doing this, he signals to the group a possible consequence of this action: if the baby should be ‘green’, then an effect could be that the ‘evil’ ones (e.g., a ‘Dracula’-character that they had been planning to add) should have the colour property ‘‘red’’. Note how Sebbe’s talk is expressed along with very specific bodily action: lifting his gaze from the reader and the cards to instead face the group, and temporarily moving the card away from the reader. Through these actions, Sebbe provides a space for anyone who would like to object to his idea to do so, while also indicating to the group that there should be joint agreement with the suggested action. In more conventional PC-settings, controlling the mouse and keyboard often becomes a source of negotiation and control of power. In the setting studied here, the technology is instead distributed over a fairly large number of tangible artefacts, making it difficult to take individual control over all the available cards and the readers at the same time. This seem to have provided for a more seamless integration between the social and the computational space, allowing for a joint performance between several children in a process in which social, creative and constructive aspects successfully blend together. Through making the resources tangible, children can physically express the intended functionality of the games at the same time as they discuss, refine, and actually realise their ideas.</region>
          <region class="DoCO:FigureBox" id="F4">
            <image class="DoCO:Figure" src="62ig.page_012.image_10.png" thmb="62ig.page_012.image_10-thumb.png"/>
            <caption class="deo:Caption" id="105" page="12" column="1">Fig. 4. Overview of the tangible programming system.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="page_nr" id="106" page="13" column="1">1024</outsider>
          <outsider class="DoCO:TextBox" type="header" id="107" page="13" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <region class="DoCO:FigureBox" id="F5">
            <image class="DoCO:Figure" src="62ig.page_013.image_11.png" thmb="62ig.page_013.image_11-thumb.png"/>
            <caption class="deo:Caption" id="113" page="13" column="1">Fig. 5. A picture is added to the display.</caption>
          </region>
          <outsider class="DoCO:TextBox" type="header" id="114" page="14" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="115" page="14" column="1">1025</outsider>
          <region class="DoCO:FigureBox" id="Fx116">
            <image class="DoCO:Figure" src="62ig.page_014.image_12.png" thmb="62ig.page_014.image_12-thumb.png"/>
          </region>
          <region class="unknown" id="117" page="14" column="1">Excerpt 3.</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="120" page="15" column="1">1026</outsider>
          <outsider class="DoCO:TextBox" type="header" id="121" page="15" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="header" id="123" page="16" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="124" page="16" column="1">1027</outsider>
        </section>
      </section>
      <section class="deo:Discussion">
        <h1 class="DoCO:SectionTitle" id="125" page="16" column="1">4. Discussion</h1>
        <region class="DoCO:TextChunk" id="146" page="16" column="1">The educational values of interactive resources that allow for physical manipulation have been extensively discussed, for instance by <xref ref-type="bibr" rid="R23" id="126" class="deo:Reference">Marshall et al. (2003)</xref>, and later by <xref ref-type="bibr" rid="R40" id="127" class="deo:Reference">Zuckerman et al. (2005)</xref>. Aspects that are emphasised in this research are primarily how tactile and haptic properties of tangible artefacts allow for richer interactive experiences with the tools, thereby providing increased possibilities for reflection and understanding. The potential benefits of being able to act collectively are men- tioned as an integral part of this, however the descriptions have mostly focused on the perspective of a single user in interaction with the technology. <xref ref-type="bibr" rid="R31" id="128" class="deo:Reference">Price and Rogers (2004)</xref> extend this discussion to further point to the educational benefits of bodily action with new technology, where physical action can be seen to add a new dimension, bridging practical and theoretical action and thereby making abstract concepts more concrete. However, in neither of these cases have the physical actions been explicitly studied as social performances directed towards and responded by in a group. With the analyses that we have presented here, we hope to extend this perspective to further point to the interactional benefits of being able to physically act in a social and collaborative setting. Several projects based on room-size technologies (such as <xref ref-type="bibr" rid="R2" id="129" class="deo:Reference">Alborzi et al., 2000</xref>; <xref ref-type="bibr" rid="R5" id="130" class="deo:Reference">Decortis and Rizzo, 2002</xref>; <xref ref-type="bibr" rid="R36" id="131" class="deo:Reference">Stanton et al., 2001</xref>) are closely related to this, emphasising how children may perform towards one another with the technology. One illustrative example is the StoryRooms project (<xref ref-type="bibr" rid="R2" id="132" class="deo:Reference">Alborzi et al., 2000</xref>), where children’s storytelling activities, in the form of enacting and performing a story in a physical room, were used both as part of the process of designing the room, as well as when the children use the room to tell a story. However, in their case, programming and configuring of the room is designed as a tool for supporting play and storytelling, while the project discussed here is defined the other way around, i.e., that play and performance work as an integral part of children’s programming activity. However, both approaches share the objective of regarding bodily performance as an essential part of interacting with the technology. Throughout this paper we have illustrated how physical performance can be an important element in children’s programming activities. Our first example showed how external resources, such as gesture directed towards a paper, are used to negotiate ideas around the dynamic properties of a game that is being built on the screen. The second example was taken from a collaborative role-play activity, showing how bodily enactment with physical resources can add a social dimension to discussing and debugging the workings of a computer game. The third example showed how computationally enhanced tangible objects work to bridge children’s social negotiation with actual implementation on the computer. By conceptualising programming in these settings through the concept of performance, we are able to point out aspects that are otherwise often neglected in design of programming tools and environments. The primary observation is that programming in all these situations is largely becom- ing an embodied activity in which physical performance is central. The children extensively rely upon and make use of bodily action and manipulations of interface elements, and they do this for communicative and collaborative purposes. The three<marker type="page" number="17"/><marker type="block"/> examples also show how different representational forms structure the activity and how actions that the children take are intrinsically intertwined with these. By investigating these issues we hope to contribute to development of method- ology within the areas of interaction design, and especially in the development of new systems for children’s collaborative programming activities. In the following we will point towards some future directions for designs that may bring the concepts of bodily performance in this area further. The aspects that we discuss are the possibilities of including full-body interactions, increased use of spatial properties of the room, and the need to further consider the social properties of interaction. Our first reflection concerns the potentials to more explicitly address the role of physical and bodily engagement in technologically rich settings. We have seen that when children construct dynamic systems, even with PC-based programming applications, a significant aspect of the activity is about physically displaying and acting out ideas and suggestions for one another. Through actions such as gesture and manipulation of the programming resources, dynamic properties and ideas for interaction are presented, discussed and argued for among the children. To achieve this, the children show an impressive creativity in inventing and appropriating alternative uses of the resources that they have at hand. These results are in line with work in CSCW (e.g., <xref ref-type="bibr" rid="R12" id="136" class="deo:Reference">Heath and Luff, 2000</xref>) and studies of social interaction (e.g., <xref ref-type="bibr" rid="R10" id="137" class="deo:Reference">Goodwin, 2000</xref>), but have rarely been introduced in studies of children’s programming. In the area of computer programming, there is instead a history of viewing interaction with the technology as mostly cognitively based, with focus on concepts such as memory, perception and conceptual understanding (see e.g., <xref ref-type="bibr" rid="R18" id="138" class="deo:Reference">Kelleher and Pausch, 2005</xref>). Naturally, physical aspects are central in most argumentations for tangible approaches to programming, however the designs have primarily addressed the needs of individual users, and the cognitive benefits from working hands on with physical programming objects (see e.g., <xref ref-type="bibr" rid="R24" id="139" class="deo:Reference">McNerney, 2000</xref>; <xref ref-type="bibr" rid="R30" id="140" class="deo:Reference">Patten et al., 2000</xref>). Even though those aspects are of much relevance, especially since programming is known to be a cognitively complex activity, further emphasis could be placed onto how users may account for ones actions in a group, and to act collectively around the resources. This implies that as designers we must consider how the objects that we create can be used for other purposes than mere computer manipulations. Especially in physical settings where participants can engage in full-body interactions such as jumping and dancing, we cannot take the viewpoint that all these actions are performed to be monitored by the system only. Instead, we need to consider also how the tangible objects can be used to possibly augment the social interactions that physical and collaborative activity inevitably entails. Another major consequence of the perspective of performance in programming is that it becomes problematic to attempt to separate social interaction from the practical implementation of a system. We have seen how the relation between negotiating ideas and to actually implement them on the computer seems to become more interweaved in tangible settings than is possible in settings where all resources are located on the computer screen. In order to meaningfully understand collaborative programming activities it could therefore be a mistake to<marker type="page" number="18"/><marker type="block"/> degrade the role of social interaction, since it appears to be such a central part of what the activity is about for the participants. In the case of the analyses presented here, the properties of the programming actions must instead be understood within a larger context of the children’s creative work. In that sense, the activity itself is a performance – it is not something that is there only to produce something that is to be used later on. Notably, in the last two excerpts that we presented, the technology allowed the participants to involve bodily actions and performances as part of their interactions with one another, as well as for conducting the actual task of the activity. Of particular importance was the possibility to spread the activity across the room, which allowed the children to continuously modify how the interactive artefacts were arranged in space. Physical objects can be used in a number of ways which may not be immediately designed for, such as being passed between one another, being hidden behind one’s back, and held up for demonstrative purposes. The artefacts were thereby used not only as tools for creating a system but also for developing a shared understanding of what to build. By closely consid- ering participants’ non-verbal actions and viewing them as conversational turns we could see how such actions shaped and contributed to the ongoing conversation, and not just as complimentary to verbal action in the process of implement- ing the systems. The tangible objects were in this sense extensively used for social ‘off-line’ interaction, as well as for interactions addressed towards the ‘system’. With only mouse and keyboard, users do not seem to have the same ability to make use of programming resources in their social interaction around what they are building. Most importantly, the perspective of performance with technology means that physical and bodily aspects of the interaction have become salient to us as analysts and subsequently in our design efforts. In our current work, we are exploring how bodily aspects of interaction can be further brought into activities in which building of dynamic systems plays a part. Larger-scale multimodal interaction, such as full body gesture interfaces (Ho  ̈ysniemi et al., 2005), interactive furniture (<xref ref-type="bibr" rid="R1" id="144" class="deo:Reference">Africano et al., 2004</xref>), and mobile technology (<xref ref-type="bibr" rid="R3" id="145" class="deo:Reference">Benford et al., 2005</xref>), are all being explored in design practice, especially in applications targeted at children. Based on a perspective of bodily performance, such technologies could hold strong potentials as resources for activities such as programming in collaborative settings, where bodily forms of expression can play an even more prominent role in the interactions than shown in the examples presented here.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="134" page="17" column="1">1028</outsider>
        <outsider class="DoCO:TextBox" type="header" id="135" page="17" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
        <outsider class="DoCO:TextBox" type="header" id="142" page="18" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="143" page="18" column="1">1029</outsider>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="147" page="18" column="1">Acknowledgements</h1>
        <region class="DoCO:TextChunk" id="148" page="18" column="1">Much of the ideas put forth in this paper have evolved in discussions with our reading and writing partners. Especially we thank Kristina Ho  ̈ o  ̈k, Petra Sundstro  ̈ m, Anna St  ̊hl, Jarmo Laksolaathi, A  ̊ sa Rudstro  ̈ m and Klas Karlgren. We also thank all the children who have contributed to this work through participating in the activities upon with this paper is based.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="149" page="19" column="1">1030</outsider>
        <outsider class="DoCO:TextBox" type="header" id="150" page="19" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="151" page="19" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="152" page="19" column="1">Africano, D., Berg, S., Lindbergh, K., Lundholm, P., Nilbrink, F., Persson, A. 2004. Designing tangible interfaces for children’s collaboration. Paper presented at the CHI 2004 extended abstracts on Human factors in computing systems.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="153" page="19" column="1">Alborzi, H., Druin, A., Montemayor, J., Sherman, L., Taxen, G., Best, J., et al. 2000. Designing StoryRooms: interactive storytelling spaces for children. Paper presented at the DIS 2000.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="154" page="19" column="1">Benford, S., Rowland, D., Flintham, M., Drozd, A., Hull, R., Reid, J., et al. 2005. Life on the edge: supporting collaboration in location-based experiences. Paper presented at the CHI 2005, Portland, Oregon, USA.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="155" page="19" column="1">Colella, V., 2000. Participatory simulations: building collaborative understanding through immersive dynamic modeling. The Journal of the Learning Sciences 9 (4), 471–500.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="156" page="19" column="1">Decortis, F.o., Rizzo, A., 2002. New active tools for supporting narrative structures. Personal and Ubiquitous Computing 6 (5–6), 416–429.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="157" page="19" column="1">Dourish, P., 2001. Where The Action Is: The Foundations of Embodied Interaction. Cambridge, Massachusetts Institute of Technology.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="158" page="19" column="1">Eisenberg, M., Eisenberg, A., Gross, M., Kaowthumrong, K., Lee, N., Lovett, W. 2002. Computationally enhanced construction kits for children: prototype and principle. Paper presented at the International Conference of the Learning Sciences, Seattle.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="159" page="19" column="1">Fernaeus, Y., Tholander, J., 2005. Looking at the computer but doing it on land’’: children’s interactions in a tangible programming space. Paper presented at the HCI 2005, Edinburgh.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="160" page="19" column="1">Fernaeus, Y., Tholander, J. 2006. Finding design qualities in a tangible programming space. Paper presented at the CHI 2006, Montreal.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="161" page="19" column="1">Goodwin, C., 2000. Action and embodiment within situated human interaction. Journal of Pragmatics 32 (10), 1489–1522.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="162" confidence="possible" page="19" column="1">Hanks, W.F., 1992. The indexical ground of deictic action. In: Duranti, A., Goodwin, C. (Eds.), Rethinking Context: Language as an Interactive Phenomenon. Cambridge University Press, Cambridge.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="163" page="19" column="1">Heath, C., Hindmarsh, J., 2000. Embodied reference: A study of deixis in workplace interaction. Journal of Pragmatics 32, 1855–1878.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="164" confidence="possible" page="19" column="1">Heath, C., Luff, P., 2000. Technology in Action. Cambridge University Press.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="165" page="19" column="1">Hutchinson, H., Mackay, W., Westerlund, B., Bederson, B.B., Druin, A., Plaisant, C., Beaudouin-Lafon, M., Conversy, S., Evans, H., Hansen, H., Roussel, N., Eiderbck, B., Lindquist, S., Sundblad, Y., 2003. Technology probes: inspiring design for and with families. Paper presented at the Proceedings of the SIGCHI conference on Human factors in computing systems, Ft. Lauderdale, Florida, USA.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="166" page="19" column="1">Ho  ̈ ysniemi, J., H  ̈m  ̈l  ̈inen, P., Turkki, L., Rouvi, T., 2005. Children’s intuitive gestures in vision-based action games. Communications of ACM 48 (1), 44–50.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="167" page="19" column="1">Jacucci, G. 2004. Interaction as performance cases of configuring physical interfaces in mixed media. Unpublished Ph.D. Thesis, University of Oulu, Oulu, Finland.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="168" page="19" column="1">Kahn, K., 1996. ToonTalk – An animated programming environment for children. Journal of Visual Languages and Computing 7 (2), 197–217.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="169" page="19" column="1">Kelleher, C., Pausch, R., 2005. Lowering the barriers to programming: a taxonomy of programming environments and languages for novice programmers. ACM Computing Surveys 37 (2), 83–137.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="170" page="19" column="1">Kindborg, M. 2003. Concurrent Comics – programming of social agents by children. Unpublished Ph.D. Dissertation, Linko  ̈ ping University, Linko  ̈ ping.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="171" page="19" column="1">Koschmann, T., LeBaron, C., 2002. Learner articulation as interactional achievment: studying the conversation of gesture. Cognition and Instruction 20 (2), 249–282.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="172" page="19" column="1">Laurel, B., 1993. Computers as Theatre. Addison-Wesley.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="173" confidence="possible" page="19" column="1">Lave, J., 1988. Cognition in Practice. Mind, mathematics and culture in everyday life. Cambridge University Press.</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="174" page="19" column="1">Marshall, P., Price, S., Rogers, Y. 2003. Conceptualising tangibles to support learning. Paper presented at the Interaction Design and Children.</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="175" confidence="possible" page="19" column="1">McNerney, T. 2000. Tangible Programming Bricks: An Approach to Making Programming Accessible to Everyone. Unpublished Master’s thesis, Massachusetts Institute of Technology.</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="178" page="20" column="1">McNerny, T.S., 2004. From turtles to Tangible Programming Bricks: explorations in physical language design. Personal and Ubiquitous Computing 8, 326–337.</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="179" page="20" column="1">Montemayor, J., Druin, A., Farber, A., Simms, S., Churaman, W., D’Amour, A. 2002. Physical programming: designing tools for children to create physical interactive environments. Paper presented at the CHI 2002, Minneapolis, Minnesota.</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="180" page="20" column="1">Nishizaka, A., 2000. Seeing what one sees: perception, emotion, and activity. Mind, Culture, and Activity 7 (1and 2), 105–123.</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="181" confidence="possible" page="20" column="1">Norman, D.A., 1993. Cognition in the head and in the world: an introduction to the special issue on situated action. Cognitive Science 17 (1), 1–6.</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="182" page="20" column="1">Oulasvirta, A., Kurvinen, E., Kankainen, T., 2003. Understanding contexts by being there: case studies in bodystorming. Personal and Ubiquitous Computing 7 (2), 125–134.</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="183" page="20" column="1">Patten, J., Griffith, L., Ishii, H. 2000. A tangible interface for controlling robotic toys. Paper presented at the CHI, Sunrotary.</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="184" page="20" column="1">Price, S., Rogers, Y., 2004. Let’s get physical: the learning benefits of interacting in digitally augmented physical spaces. Computers and Education 43 (1–2), 137–151.</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="185" page="20" column="1">Resnick, M., Wilensky, U., 1998. Diving into complexity: developing probabilistic decentralized thinking through role-playing activities. The Journal of the Learning Sciences 7 (2), 153.</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="186" page="20" column="1">Rettig, M., 1994. Prototyping for tiny fingers. Communications of the ACM 37, 21–27.</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="187" page="20" column="1">Rogers, Y., Price, S., Fitzpatrick, G., Fleck, R., Harris, E., Smith, H., et al. 2004. Ambient wood: designing new forms of digital augmentation for learning outdoors. Paper presented at the Proceedings of the International Conference on Interaction Design and Children (IDC 2004).</ref>
          <ref rid="R35" class="deo:BibliographicReference" id="188" page="20" column="1">Smith, D.C., Cypher, A., 1999. Making Programming Easier for Children. In: Druin, A. (Ed.), The Design of Children’s Technology. Morgan Kaufmann Publishers, pp. 202–221.</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="189" page="20" column="1">Stanton, D., Bayon, V., Neale, H., Ghali, A., Benford, S., Cobb, S., et al. 2001. Classroom collaboration in the design of tangible interfaces for storytelling. Paper presented at the CHI 2001.</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="190" page="20" column="1">Suchman, L., 1987. Plans and Situated Actions. Cambridge University Press.</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="191" page="20" column="1">Tholander, J. 2003. Constructing to Learn Learning to Construct – studies of computational tools for learning. Unpublished Doctoral dissertation, Stockholm University/Royal Institute of Technology, Stockholm.</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="192" confidence="possible" page="20" column="1">Wertsch, J.V., 1998. Mind as Action. Oxford University Press, New York, New York.</ref>
          <ref rid="R40" class="deo:BibliographicReference" id="193" page="20" column="1">Zuckerman, O., Arida, S., Resnick, M. 2005. Extending tangible interfaces for education: digital montessori-inspired manipulatives. Paper presented at the SIGCHI conference on Human factors in computing systems, Portland, Oregon, USA.</ref>
          <ref rid="R41" class="deo:BibliographicReference" id="194" page="20" column="1">Zuckerman, O., Resnick, M. 2003. A physical interface for system dynamics simulation. Paper presented at the CHI 2003, Ft. Lauderdale, Florida, USA.</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="header" id="176" page="20" column="1">Y. Fernaeus, J. Tholander / Interacting with Computers 18 (2006) 1012–1031</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="177" page="20" column="1">1031</outsider>
      </section>
    </body>
  </article>
</pdfx>

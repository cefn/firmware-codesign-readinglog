<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>1007c3aa4c5e7f704e95e8e165f4c87a9bbdbb5da388b906fa107375cbfb49a0</job>
    <base_name>62md</base_name>
    <doi confidence="possible">10.1007/978-3-642-31991-4_2</doi>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <title-group>
        <article-title class="DoCO:Title" id="1">Design Thinking Research</article-title>
      </title-group>
      <region class="unknown" id="2">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</region>
      <contrib-group class="DoCO:ListOfAuthors">
        <contrib contrib-type="author">
          <name id="3">Shelley Goldman</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="4">Maureen P. Carroll</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="5">Zandile Kabayadondo</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="6">Leticia Britos Cavagnaro</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="7">Adam W. Royalty</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="8">Bernard Roth</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="9">Swee Hong Kwek</name>
        </contrib>
        <contrib contrib-type="author">
          <name id="10">Jain Kim</name>
        </contrib>
      </contrib-group>
      <abstract class="DoCO:Abstract" id="11">The research explored the relationship of learning design thinking and assessing that progress. It addressed the questions: How can we understand what is learned in design thinking classes, and how assessments might contribute to that process in authentic ways? The study followed a reciprocal research and design methodology where basic research and the design of assessment solutions were ongoing, reciprocal, and related to each other in organic ways. We learned that the learning of design thinking dispositions and mindsets is an emergent journey—with various levels of sophistication, transformation, application, and integration. We introduce the concept of mindshifts to represent the developing and nascent epistemological viewpoints and instincts that are strengthened while becoming a design thinker. We</abstract>
      <region class="unknown" id="13">S. Goldman ( * ) Stanford University School of Education - Professor (Teaching) of Education and, by courtesy, of Mechanical Engineering e-mail: <email id="12">sgoldman@stanford.edu</email> M.P. Carroll Stanford University School of Education - Research Staff Z. Kabayadondo Stanford University School of Education - PhD Candidate L.B. Cavagnaro Stanford University Technology Ventures Program - Associate Director A.W. Royalty Stanford University Hasso Plattner Institute of Design - Academic Staff B. Roth Stanford University School of Engineering - Professor and Hasso Plattner Institute of Design Academic Director S.H. Kwek Stanford University School of Education - Master’s Degree Graduate J. Kim Stanford University School of Education - Master’s Degree Graduate</region>
      <outsider class="DoCO:TextBox" type="page_nr" id="14">13</outsider>
      <outsider class="DoCO:TextBox" type="footer" id="15">H. Plattner et al. (eds.), Design Thinking Research, Understanding Innovation, DOI 10.1007/978-3-642-31991-4_2, # Springer-Verlag Berlin Heidelberg 2012</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="16">14</outsider>
      <outsider class="DoCO:TextBox" type="header" id="17">S. Goldman et al.</outsider>
      <region class="DoCO:TextChunk" id="18">review designs for tools that were based on the concept of mindshifts that include reflective and performance assessments and an assessment dashboard.</region>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="19" page="2" column="1">1 Introduction and Background</h1>
        <region class="DoCO:TextChunk" id="25" page="2" column="1">As students become design thinkers, they emerge with significant changes in their approaches to problem solving and to new challenges. They start to develop a sense of resiliency that enables them to think “outside the box.” This research explored the experiences of students while they were enrolled in a university course at the Hasso Plattner Institute of Design at Stanford University and took up questions about the relationship between learning design thinking and assessing progress. To pursue the metaphor, assessment is often described as a “black box” activity, with students being tested and assessed outside of the actual learning process. <xref ref-type="bibr" rid="R5" id="20" class="deo:Reference">Black and Wiliam (1998)</xref> describe how policies in the U.S. and in many other countries seem to treat the classroom as a black box, where certain inputs from the outside are fed into the box, and from which students emerge with certain competencies. Our goal was to understand, document, and design tools that could help assess what students were learning in design thinking courses. We sought to bring assessment “into the box” of the university design thinking courses as students were learning how to think “outside the box”. We sought to understand the learning experience of the students in ways that would provide a reflection of progress made towards design thinking based on their authentic, course-based experiences. We hoped the work would have implications for both students and their course instructors. Students could better reflect on and have information about their evolving design learning. Instructors would be able to reflect on the progress of the individual and their design team, and use the information to reorganize teaching and curriculum to better meet the needs of students. The research addressed the following key questions: How can we understand what is learned in design thinking classes, and how might assessments contribute to that process in authentic and helpful ways? The study followed a reciprocal research and design (RR&amp;D) process and methodology (<xref ref-type="bibr" rid="R1" id="21" class="deo:Reference">Alexander et al. 2010</xref>). In the RR&amp;D model, basic research and the development of solutions are on-going, and are reciprocal and related to each other in organic ways. In this project, interim findings of studies of students in design thinking courses and activities were utilized as needs assessments for emergent assessment designs. This was done in such a way that after each round of data gathering and analysis, the preliminary results contributed to the creation of performance and reflection-based assessments. Design thinking aspects of the RR&amp;D model influenced the research, which included interviews, observations, analysis/ synthesis, and ideation to iterate successive prototypes of assessment tools for both students and their instructors. One such implement emerging from this process was the concept of a dashboard with tools for tracking how students are learning the art and practice of design thinking.<marker type="page" number="3"/><marker type="block"/> This paper chronicles the research and design process and its results. The research began by building on and adapting findings from a prior study we completed on assessment that occurred in K-12 educational settings and resulted in the development of a Design Thinking Assessment Rubric. That research resulted in a prototype of a rubric for documenting and assessing the skills and processes that students come in contact with while learning in the context of design thinking classrooms. The rubric allows the documentation of skills and processes learned such as interviewing, brainstorming and prototyping. That rubric provided a starting point for the research on assessment reported herein, which focused on graduate student design thinking classrooms at Stanford University’s Hasso Plattner Institute of Design.</region>
        <outsider class="DoCO:TextBox" type="header" id="23" page="3" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="24" page="3" column="1">15</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="26" page="3" column="1">2 From Mindsets to Mindshifts</h1>
        <region class="DoCO:TextChunk" id="35" page="3" column="1">Through this study we have been able to rethink, redevelop, and redefine ideas about the assessment challenges related to design thinking. We were able to redefine the parameters and complexity of design thinking assessments and refine a rubric and its uses for students and their instructors. Ultimately, the study helped us gain further understanding of the different skills, stages, and mindsets of design thinking, their evolution among students, and their relationships to each other. This last finding was most significant: we could develop assessments to capture the complexity and nested relationships of design thinking skills, processes and mindsets. One nuance of this complexity was to consider and capture, instead of static mindsets, mindshifts that result from the process of learning design thinking came into being. Since we consider the learning of design thinking dispositions as an emergent journey—with various levels of sophistication, transformation, application, and integration—we use the term mindshifts to represent the active shifts that students are making. Mindshifts are the developing and often nascent epistemological viewpoints and instincts that are strengthened (or instilled) and made observable through change in a learner’s orientations and actions as a design thinker. Mindshifts are significant in the design thinking learning arc. For many students they are the re-synthesis and reorientation of their worldviews, routes, and propensities in problem solving. They require new categories and sensibilities. Even as students are making changes to their categories or worldviews, they hold on to and integrate old and new ways of thinking and acting. There is a long history of ideas about how conceptual shifts can be understood. <xref ref-type="bibr" rid="R39" id="27" class="deo:Reference">Wallace (1956)</xref> examined how changes in cultural thinking and worldviews were possible. Sometimes the shifts were violent and intense, and at other times they were more gradual, with a back and forth between old and new views of the world and how to act in it. Mindshifts are not always at the cultural level, and can occur at more local levels. Carol Dweck’s work (2007) on fixed and growth mindsets shows how growth mindsets can be learned—hard work and a propensity towards problem solving and action can lead to great learning and to productivity. Studies in physics education also show how students’ na  ̈ve ideas about the physical world could be<marker type="page" number="4"/><marker type="block"/> reorganized through instruction (<xref ref-type="bibr" rid="R35" id="33" class="deo:Reference">Smith et al. 1993</xref>). We think of mindshifts in a similar vein. Design thinking students accomplish new mindshifts as they learn and become experienced. Design thinking mindshifts differ from design skills and processes. They often seem synthetic to other skills and processes, and are the superstructure of a learned design thinker. They are difficult to observe, but it is possible to uncover and identify them. These ideas about mindshifts led to a framework for reflective assessment activities, a performance-based rubric for skills and processes, and an assessment dashboard for managing information about what is learned. As such, the conception of mindshifts challenged our assumptions about how to assess design thinking. We initially focused primarily on process and skill development and on how to assess these, but later prioritized the identification of mindshifts, which we defined as epistemological viewpoints that are evident by a change in one’s orientation as a design thinker (<xref ref-type="fig" rid="F1" id="34" class="deo:Reference">Fig. 1</xref>). This understanding led us to a deeper investigation of the transitional nature of what it means to adopt the orientation of a developing design thinker. Of the conceptual shifts we identified, we focused on four key mindshifts: human-centered; experimental; collaborative; and metacognitive.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="29" page="4" column="1">16</outsider>
        <outsider class="DoCO:TextBox" type="header" id="30" page="4" column="1">S. Goldman et al.</outsider>
        <region class="DoCO:FigureBox" id="F1">
          <image class="DoCO:Figure" src="62md.page_004.image_01.png" thmb="62md.page_004.image_01-thumb.png"/>
          <caption class="deo:Caption" id="32" page="4" column="1">Fig. 1 Mindshifts</caption>
        </region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="36" page="4" column="1">2.1 Human-Centered</h2>
          <region class="DoCO:TextChunk" id="40" page="4" column="1">The human-centered mindshift is characterized by a central focus on empathy for others. We focused our work specifically on assessments that help make visible and document the development of students’ human-centered mindsets. When students are developing a human-centered mindset, they begin to move beyond egocentric views of the world and no longer design based on their own needs, desires, <marker type="page" number="5"/><marker type="block"/> experiences or preferences. Becoming human-centered is a fluid and dynamic process where students actively seek solutions to problems that meet the needs of others who might benefit from their innovation or design. Each engagement takes students toward being more human-centered and can help them see, consider, interact with, and have empathy for others. A human-centered mindset is an integral, necessary and distinguishing element of design thinking. While we see that students can accomplish human-centered mindshifts, we suggest that the tasks developed and researched can be perform as near transfer tasks for examining students’ development of a “human centered” mindset.</region>
          <outsider class="DoCO:TextBox" type="header" id="38" page="5" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="39" page="5" column="1">17</outsider>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="41" page="5" column="1">2.2 Experimental</h2>
          <region class="DoCO:TextChunk" id="42" page="5" column="1">The experimental mindshift is characterized by a realization that everything may be considered a prototype. Having an experimental stance changes one’s approach to problem solving by allowing one to do, make, and visualize as integral parts of thinking and of the evolving ideas.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="43" page="5" column="1">2.3 Collaborative</h2>
          <region class="DoCO:TextChunk" id="44" page="5" column="1">The collaborative mindshift is characterized by a belief that collaboration is a key component of problem solving, and that radical collaborations undergird transformative innovation.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="45" page="5" column="1">2.4 Metacognitive</h2>
          <region class="DoCO:TextChunk" id="46" page="5" column="1">The metacognitive mindshift is characterized by an awareness that it is essential to be aware of where one is in the design thinking process in order to agilely respond to changing parameters of a problem.</region>
        </section>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="47" page="5" column="1">3 Needs</h1>
        <region class="DoCO:TextChunk" id="61" page="5" column="1">It is critical that students master both the knowledge of core subjects and the critical skills necessary for readiness in the innovation economy of the twenty-first century. Twenty-first century skills include critical thinking and problem solving, communication, collaboration, and creativity and innovation ( <xref ref-type="bibr" rid="R33" id="48" class="deo:Reference">Partnership for 21st Century Skills 2008</xref>). Content learning, life skills, innovation, and fluency with technologies such as media and web functionalities are also included. These skills are considered essential for developing a participatory, innovative, and technologically sophisticated culture; and contribute to the personal, educational, professional, and civic<marker type="page" number="6"/><marker type="block"/> lives of learners (<xref ref-type="bibr" rid="R23" id="52" class="deo:Reference">Jenkins 2006</xref>; <xref ref-type="bibr" rid="R23" id="53" class="deo:Reference">Jenkins et al. 2006</xref>). Design thinking, with its focus on problem solving and creative confidence, is nested within this view of cultural shift. Such new learning goals create a critical need to understand how design thinking is integrated into classroom learning environments. A need for new metrics and assessment methodologies accompanies these new ways of learning, as educators become increasingly aware that measures of student progress need to align with the new skills required for school, entry to the work- force, and life (<xref ref-type="bibr" rid="R11" id="54" class="deo:Reference">COSEPUP 2006</xref>). The US <xref ref-type="bibr" rid="R12" id="55" class="deo:Reference">National Science Foundation Task Force on Cyberlearning (2008)</xref> described this need as follows: Despite the revolutions wrought by technology in medicine, engineering, communications, and many other fields, the classrooms, textbooks, and lectures of today are little different than those of our parents. Yet today’s students use computers, mobile telephones, and other portable technical devices regularly for almost every form of communication except learning. The time is now—if not long overdue—for radical rethinking of learning and of the metrics for success.<marker type="block"/> President Obama has also recognized the critical need to measure twenty-first century skills, calling on the nation’s governors to: . . . develop standards and assessments that don’t simply measure whether students can fill in a bubble on a test, but whether they possess 21st century skills like problem-solving and critical thinking and entrepreneurship and creativity (<xref ref-type="bibr" rid="R31" id="57" class="deo:Reference">Obama 2009</xref>).<marker type="block"/> Most of the assessment done today is after the fact and designed to indicate only whether students have learned. Not enough is done to collect and aggregate data about student learning that makes the information valuable to and accessible by stakeholders who might support continuous improvement and innovation. Very few assessments are authentic to classroom-supported learning activities or to the application of what is learned out of school situations (<xref ref-type="bibr" rid="R2" id="59" class="deo:Reference">Baker 2010</xref>). Generally, assessments do not give students access to, or active participation in, their own learning progressions. <xref ref-type="bibr" rid="R34" id="60" class="deo:Reference">Silva (2008)</xref> describes the creation of effective measures of twenty-first century skills, and the need for better and more comprehensive assessments that measure both the ability to think creatively and to evaluate information, and student’s mastery of core content or basic skills and knowledge. These notions of complex, holistic and performance-based measures relating to innovation learning were central to this project’s research focus and the development of assessment tools that could begin to capture the complexity of design learning in progress.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="50" page="6" column="1">18</outsider>
        <outsider class="DoCO:TextBox" type="header" id="51" page="6" column="1">S. Goldman et al.</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="62" page="6" column="1">4 Theoretical Perspectives</h1>
        <region class="DoCO:TextChunk" id="89" page="6" column="1">The five key phases of the design thinking process are empathize, define, ideate, prototype and test ( <xref ref-type="bibr" rid="R21" id="63" class="deo:Reference">Hasso Plattner Institute of Design 2007</xref>). Together, they provide each learner with a relevant, socially situated, complex problem-solving environment in which to generate solutions. While learning to become design thinkers, students focus on defining the parameters of a problem, identifying needs, dealing with varying levels of ambiguity, actively solving problems and making connections<marker type="page" number="7"/><marker type="block"/> between their lives inside and outside of school. As researchers of design thinking who are also concerned with learning, we were guided by a theoretical stance that is based in experiential and sociocognitive views of learning. As Vygotsky (1934/ 1976) described, opportunities to interact with others who have varying degrees of expertise in a social environment become crucial to learning. The human-centered focus of design thinking and the deep and radical collaborations that define the process provide a deeply social process for learning. Design thinking is an approach toward learning that encompasses active problem solving by engaging with (<xref ref-type="bibr" rid="R14" id="67" class="deo:Reference">Dewey 1916</xref>), and changing, the world. Language is central to this view, as we communicate and engage in dialogue with others (Bakhtin 1981). Learning, as <xref ref-type="bibr" rid="R16" id="68" class="deo:Reference">Freire and Macedo (1987)</xref> describe it, demands a critical way of comprehending and of realizing the reading of the word and that of the world, the reading of text and of context. Design thinking supports this Freirean notion of impactful change which focuses on learning as a process where knowledge is presented to us, then shaped through understanding, discussion and reflection and, ultimately, action on behalf of others. Furthermore, design thinking is also informed by Papert’s (1980) view of constructionism, which describes how ideas get formed and transformed when learners are involved in making tangible objects that are expressed through different media, actualized in particular contexts (<xref ref-type="bibr" rid="R25" id="69" class="deo:Reference">Kafai and Resnick 2000</xref>; <xref ref-type="bibr" rid="R36" id="70" class="deo:Reference">Todd 1999</xref>). This transformation, which <xref ref-type="bibr" rid="R20" id="71" class="deo:Reference">Haskell (1985)</xref> describes as the acquisition of a know-how skill and new technologies, inspires the subject with an irresistible urge to change the lives of strangers who those technologies and skills can impact. Design thinking provides a robust scaffold for divergent problem solving, as it engenders a sense of creative confidence that is both resilient and highly optimistic. The need for this kind of approach is timely. According to the <xref ref-type="bibr" rid="R7" id="72" class="deo:Reference">Carnegie Foundation Commission on Mathematics and Science (2009)</xref>, the United States needs an educated young citizenry with the capacity to contribute to and gain from the country’s future productivity, understand policy choices, and participate in building a sustainable future. Likewise, research has indicated that many first-year college students need further development in critical thinking and problem solving (<xref ref-type="bibr" rid="R28" id="73" class="deo:Reference">Lundell et al. 2004</xref>). The need for knowledge and skills from science, technology, engineering, and mathematics are considered crucial to virtually every endeavor of individual and community life. And, in a time of economic uncertainty, design thinking has the potential to address the demands of developing, recruiting and retaining top students and agents of innovation. Design thinking, as a mode of inquiry that puts “doing” and “innovating” at the center of problem-solving, promises to address future needs of the globe. It has the potential to engage students in ways that are inclusive of their diversity, makes school learning relevant and real, pressing local and global issues which can enhance one’s motivation to learn. It creates a “third space” (Guti  ́rrez 2008), an interdisciplinary space where students respond to design challenges with a clearly articulated sense of their confidence and agency and, more specifically, of their identities as change agents. At the university level, the commitments of both Stanford University and the University of Potsdam to design thinking education and research are leading the<marker type="page" number="8"/><marker type="block"/> way to better understandings of what is taking place in design thinking education and creating tools that help capture and improve the process at the university level (<xref ref-type="bibr" rid="R29" id="77" class="deo:Reference">Meinel et al. 2011</xref>; this volume). Design thinking education at any level has the potential to impact learning skills such as working in groups, following a process, defining problems, and creating solutions (<xref ref-type="bibr" rid="R4" id="78" class="deo:Reference">Barron 2006</xref>). Some research in the K-12 arena shows that design-based learning can be productive even before the university years (<xref ref-type="bibr" rid="R8" id="79" class="deo:Reference">Carroll et al. 2010</xref>; <xref ref-type="bibr" rid="R22" id="80" class="deo:Reference">Hmelo et al. 2000</xref>; <xref ref-type="bibr" rid="R17" id="81" class="deo:Reference">Goldman 2002</xref>). Early work in this domain has indicated the potential for design to contribute to young people’s metacognitive (<xref ref-type="bibr" rid="R22" id="82" class="deo:Reference">Kolodner et al. 2000</xref> and 2003) and social learning (<xref ref-type="bibr" rid="R10" id="83" class="deo:Reference">Cognition and Technology Group at Vanderbilt 1997</xref>) as well as in specific subject areas (<xref ref-type="bibr" rid="R18" id="84" class="deo:Reference">Goldman et al. 1998</xref>; <xref ref-type="bibr" rid="R30" id="85" class="deo:Reference">Middleton and Corbett 1998</xref>). <xref ref-type="bibr" rid="R37" id="86" class="deo:Reference">Vande Zande (2007)</xref> characterizes design thinking as a means of creative problem-solving that relates thought and action directly and dynamically. The methodologies of design thinking and rapid prototyping play important roles in developing transformative advances in learning and teaching (<xref ref-type="bibr" rid="R9" id="87" class="deo:Reference">Cobb et al. 2003</xref>; Design-<xref ref-type="bibr" rid="R13" id="88" class="deo:Reference">Based Research Collective 2003</xref>). Mimicking this orientation towards creative problem-solving, radical collaborations, and learning through design in our subject matter, a design thinking research methodology, the team was able to orient itself to the complex problem of assessing design thinking. Two types of studies defined the research agenda and process. The first set of studies took an exploratory approach, using observations and interview methods to generate a detailed understanding of students’ design learning just after they were ensconced in courses. The second series of studies were aimed at testing the assessment tool prototypes that were designed in conjunction with our exploratory study results. The two types of studies were reciprocal, taking our team back and forth between them to refine findings in an iterative mode of understanding learning and assessment. Here, it was our intention and practice for findings based on exploratory studies to contribute to a prototype assessment tool. When analyzing results of testing on the tools, we then poured those results back into more refined or nuanced understandings of the original basic research findings.</region>
        <outsider class="DoCO:TextBox" type="header" id="65" page="7" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="66" page="7" column="1">19</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="75" page="8" column="1">20</outsider>
        <outsider class="DoCO:TextBox" type="header" id="76" page="8" column="1">S. Goldman et al.</outsider>
      </section>
      <section class="deo:Methods">
        <h1 class="DoCO:SectionTitle" id="90" page="8" column="1">5 Research Methods and Analysis</h1>
        <region class="DoCO:TextChunk" id="98" page="8" column="1">Qualitative methodologies ( <xref ref-type="bibr" rid="R6" id="91" class="deo:Reference">Bogdan and Biklen 1992</xref>) were employed in data collection and analysis. The exploratory studies took a student-centered, emic approach and were conducted with students who were in Stanford design thinking courses. We conducted observations and interviewed students who were enrolled in two of Stanford’s Hasso Plattner Institute of Design (d.school) classes: Design Thinking Bootcamp; and Design Garage. The observations took place during the Fall and Winter academic quarters. Observations, which focused on the full class and on smaller project teams, were recorded in field note records. At the end of the course, observations were followed with open-ended interviews with student participants. Interview questions covered topics relating to the overall experience in the class. Some asked them to reflect on, and describe, when and what they thought they were learning. Sample questions from the interview included:<marker type="page" number="9"/><marker type="block"/> What has been your biggest struggle? What has been your biggest surprise? Please draw a visual representation of design thinking as you understand it. Tell us about an experience of boot camp that made an impression on you. What do you think will stay with you after the class is completed? With the observations and interviews completed, analyses were conducted to identify the kinds of learning experiences students were having and to determine how they met the goals set for them by their instructors. Analysis techniques were qualitative and included open coding of the field notes and interviews, searches for important language, events, and “learnings” that students described, and places where students expressed uncertainty about what or whether they were learning. We searched for times, places and events where feedback came into play for the student: how they understood the feedback they were getting; when they reported they wanted feedback that they did not receive; and what they thought that meant for them as budding design thinkers. This protocol helped us identify opportunities for feedback or reflection on performance; expressions of learning; and documentation of learning. For example, in one class we observed students asking for confirmation that they were “getting this ideation process correct” during class, and being told, “Don’t worry about whether or not you are getting it at this point in time. Just give it a try!” Students were not always reassured at those times, but forged onward. For a few students, we could actually trace how those classroom moments played out in their own thinking or in the feedback they received on class projects. This is an example of a series of assessment opportunities that we could identify and try to understand. With the preliminary exploratory study findings at hand, we began to design a set of assessment tools. We conducted formative user-tests with these tools to improve them iteratively and to further refine insights from our exploratory findings. Through user-testing feedback on the assessment tools and exploratory observations, we were able solve our ongoing dilemma about how difficult it seemed to assess design thinking mindsets. The studies indicated that mindset development was difficult to observe and document during classroom activities even though they seemed present when you talked to students about their experiences and design projects. The cycling back-and-forth among the studies helped us see that the assessment rubric was not an appropriate vehicle for assessing the students’ evolving mindshifts. We realized mindshifts could best be assessed and benchmarked through specialty performance assessment tasks and prompts. In order to develop performance assessment tasks that could measure the development and presence of mindsets, we observed and interviewed school chil- dren, university students, and instructors and experienced design thinkers. We focused our studies on one mindset—being human centered. We developed and researched two tasks—one task for student groups and one task for individuals— which would show how students approached and worked through challenges. We could thus explore how students were exhibiting a human-centered mindset and document the level of sophistication at which this occurred. We administered the<marker type="page" number="10"/><marker type="block"/> tasks to middle school, undergraduate, graduate students, and design thinking instructors. This enabled us to examine and hopefully distinguish among performances of novice, intermediary and sophisticated design thinkers. As we hoped, an analysis of stark differences between the novices and experts revealed a complex pattern of development, and indicated that mindsets might be more in flux than “set”. A way to conceive of and describe some of the common evolving behavioral moves for novice, intermediate and solidified mindsets was therefore the starting point for the concept of evolving mindshifts and a new round of development and validation of the reflective assessment rubric and the performance tasks.</region>
        <outsider class="DoCO:TextBox" type="header" id="93" page="9" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="94" page="9" column="1">21</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="96" page="10" column="1">22</outsider>
        <outsider class="DoCO:TextBox" type="header" id="97" page="10" column="1">S. Goldman et al.</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="99" page="10" column="1">6 Assessment Tool Prototypes</h1>
        <region class="DoCO:TextChunk" id="100" page="10" column="1">Introductions to the assessment tools that were prototyped and studied follow. Each introduction includes a basic description of the tool. We conducted observations and interviewed students who were enrolled at Stanford’s Hasso Plattner Institute of Design (d.school) classes: Design Thinking Bootcamp and Design Garage, and also students from Stanford’s School of Education Learning, Design &amp; Technology program. With insights from these research experiences in place, we began to iterate a set of tools that would measure both mindshift (the active process of developing a mindset) and process. We focused on the creation of performance- based tools and reflective tools that assessed how one would approach both problem definition and problem solving. These would capture the essential shifts that occur when one develops as a design thinker. Our implements include (1) the Reflective Assessment Rubric; (2) the team-based Windaloobah Experiment task; (3) the Designing Twenty-first Century Learning Spaces Task; and (4), the Assessment Dashboard concept.</region>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="101" page="10" column="1">6.1 The Reflective Assessment Rubric</h2>
          <region class="DoCO:TextChunk" id="111" page="10" column="1">With an initial prototype of a design thinking assessment rubric developed in a prior research project, we used the iterative design thinking approach to continue evolving the rubric. Our activities centered on: interviews, observations, analysis/ synthesis, ideation, prototyping and testing, as focal points of the design process. The learning from each type of prototype informed successive versions of the assessment rubric. <xref ref-type="fig" rid="F2" id="102" class="deo:Reference">Figure 2</xref> illustrates a sample page from an advanced prototype of the reflective assessment rubric. Observations of expert and novice designers led to a matrix of skills, processes and mindsets related to design thinking. When we considered how they were noticed and could be documented, we realized that different kinds of assessments were needed for assessing skills, processes, and mindsets. Some were nested; others<marker type="page" number="11"/><marker type="block"/> were umbrella skills. Some were discrete; others were bundled. Some could be documented and much repetition and practice put them into place; others could be accomplished once and thenceforth seem to take root. Some design thinking skills overlapped with skills from other domains, for example, interviewing, observation, and persistence skills. Other skills, such as those related to human-centeredness, ideation, and prototyping were more exclusive to design thinking. We reconsidered the rubric’s categories and chose specific types of actions to be included that best exemplified design thinking. We also separated mindshifts from rubric assessment, and turned attention to mindshifts. To date, the rubric consists of mindshifts, skills, and three levels of expertise. It also indicates where a specific skill is exhibited in the process and where skills tend to overlap and interact with mindshifts. The identified skills include the following: • Interviewing • Prototyping • Synthesis • Persistence • Resilience • Adaptability • Risk-taking<marker type="page" number="12"/><marker type="block"/> • Brainstorming • Bias Towards Action • Storytelling • Process Vocabulary • Collaboration A specific skill may present itself in more than one phase of the process. For example, one might interview during both the empathy and testing phase of the design thinking process, which will, consequently, reflect different components of the skill. Students of design thinking learn at different rates, and the three levels are approximate representations of behaviors and actions for novice, intermediate and skilled design thinkers. When analyzing data, we also found that students exhibited a range of skills that were indicative of their abilities as developing design thinkers. Levels of expertise varied for each phase of the process. While working on the rubric we considered who would best be in a position to assess developing skills and mastery of processes. While many items called for assessment by an instructor, we also identified many items on the rubric that could be documented by students. For example, students could track their work and progress relating to topics such as persistence, self-regulation, and development of meta skills. The rubric is available electronically and we continue to validate it based on feedback from students and instructors.</region>
          <outsider class="DoCO:TextBox" type="header" id="104" page="11" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="105" page="11" column="1">23</outsider>
          <region class="DoCO:FigureBox" id="F2">
            <image class="DoCO:Figure" src="62md.page_011.image_02.png" thmb="62md.page_011.image_02-thumb.png"/>
            <caption class="deo:Caption" id="107" page="11" column="1">Fig. 2 Sample page from the reflective assessment rubric</caption>
          </region>
          <outsider class="DoCO:TextBox" type="page_nr" id="109" page="12" column="1">24</outsider>
          <outsider class="DoCO:TextBox" type="header" id="110" page="12" column="1">S. Goldman et al.</outsider>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="112" page="12" column="1">6.2 The Windaloobah Experiment Task</h2>
          <region class="DoCO:TextChunk" id="114" page="12" column="1">Once we discovered that the rubric was an inappropriate instrument for assessing mindshifts, we transferred our efforts to the design of performance-based assessment tasks. We created an assessment task, The Windaloobah Experiment, to gauge students’ understanding of the design thinking mindsets. The task was designed to give students, working in teams, opportunities and resources for exhibiting empathy and human-centeredness. It was administered to two classes of middle school students and two groups of master’s level graduate students. In the middle school, one class had recently completed an integrated mathematics and design thinking challenge. The second class had not yet been introduced to design thinking. The graduate students were diverse in experience, ranging from none to a student who was in the d.school class Design Thinking Bootcamp. The Windaloobah Experiment was structured as an hour long design challenge. The students were asked to work in teams to design a Windaloobah, however, the definition of a Windaloobah (a made up word) was deliberately ambiguous. Students watched a brief introductory video. <xref ref-type="fig" rid="F3" id="113" class="deo:Reference">Figure 3</xref> contains the video script from the video. After watching the video, the students were given information packets with profiles of people who would be part of the community embarking on a journey on the Windaloobah. The profiles consisted of a photograph of each community</region>
          <outsider class="DoCO:TextBox" type="header" id="115" page="13" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="116" page="13" column="1">25</outsider>
          <region class="DoCO:TextChunk" id="117" confidence="possible" page="13" column="1">Welcome to the Windaloobah Experiment. It is the year 2125. A group of brave and adventurous explorers have joined the Windaloobah experiment. For the next 15 months they have no permanent home. Your job is to design a Windaloobah. What is a Windaloobah? • A Windaloobah must have room for 5 people. • A Windaloobah must travel through water, skies, snow, it must be able to move through cities. It must be ready for unexpected adventures. • A Windaloobah is a home away from home.</region>
          <region class="DoCO:FigureBox" id="F3">
            <caption class="deo:Caption" id="118" page="13" column="1">Fig. 3 The Windaloobah Experiment video script</caption>
            <image class="DoCO:Figure" src="62md.page_013.image_03.png" thmb="62md.page_013.image_03-thumb.png"/>
          </region>
          <region class="DoCO:FigureBox" id="F4">
            <caption class="deo:Caption" id="119" page="13" column="1">Fig. 4 Windaloobah community member profile</caption>
          </region>
          <outsider class="DoCO:TextBox" type="page_nr" id="120" page="14" column="1">26</outsider>
          <outsider class="DoCO:TextBox" type="header" id="121" page="14" column="1">S. Goldman et al.</outsider>
          <region class="DoCO:TextChunk" id="123" page="14" column="1">member, and text describing his or her interests, needs and challenges (See example profile in <xref ref-type="fig" rid="F4" id="122" class="deo:Reference">Fig. 4</xref>). The Windaloobah community included a grandmother, a 3-year-old boy, a shy 13-year-old girl, a 23-year old musician, and a 19-year-old videographer. The students were also given an envelope with a travel itinerary describing the conditions the travelers would encounter, and a set of pictures (a kite, a sign with 5 mph on it, and a squirrel.) The students had to ascertain what they might do with ambiguous information. Each group was also given a cardboard box filled with an assortment of prototyping materials. The Windaloobah Experiment task enabled us to observe and document human- centeredness as groups of students engaged a design challenge. With the task, we could discriminate human-centeredness, separating out how human-centered design thinkers approached the task differently. Students who had even an introductory level of design thinking showed more human-centered behaviors and actions than those who were completely inexperienced.</region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="124" page="14" column="1">6.3 The Designing Twenty-First Century Learning Spaces Task</h2>
          <region class="DoCO:TextChunk" id="126" page="14" column="1">The research team was also interested in designing a reflection-based task for individuals in order to gain further insight into human-centered mindshifts. Students were invited to a website, Designing Twenty-first Century Learning Spaces, where they were asked to provide input (<xref ref-type="fig" rid="F5" id="125" class="deo:Reference">Fig. 5</xref>). They were asked to watch a video that consisted of two components of exploring the issue. The first part of the video focused on a classroom filled with an array of technology materials. There were no students in the room. The second part of the video featured a story about a teacher, Nate, in an urban classroom who was concerned about meeting the needs of his students. At the end of the video, the research subjects were directed to a survey and asked to share their thoughts. The survey consisted of two questions: In your opinion, what is the most important aspect to consider in the design of the classroom of the future? What would you do if you had to design a classroom for Nate? The survey also included a question regarding the responder’s experiences with and exposure to the design thinking process. Preliminary data analysis indicated that students with no design thinking experience showed a baseline of little to no human-centeredness. If they did orient to the Nate’s stated needs, it was limited to a level of “noticing” which did not extend to design solutions. At present, the task needs guidelines for scoring responses, and in future work we would like to validate the task with a large number of participants.</region>
          <outsider class="DoCO:TextBox" type="header" id="127" page="15" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="128" page="15" column="1">27</outsider>
          <region class="DoCO:FigureBox" id="F5">
            <image class="DoCO:Figure" src="62md.page_015.image_04.png" thmb="62md.page_015.image_04-thumb.png"/>
            <caption class="deo:Caption" id="130" page="15" column="1">Fig. 5 Designing twenty-first century learning spaces</caption>
          </region>
        </section>
        <section class="DoCO:Section">
          <h2 class="DoCO:SectionTitle" id="131" page="15" column="1">6.4 The Assessment Dashboard</h2>
          <region class="DoCO:TextChunk" id="140" page="15" column="1">From the time we first prototyped the assessment rubric, we were aware that instructors and students would want a way to keep track of design learning over time. Design thinking is a complex of interwoven and interdependent skills, processes and mindshifts. Even students in the same course and design challenge are likely to develop different skills, capabilities and mindsets. Thus, in each study we completed, we looked for ways to think about and organize the assessment process and the snapshot on learning that it generates. We initially had the idea of a longitudinal portfolio that would follow students and their learning over time. At the time all of our effort was focused on the assessment rubric. Once we moved to a notion of varied palette of assessment types, we had to rethink how to organize assessment information so it was useful and transfer- able to stakeholders. We tried different ways to organize mindshifts with skills and practices. We decided to treat mindshifts as reflective tasks where student-simulated approaches to design thinking action would help reveal the more hidden propensities of mindshifts. In order to allow students and teachers to effectively visualize these relationships, make explicit connections with their projects, and document a student’s progress in developing as a design thinker, our work turned to designing an online dashboard. The dashboard was conceived to consider many of the needs <marker type="page" number="16"/><marker type="block"/> we were discovering. Figures 6 and 7 illustrate the framework for a dashboard that might meet the needs of individual students, students working in teams, and instructors who must weigh in on learning for both instances. This framework would allow stakeholders to document the different aspects of design learning and would serve as an assessment environment that traveled with the student over time. The dashboard would archive media related to design challenges and benchmarks in design learning, helping trace the changing levels of sophistication as a design thinker grew over time. To date, we have developed a first prototype of the dashboard and will be moving towards user feedback and further iterations. The dashboard is designed to enable instructors and learners to: • Visualize the skills that are relevant to stages of the design thinking process • Visualize the skills and process stages that contribute to each mindshift (<xref ref-type="fig" rid="F6" id="137" class="deo:Reference">Fig. 6</xref>) • Build a portfolio (<xref ref-type="fig" rid="F6" id="138" class="deo:Reference">Fig. 6</xref>), selecting those stages and skills focused on in a given project. Developing mindshifts are included. • Assess and view the performance of individuals and teams for different projects, progress over time, and for each of the mindshifts (<xref ref-type="fig" rid="F7" id="139" class="deo:Reference">Fig. 7</xref>). The dashboard will also allow the research team to prototype and refine the assessment of the skills that are included in the rubric by tracking its use by teachers. At the moment the dashboard is in the user feedback phase.</region>
          <outsider class="DoCO:TextBox" type="page_nr" id="133" page="16" column="1">28</outsider>
          <outsider class="DoCO:TextBox" type="header" id="134" page="16" column="1">S. Goldman et al.</outsider>
          <region class="DoCO:FigureBox" id="F6">
            <image class="DoCO:Figure" src="62md.page_016.image_05.png" thmb="62md.page_016.image_05-thumb.png"/>
            <caption class="deo:Caption" id="136" page="16" column="1">Fig. 6 A view of the dashboard from the mindset view</caption>
          </region>
          <outsider class="DoCO:TextBox" type="header" id="141" page="17" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
          <outsider class="DoCO:TextBox" type="page_nr" id="142" page="17" column="1">29</outsider>
          <region class="unknown" id="143" page="17" column="1">Teacher/Student Dashboard Driving Experience Design Project 100.0 90.0 80.0 70.0 student 60.0 50.0 40.0 BY 30.0 20.0 10.0 0.0</region>
          <region class="unknown" id="144" page="17" column="1">Human-centered Experimental Collaborative Metacognitive</region>
          <region class="unknown" id="145" page="17" column="1">100 90 80 70 team 50 60 BY 40 30 20 10 0</region>
          <region class="DoCO:FigureBox" id="Fx146">
            <image class="DoCO:Figure" src="62md.page_017.image_06.png" thmb="62md.page_017.image_06-thumb.png"/>
          </region>
          <region class="unknown" id="147" page="17" column="1">Hu Ex Co Me ma pe lla tac n-c en rim en bo rat og nit ter tal ive ive ed</region>
          <region class="DoCO:FigureBox" id="F7">
            <caption class="deo:Caption" id="148" page="17" column="1">Fig. 7 Visualizing progress over design projects</caption>
          </region>
        </section>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="149" page="17" column="1">7 Summary and Discussion</h1>
        <region class="DoCO:TextChunk" id="156" page="17" column="1">Through a series of reciprocal research and design studies we explored critical elements of learning the design thinking process and possible ways to document them. Our focus on the development of performance-based assessment tasks, on reflection-based assessment tasks, and on the further development and refinement of an assessment rubric made for rich learning. The results of the project helped enrich our assessment tools and our conceptualization of design learning. Firstly, we understood the complex relationship and differences between design thinking skills and processes, and the development of design thinking mindsets. These differences had implications for the assessment tools. Secondly, we conceived mindshifts, which express the developmental journey towards mindsets that are so important when a person is learning to be a design thinker. Mindshifts are epistemological viewpoints in flux. They are part of the process of becoming design thinkers. We were able to identify four central mindshifts— becoming human-centered, experimental, collaborative, and metacognitive—each of which are representative of different aspects of one’s development as a design thinker. Our perspective change to shifts gave us new insights into the most significant ways that one’s behavior and orientation change as one grows as a design thinker. A mindshift, when finally set, is an underlying structure for thinking and acting as a design thinker—it is the deep structure and world-view that is learned in conjunction with, and supports, the development of design skills. For example, one <marker type="page" number="18"/><marker type="block"/> might be a good prototype developer, but someone with an experimental mindshift understands the value of prototyping and seems to have instincts for bringing prototyping into the process early and often. One might be a skilled interviewer, but being an empathetic interviewer—the manifestation of the human-centered mindshift—is essential to being a design thinker. Prior to understanding the mindsets as shifts in perspectives and development of predilections instincts, we focused on the skills and processes of design thinking that were observable and documented based on the performance of tasks and activities. However, after this change in orientation, we focused our work specifically on assessments that help make visible and document the development of students’ human-centered mindshift. When students are developing a human- centered mindset, they move towards solutions that resonate with the needs and lives of others, marking a sharp contrast to egocentric views of the world that are characteristic of a failure to adopt human-centeredness. Mindset development is a fluid and dynamic process, yet for some students, developing a mindset might seem like a “switch has been flipped from off to on”. For others, mindshifts come in more complex and incremental ways. Each step a student takes toward being more human-centered can help him or her see, consider, interact with, and have empathy for others. Our research team and other design thinking educators took for granted that some or all students would gain mindsets, but during this project we were actually able to witness students reaching benchmark points in the evolution of these mindsets. Such students were in the process of mindshifts. We saw that students might have no inclination toward human-centeredness, they might tend to act in human-centered ways intermittently or at convenient stages of the design process; or they might consistently orient themselves in human-centered ways no matter where they were in the design process. Our reflective tasks aided us in seeing differences in those who were “mind-shifting” and those who were not. Likewise, our research with students who had little or no experience with design thinking courses showed a stark contrast with those who were taking courses and those who were already considered more professional design thinkers. We were able to expand and refine design thinking skills that were included in the rubric and identify actions and behaviors that might be part of the documentation process. Through the RR&amp;D process, we identified topics for further research and design of assessment tools for the design thinking classroom. The following questions will be the focus of future work: 1. How effectively do the performance-based assessment rubric and reflection- based tasks document the skills and mindshifts inherent in the design thinking process? How useful are they as tools for both students and instructors? 2. Are the tools useful in a variety of educational settings as indicators of design learning? 3. Since the tools were developed to assess, document, and help individuals and their instructors in design thinking education, what needs to be accounted for in developing assessments of groups who are learning design thinking? Even with a demonstrated strong need for such tools, are these assessments practical and usable given the structure of courses?<marker type="page" number="19"/><marker type="block"/> We made progress toward our goal of providing a detailed reflective framework for students and teachers to document, reflect on, and confirm their engagements and progress in relation to a diverse range of design thinking activities. The framework is accompanied by a set of tools for tracking and certifying students’ progress in relation to design thinking skills, processes and mindsets. In addition, the tools can provide a shared resource for design thinking teams and instructors. It is essential to develop a comprehensive understanding of design thinking from theoretical and applied vantage points. It is our hope that our research will contribute to this understanding.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="151" page="18" column="1">30</outsider>
        <outsider class="DoCO:TextBox" type="header" id="152" page="18" column="1">S. Goldman et al.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="154" page="19" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="155" page="19" column="1">31</outsider>
      </section>
      <section class="deo:Acknowledgements">
        <h1 class="DoCO:SectionTitle" id="157" confidence="possible" page="19" column="1">Acknowledgments</h1>
        <region class="DoCO:TextChunk" id="158" confidence="possible" page="19" column="1">We would like to thank the students and instructors who participated in our studies. They have made it possible for us to better understand what it means to become a design thinker and how assessment tools could add value to design learning. A grant from the Hasso Plattner Design Thinking Research Program made this work possible. Findings and opinions presented are those of the authors and do not represent the HPDTRP.</region>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="159" page="19" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="160" page="19" column="1">Alexander A, Blair KP, Goldman S, Jimenez O, Nakaue M, Pea R, Russell A (2010) Go Math! How research anchors new mobile learning environments. In: Proceedings of the sixth inter- national IEEE conference on wireless, mobile, and ubiquitous technologies in education (WMUTE). Kaohsiung, pp 57–64</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="161" confidence="possible" page="19" column="1">Baker E (2010) What probably works in alternative assessment. CRESST Report 772. National Center for Research on Evaluation, Standards, and Student Testing, Los Angeles</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="162" page="19" column="1">Bakhtin MM [1930s] (1981) The dialogic imagination: four essays. In: Holquist M (ed) (Trans: Emerson C, Holquist M). University of Texas Press, Austin/London</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="163" page="19" column="1">Barron B (2006) Interest and self-sustained learning as catalysts of development: learning ecology perspective. Hum Dev 49(4):193–224</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="164" page="19" column="1">Black P, Wiliam D (1998) Inside the black box: raising standards through classroom assessment. Phi Delta Kappan, 80(2):139–148, October 1998</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="165" page="19" column="1">Bogdan R, Biklen S (1992) Qualitative research for education: an introduction to theory and methods. Allyn &amp; Bacon, Boston</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="167" page="19" column="1">Carnegie Foundation Commission on Mathematics and Science (2009) Excellence and equity in mathematics and science to transform education. <ext-link ext-link-type="uri" href="http://opportunityequation.org/report." id="166">http://opportunityequation.org/report.</ext-link> Accessed 29 Jan 2011</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="168" page="19" column="1">Carroll M, Goldman S, Britos L, Koh J, Royalty A, Hornstein M (2010) Destination, imagination, and the fires within: design thinking in a middle school classroom. Int J Art Design Educ 29 (1):37–53</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="169" page="19" column="1">Cobb P, DiSessa A, Lehrer R, Scauble L (2003) Design experiments in educational research. Educ Res 21(1):9–13</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="170" page="19" column="1">Cognition and Technology Group at Vanderbilt (1997) The Jasper Project: Lessons in Curriculum, Instruction, Assessment, and Professional Development. Lawrence Erlbaum Associates, Inc., Mahwah, NJ</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="171" confidence="possible" page="19" column="1">Committee on Science, Engineering and Public Policy (COSEPUP) (2006) Beyond bias and barriers: fulfilling the potential of women in academic science and engineering. National Science Foundation, Arlington</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="173" confidence="possible" page="19" column="1">National Science Foundation Task Force on Cyberlearning (2008) Fostering learning in the networked world: the cyberlearning opportunity and challenge. <ext-link ext-link-type="uri" href="http://www.nsf.gov/pubs/2008/" id="172">http://www.nsf.gov/pubs/2008/</ext-link></ref>
          <ref class="deo:BibliographicReference" id="177" page="20" column="1">nsf08204/nsf08204.pdf <ext-link ext-link-type="uri" href="http://www.nsf.gov/pubs/2008/nsf08204/nsf08204.pdf." id="176">http://www.nsf.gov/pubs/2008/nsf08204/nsf08204.pdf.</ext-link> Accessed 20 Dec 2010</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="178" confidence="possible" page="20" column="1">Design-Based Research Collective (2003) Design-based research: an emerging paradigm for educational inquiry. Educ Res 32(1):5–8</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="179" page="20" column="1">Dewey J (1916) Democracy and education. Macmillan, New York</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="181" page="20" column="1">Dweck C (2007) How not to talk to your kids: the inverse power of praise. New York Magazine. <ext-link ext-link-type="uri" href="http://nymag.com/news/features/27840/." id="180">http://nymag.com/news/features/27840/.</ext-link> Accessed 8 Nov 2011</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="182" page="20" column="1">Freire P, Macedo D (1987) Literacy: reading the word and the world. Bergin and Garvey, South Hadley</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="183" page="20" column="1">Goldman S (2002) Instructional design: learning through design. In: Guthrie J (ed) Encyclopedia of education, 2nd edn. Macmillan Reference USA, New York, pp 1163–1169</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="184" page="20" column="1">Goldman S, Knudsen J, Latvala M (1998) Engaging middle schoolers in and through real-world mathematics. In: Leutzinger L (ed) Mathematics in the middle. National Council of Teachers of Mathematics, Reston, pp 129–140</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="185" confidence="possible" page="20" column="1">Guti  ́rrez KD (2008) Developing a sociocritical literacy in the third space. Read Res Quart 43 (2):148–164</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="186" page="20" column="1">Haskell TL (1985) Capitalism and the origins of the humanitarian sensibility, parts 1 and 2. Am Hist Rev. 90(3, 4):339–361, 547–566</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="187" page="20" column="1">Hasso Plattner Institute of Design at Stanford (2007) Design thinking process. Stanford University, Palo Alto</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="188" page="20" column="1">Hmelo C, Holton D, Kolodner J (2000) Designing to learn about complex systems. JLearn Sci 9 (3):247–298</ref>
          <ref rid="R23" class="deo:BibliographicReference" id="189" confidence="possible" page="20" column="1">Jenkins H (2006) Convergence culture: where old and new media collide. New York University Press, New York</ref>
          <ref rid="R24" class="deo:BibliographicReference" id="190" page="20" column="1">Jenkins H, Clinton K, Purushotma R, Robinson AJ, Weigel M (2006) Confronting the challenges of participatory culture: media education for the 21st century. The MacArthur Foundation, Chicago</ref>
          <ref rid="R25" class="deo:BibliographicReference" id="191" page="20" column="1">Kafai Y, Resnick M (eds) (2000) Constructionism in practice: designing, thinking, and learning in a digital world. Lawrence Erlbaum Associates, Mahwah</ref>
          <ref rid="R26" class="deo:BibliographicReference" id="192" page="20" column="1">Kolodner J, Gray JT, Fasse BB (2000) Promoting transfer through case-based reasoning: rituals and practices in learning by DesignTM classrooms. Cogn Sci Q 1:183–232</ref>
          <ref rid="R27" class="deo:BibliographicReference" id="193" page="20" column="1">Kolodner JL, Camp PJ, Crismond D, Fasse B, Gray J, Holbrook J, Putambeckar S, &amp; Ryan M (2003) Problem-based learning meets case-based reasoning in the middle-school science classroom: Putting Learning By Design Into Practice. The Journal of the Learning Sciences, 12 (4): 495–547</ref>
          <ref rid="R28" class="deo:BibliographicReference" id="194" page="20" column="1">Lundell DB, Higbee JL, Hipp S, Copeland RE (2004) Building bridges for access and success from high school to college: proceedings of the metropolitan higher education consortium’s developmental education initiative. Center for Research on Developmental Education and Urban Literacy, University of Minnesota, Minneapolis</ref>
          <ref rid="R29" class="deo:BibliographicReference" id="195" page="20" column="1">Meinel C, Leifer L, Plattner H (eds) (2011) Design thinking: understand–improve–apply. Springer, Heidelberg</ref>
          <ref rid="R30" class="deo:BibliographicReference" id="196" page="20" column="1">Middleton JA, Corbett R (1998) Sixth-grade students’ conceptions of stability in engineering contexts. In: Lehrer R, Chazan D (eds) Designing learning environments for developing understanding of geometry and space. Lawrence Erlbaum Associates, Mahwah, pp 249–266</ref>
          <ref rid="R31" class="deo:BibliographicReference" id="198" page="20" column="1">Obama B (2009) Address to the Hispanic Chamber of Commerce. U.S. Department of Education, Assessment: measure what matters. <ext-link ext-link-type="uri" href="http://www.ed.gov/technology/netp-2010/assessment-" id="197">http://www.ed.gov/technology/netp-2010/assessment-</ext-link> measure-what-matters. Accessed 20 Dec 2010</ref>
          <ref rid="R32" class="deo:BibliographicReference" id="199" page="20" column="1">Papert S (1980) Mindstorms. Children, computers and powerful ideas. Basic Books, New York</ref>
          <ref rid="R33" class="deo:BibliographicReference" id="200" confidence="possible" page="20" column="1">Partnership for 21st Century Skills (2008) 21st Century Skills, Education &amp; Competitiveness: A Resource and Policy Guide. Tucson: Partnership for 21st Century Skills</ref>
          <ref rid="R34" class="deo:BibliographicReference" id="202" page="20" column="1">Silva E (2008) Measuring skills for the 21st century. Education Sector, pp 1–10. <ext-link ext-link-type="uri" href="http://www" id="201">http://www</ext-link>. educationsector.org/publications/measuring-skills-21st-century. Accessed 28 Nov 2010</ref>
          <ref rid="R35" class="deo:BibliographicReference" id="205" page="21" column="1">Smith JP, diSessa AA, Roschelle J (1993) Misconceptions reconceived: a constructivist analysis of knowledge in transition. J Learn Sci 3(2):115–163 (1993–1994)</ref>
          <ref rid="R36" class="deo:BibliographicReference" id="206" page="21" column="1">Todd R (1999) Design and technology yields a new paradigm for elementary schooling. J Technol Stud 25(2):26–33</ref>
          <ref rid="R37" class="deo:BibliographicReference" id="207" page="21" column="1">Vande Zande R (2007) Design education as community outreach and interdisciplinary study. J Learn Through Arts 3(1):1–22</ref>
          <ref rid="R38" class="deo:BibliographicReference" id="208" page="21" column="1">Vygotsky LS (1934/1976) Thought and language. MIT Press, Cambridge, MA</ref>
          <ref rid="R39" class="deo:BibliographicReference" id="209" page="21" column="1">Wallace A (1956) Revitalization movements: some theoretical considerations for their compara- tive study. Am Anthropol 58:264–281</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="page_nr" id="174" page="20" column="1">32</outsider>
        <outsider class="DoCO:TextBox" type="header" id="175" page="20" column="1">S. Goldman et al.</outsider>
        <outsider class="DoCO:TextBox" type="header" id="203" page="21" column="1">Assessing d.learning: Capturing the Journey of Becoming a Design Thinker</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="204" page="21" column="1">33</outsider>
        <region class="DoCO:FigureBox" id="Fx210">
          <image class="DoCO:Figure" src="62md.page_022.image_07.png" thmb="62md.page_022.image_07-thumb.png"/>
        </region>
        <region class="DoCO:TextChunk" id="212" confidence="possible" page="22" column="1"> <ext-link ext-link-type="uri" href="http://www.springer.com/978-3-642-31990-7" id="211">http://www.springer.com/978-3-642-31990-7</ext-link></region>
        <region class="DoCO:FigureBox" id="Fx213">
          <image class="DoCO:Figure" src="62md.page_022.image_08.png" thmb="62md.page_022.image_08-thumb.png"/>
        </region>
      </section>
    </body>
  </article>
</pdfx>
